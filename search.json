[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This site is a work in progress! Original .R and .rmd files from are being migrated into a new book using quarto."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Welcome",
    "section": "Welcome",
    "text": "Welcome\nThis book is meant to accompany BIO/ENV 2100:Biostatistics at Baruch College, but it should offer another perspective to anyone trying to learn statistics, R, or some combination. The class now includes\n\na website housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!\n\nAll of these resources may prove useful in learning the material.\nI say another perspective because an immediate question should be why the world needs another self-published statistics book, especially one focused on introducing R. There are already many, many good ones (some of which are shared at the end of each of relevant chapter and in the list of additional resources).To this I offer a few responses\n\nAs already noted, this book was designed to accompany courses I teach. Having the material presented in the same order, but with additional context, should help students learn the material.\nThe courses I teach focus on introducing statistics from a biological perspective, so examples, papers, and problems focus on natural systems when possible. Having examples, including from published papers, that introduce the need and use of various tests should aid in helping students learn\n\nwhy various tests exist\nhow they relate to each other\nwhen one should be used as opposed to another\nhow to defend the choices you made or evaluate those of others!"
  },
  {
    "objectID": "index.html#here-there-be-monsters-but-also-opportunities",
    "href": "index.html#here-there-be-monsters-but-also-opportunities",
    "title": "Welcome",
    "section": "Here there be monsters, but also opportunities!",
    "text": "Here there be monsters, but also opportunities!\nStatistics is a complex field that is unfortunately often stuffed into the curriculum of other majors (see above). However, my goal is to teach the concepts while also giving students the tools to actually address questions. Given these goals,\n\nwe’ll learn how to use tools and applications including R (through Rstudio), git, and markdown. If this is your first time using any (or all) of these tools, don’t worry. We will start at the very beginning.\n\nThere are many, many ways to do any task in R. I will show you one (sometimes two) for a given concept, but note you may find other approaches online or in other material\nI typically use verbose coding (more words and lines, but easier to read and understand). I know much of what we do could be done in fewer steps, but speed is commonly less of an issue than readability (which is connected to repoducibility) for our fields\n\nGiven our focus on concepts, we will not dwell on the proofs or other mathematical components of statistics. I’m happy to point you towards texts to help with those, or discuss them.\nWe will use easy examples to illustrate concepts and applications (toy datasets), which make it easier for you to update in the future (real data are often messy!) while also connecting our class to real-life papers and ideas as much as possible\n\n\n\n\nFigure 1: Old maps rarely stated “Here there be monsters”, but mythical animals did appear on maps!\n\n\nBe warned: You may encounter some questions as we introduce new material. For example, we’ll talk about normality before fully explaining it. We’ll also use code (to make figures, for example) before you understand it. Feel free to ask questions, but you can also be sure we’ll cycle back (and expand) on many topics. I’ll also add asides/tangents throughout the book to help answer some common questions that pop up.\nHopefully this will open the door to careers in data science (a related term) and statistics to some students who haven’t considered that path before. Jobs in these fields are some of the fastest growing in the country, and the skills you learn in this class, including\n\nCritical thinking\nCoding\n\nR\nmarkdown\ngit\n\nData wrangling\nVisualization and stats\nWriting and communication\n\nwill be some of the most transferable you acquire as an undergraduate.\n\n\n\nFigure 2: Chart from Occupational Outlook Handbook showing fastest growing occupations and median pay. Data from 9.8.22. Screenshot taken 7.26.23\n\n\nI hope you find the book useful and learn to see statistics as more than something you do to finish a project or a course that you are required to take. The book is written in quarto, a derivative/extension of rmarkdown, which allows R code and prose to be easily created and published together. You can see the code for all the material on github, and you will learn early on how to make a copy of the material that you can work on yourself."
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html",
    "href": "content/solutions/7_More_ANOVAs_solutions.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#overview",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#overview",
    "title": "More ANOVAs",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the More ANOVAs lecuture."
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#examples",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#examples",
    "title": "More ANOVAs",
    "section": "Examples",
    "text": "Examples\n\nIf interaction is significant\nFollowing the memory example from class, read in and check data\n\nmemory &lt;- read.table(\"http://www.statsci.org/data/general/eysenck.txt\", header = T,\n                     stringsAsFactors = T)\nstr(memory)\n\n'data.frame':   100 obs. of  3 variables:\n $ Age    : Factor w/ 2 levels \"Older\",\"Younger\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Process: Factor w/ 5 levels \"Adjective\",\"Counting\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Words  : num  8 6 4 6 7 6 5 7 9 7 ...\n\n\nLet’s put younger level first\n\nlibrary(plyr)\nmemory$Age &lt;- relevel(memory$Age, \"Younger\")\n\nand graph\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nfunction_output &lt;- summarySE(memory, measurevar=\"Words\", groupvars =\n                               c(\"Age\", \"Process\"), na.rm = T)\nlibrary(ggplot2)\nggplot(function_output, aes(x=Age, y=Words,color=Process, \n                                   shape = Process)) +\n  geom_line(aes(group=Process, linetype = Process), size=2) +\n    geom_point(size = 5) +\n  ylab(\"Words remembered\")+ \n  xlab(\"Age\") + \n  ggtitle(\"Process type interacts with age to impact memory\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThere appears to be some interactions. Let’ build a model\n\nmemory_interactions &lt;- lm(Words ~ Age * Process, memory)\n\nand check assumptions.\n\npar(mfrow=c(2,2))\nplot(memory_interactions)\n\n\n\n\nThese appear to be met, so look at output\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(memory_interactions, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 272.9281 &lt; 2.2e-16 ***\nAge           72.2  1   8.9963 0.0034984 ** \nProcess     1353.7  4  42.1690 &lt; 2.2e-16 ***\nAge:Process  190.3  4   5.9279 0.0002793 ***\nResiduals    722.3 90                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince interaction is significant, analyze subsets. For example,\n\nmemory_interactions_young &lt;- lm(Words ~ Process, memory[memory$Age == \"Younger\",])\nplot(memory_interactions_young)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(memory_interactions_young, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 343.442 &lt; 2.2e-16 ***\nProcess     1353.7  4  53.064 &lt; 2.2e-16 ***\nResiduals    287.0 45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant difference in words recalled based on process, but why? Investigate with post-hoc tests.\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncomp_young &lt;- glht(memory_interactions_young, linfct = mcp(Process = \"Tukey\"))\nsummary(comp_young)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Words ~ Process, data = memory[memory$Age == \"Younger\", \n    ])\n\nLinear Hypotheses:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \nCounting - Adjective == 0      -8.300      1.129  -7.349  &lt; 0.001 ***\nImagery - Adjective == 0        2.800      1.129   2.479  0.11369    \nIntentional - Adjective == 0    4.500      1.129   3.984  0.00219 ** \nRhyming - Adjective == 0       -7.200      1.129  -6.375  &lt; 0.001 ***\nImagery - Counting == 0        11.100      1.129   9.828  &lt; 0.001 ***\nIntentional - Counting == 0    12.800      1.129  11.333  &lt; 0.001 ***\nRhyming - Counting == 0         1.100      1.129   0.974  0.86546    \nIntentional - Imagery == 0      1.700      1.129   1.505  0.56455    \nRhyming - Imagery == 0        -10.000      1.129  -8.854  &lt; 0.001 ***\nRhyming - Intentional == 0    -11.700      1.129 -10.359  &lt; 0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nBlocking example\nFollowing feather color example from class:\n\n# more than 2? ####\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nstr(feather)\n\n'data.frame':   32 obs. of  3 variables:\n $ Bird       : Factor w/ 16 levels \"A\",\"B\",\"C\",\"D\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Feather    : Factor w/ 2 levels \"Odd\",\"Typical\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Color_index: num  -0.255 -0.213 -0.19 -0.185 -0.045 -0.025 -0.015 0.003 0.015 0.02 ...\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather = \"Special\", \n                      Color_index= feather[feather$Feather == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather &lt;- merge(feather, special, all = T)\n\n\nAnova(lm(Color_index ~ Feather + Bird, data=feather), type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.36392  1  59.9538 1.224e-08 ***\nFeather     1.67906  2 138.3093 7.208e-16 ***\nBird        0.34649 15   3.8055 0.0008969 ***\nResiduals   0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\ncompare &lt;- glht(lm(Color_index ~ Feather + Bird, data=feather), linfct = mcp(\"Feather\" = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather + Bird, data = feather)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nTypical - Odd == 0      0.13713    0.02755   4.978   &lt;1e-04 ***\nSpecial - Odd == 0      0.44712    0.02755  16.232   &lt;1e-04 ***\nSpecial - Typical == 0  0.31000    0.02755  11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n#note comparison doesn't work\nAnova(lm(Color_index ~ Feather * Bird, data=feather), type= \"III\")\n\nError in Anova.lm(lm(Color_index ~ Feather * Bird, data = feather), type = \"III\"): residual df = 0"
  },
  {
    "objectID": "content/solutions/7_More_ANOVAs_solutions.html#practice",
    "href": "content/solutions/7_More_ANOVAs_solutions.html#practice",
    "title": "More ANOVAs",
    "section": "Practice",
    "text": "Practice\n\n1\nA survey was conducted to see if athletes and non-athletes deal with anger in the same way. Data is @\nangry &lt;- read.csv(“https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv”, stringsAsFactors = T)\nand more information is at\nhttp://onlinestatbook.com/case_studies/angry_moods.html.\nFocus on the following variables:\nSports 1 = athletes, 2 = non-athletes Gender 1 = males, 2 = females Expression (AE) index of general anger expression: (Anger-Out) + (Anger-In) - (Control-Out) - (Control-In) + 48\nIs there any evidence that gender or athlete status impact how anger is expressed?\n\nangry &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv\", stringsAsFactors = T)\nstr(angry)\n\n'data.frame':   78 obs. of  7 variables:\n $ Gender          : int  2 2 2 2 1 1 1 2 2 2 ...\n $ Sports          : int  1 1 1 1 1 1 1 1 1 1 ...\n $ Anger.Out       : int  18 14 13 17 16 16 12 13 16 12 ...\n $ Anger.In        : int  13 17 14 24 17 22 12 16 16 16 ...\n $ Control.Out     : int  23 25 28 23 26 25 31 22 22 29 ...\n $ Control.In      : int  20 24 28 23 28 23 27 31 24 29 ...\n $ Anger_Expression: int  36 30 19 43 27 38 14 24 34 18 ...\n\nangry$Gender &lt;- as.factor(angry$Gender)\nlibrary(plyr)\nangry$Gender &lt;- revalue(angry$Gender, c(\"1\" = \"male\", \n                                        \"2\" = \"female\"))\nangry$Sports &lt;- as.factor(angry$Sports)\nangry$Sports &lt;- revalue(angry$Sports, c(\"1\" = \"athlete\",\n                                        \"2\" = \"non-athlete\"))\nlibrary(Rmisc)\nanger_summary &lt;- summarySE(angry, measurevar=\"Anger_Expression\", groupvars =\n                               c(\"Sports\", \"Gender\"), na.rm = T)\nlibrary(ggplot2)\nggplot(anger_summary, aes(x=Gender, y=Anger_Expression, color=Sports, \n                                   shape = Sports)) +\n  geom_point(size = 3) +\n  geom_line(aes(group=Sports, linetype =Sports), size=2) +\n  geom_errorbar(aes(ymin=Anger_Expression-ci, ymax=Anger_Expression+ci), size=1.5) +\n  ylab(\"Anger level\")+ \n  xlab(\"Gender\") + \n  scale_shape_discrete(guide=FALSE)+\n  scale_linetype_discrete(guide=FALSE)+\n  ggtitle(\"Anger level among groups\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: The `guide` argument in `scale_*()` cannot be `FALSE`. This was deprecated in\nggplot2 3.3.4.\nℹ Please use \"none\" instead.\n\n\n\n\n\nI first read in and recoded some data for ease and plotting. I then produced a plot to consider the null hypotheses that\n\nthe sport an athlete plays does not influence anger level\nthe gender of an athlete does not influence anger level\nthe sport an athlete plays and their gender do not interact to influence anger level\n\n\nangry_gender &lt;- lm(Anger_Expression ~ Sports * Gender, angry)\nplot(angry_gender)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(angry_gender, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Anger_Expression\n               Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   11200.1  1 71.8690 1.617e-12 ***\nSports          480.1  1  3.0807   0.08336 .  \nGender           17.7  1  0.1135   0.73711    \nSports:Gender     5.2  1  0.0336   0.85505    \nResiduals     11532.2 74                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#remove interaction since not significant\nangry_gender &lt;- lm(Anger_Expression ~ Sports + Gender, angry)\nplot(angry_gender)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(angry_gender, type = \"III\") #only differs among those who play sports\n\nAnova Table (Type III tests)\n\nResponse: Anger_Expression\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 17367.1  1 112.8964 &lt; 2.2e-16 ***\nSports       1357.2  1   8.8227  0.003995 ** \nGender         16.3  1   0.1061  0.745501    \nResiduals   11537.4 75                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI then analyzed the data using factorial ANOVA. The outcome is continuous and both explanatory variables are categorical. The design is also fully randomized. Resildual plots indicated all assumptions were met (there is no pattern in the residuals and they are normally distributed). Analysis shows an insignificant interaction (F1,74=.04, p=.855) between sport and gender, so I removed the interaction term. The reduced model showed anger levels differed among athletes and non-athletes but not by gender. There was no need for post-hoc tests (only 2 levels/groups for each categorial variable.)\n\n\n2\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at http://www.statsci.org/data/oz/ms212.txt With more info at http://www.statsci.org/data/oz/ms212.html. Is there evidence that frequency of exercise (Exercise column) and gender impact change in pulse rate for students who ran (Ran column = 1)?\n\npulse &lt;- read.table(\"http://www.statsci.org/data/oz/ms212.txt\", header = T, \n                    stringsAsFactors = T)\npulse$Exercise &lt;- factor(pulse$Exercise)\nlibrary(plyr)\npulse$Exercise &lt;- revalue(pulse$Exercise, c(\"1\" = \"high\", \n                                            \"2\" = \"moderate\", \n                                            \"3\" = \"low\"))\npulse$Gender &lt;- factor(pulse$Gender)\npulse$Gender &lt;- revalue (pulse$Gender, c(\"1\" = \"male\", \"2\" = \"female\"))\npulse$change &lt;- pulse$Pulse2 - pulse$Pulse1\nchange_summary &lt;- summarySE(pulse[pulse$Ran == 1, ], measurevar=\"change\", groupvars =\n                               c(\"Exercise\", \"Gender\"), na.rm = T)\n\nWarning in qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced\n\nggplot(change_summary, aes(x=Gender, shape = Exercise, color = Exercise,\n                           y=change)) +\n  geom_point(size = 3) +\n  geom_line(aes(group=Exercise, linetype =Exercise), size=2) +\n  geom_errorbar(aes(ymin=change-ci, ymax=change+ci), size=1.5) +\n  ylab(\"Change in pulse \\n (beats per minute)\") +\n  scale_color_discrete(name = \"Exercise level\")+\n  scale_shape_discrete(guide=FALSE)+\n  scale_linetype_discrete(guide=FALSE)+\n  ggtitle(\"Change in pulse does \\n not differ among groups\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\nI first read in and recoded some data for ease and plotting. I then produced a plot to consider the null hypotheses that\n\nexercise level does not influence change in pulse rate\ngender does not influence change in pulse rate\ngender and exercise level do not interact to influence change in pulse rate\n\n\nexercise &lt;- lm(change ~ Gender * Exercise, pulse[pulse$Ran == 1, ])\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Gender * Exercise, data = pulse[pulse$Ran == \n    1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-44.231 -11.300   1.769  10.083  48.444 \n\nCoefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)                     45.000      8.746   5.145 7.44e-06 ***\nGenderfemale                    35.000     23.139   1.513   0.1383    \nExercisemoderate                 9.231     10.573   0.873   0.3879    \nExerciselow                     12.400     12.972   0.956   0.3449    \nGenderfemale:Exercisemoderate  -38.231     24.678  -1.549   0.1292    \nGenderfemale:Exerciselow       -46.844     26.043  -1.799   0.0796 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.42 on 40 degrees of freedom\nMultiple R-squared:  0.0828,    Adjusted R-squared:  -0.03185 \nF-statistic: 0.7222 on 5 and 40 DF,  p-value: 0.6107\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n                 Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)     12150.0  1 26.4739 7.444e-06 ***\nGender           1050.0  1  2.2879    0.1383    \nExercise          496.3  2  0.5407    0.5865    \nGender:Exercise  1488.8  2  1.6220    0.2102    \nResiduals       18357.7 40                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#rerun without interaction\nexercise &lt;- lm(change ~ Gender + Exercise, pulse[pulse$Ran == 1, ])\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Gender + Exercise, data = pulse[pulse$Ran == \n    1, ])\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.99 -14.89   2.23  11.91  45.19 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        50.391      8.273   6.091 2.94e-07 ***\nGenderfemale       -2.738      6.770  -0.404    0.688    \nExercisemoderate    3.603      9.572   0.376    0.708    \nExerciselow         1.155     10.617   0.109    0.914    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.74 on 42 degrees of freedom\nMultiple R-squared:  0.008416,  Adjusted R-squared:  -0.06241 \nF-statistic: 0.1188 on 3 and 42 DF,  p-value: 0.9485\n\nAnova(exercise, type = \"III\") #no significance\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 17532.0  1 37.1019 2.937e-07 ***\nGender         77.3  1  0.1636    0.6879    \nExercise       97.1  2  0.1028    0.9025    \nResiduals   19846.5 42                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nI then analyzed the data using factorial ANOVA. The outcome is continuous and both explanatory variables are categorical. The design is also fully randomized. Residual plots indicated all assumptions were met (there is no pattern in the residuals and they are normally distributed). Analysis shows an insignificant interaction (F2,40=1.2, p=.21) between exercise level and gender, so I removed the interaction term. The reduced model showed neither gender (F1,42=.16, p =.69) or exercise level (F2,42=.1, p=.90) influenced change in pulse rate, so I failed to reject the related null hypotheses.\n\n\n3\nData from Valdez et al 2023 is available @ https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv.\nImport it into to R and\n\ndetermine how the snail grazing and nitrogen levels impact number of flowering shoots(Shoot.density..m2)\nconstruct a plot to showcase your analysis\n\n\nvaldez_2023 &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv\", stringsAsFactors = T)\nshoot_model &lt;-lm( Shoot.density..m2~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\nplot(shoot_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(shoot_model, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Shoot.density..m2\n                           Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)                196608  1 271.0588 1.334e-09 ***\nSnail.Level                 36238  2  24.9804 5.277e-05 ***\nNitrogen.level               4267  1   5.8824    0.0320 *  \nSnail.Level:Nitrogen.level   3100  2   2.1373    0.1607    \nResiduals                    8704 12                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNo interaction, so I can remove or not.\n\nshoot_model_reduced &lt;- update(shoot_model, .~.- Snail.Level:Nitrogen.level)\nAnova(shoot_model_reduced)\n\nAnova Table (Type II tests)\n\nResponse: Shoot.density..m2\n               Sum Sq Df F value    Pr(&gt;F)    \nSnail.Level     45596  2  27.039 1.556e-05 ***\nNitrogen.level  11150  1  13.224  0.002696 ** \nResiduals       11804 14                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nBoth have impacts.\n\nsnail_post_hoc &lt;- glht(shoot_model_reduced, linfct = mcp(Snail.Level = \"Tukey\"))\nsummary(snail_post_hoc)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Shoot.density..m2 ~ Snail.Level + Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nremoval - control snails == 0           50.67      16.76   3.022  0.02306 *  \nsnail addition - control snails == 0   -72.00      16.76  -4.295  0.00201 ** \nsnail addition - removal == 0         -122.67      16.76  -7.317  &lt; 0.001 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nsignificant difference among all snails.\n\nshoot_summary &lt;- summarySE(valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], measurevar = \"Shoot.density..m2\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\"))\nshoot_summary\n\n     Snail.Level Nitrogen.level N Shoot.density..m2        sd        se\n1 control snails     Fertilized 3          256.0000 27.712813 16.000000\n2 control snails        without 3          202.6667  9.237604  5.333333\n3        removal     Fertilized 3          320.0000 16.000000  9.237604\n4        removal        without 3          240.0000 27.712813 16.000000\n5 snail addition     Fertilized 3          165.3333 36.950417 21.333333\n6 snail addition        without 3          149.3333 33.306656 19.229607\n        ci\n1 68.84244\n2 22.94748\n3 39.74620\n4 68.84244\n5 91.78992\n6 82.73832\n\nshoot_summary$Snail.Level &lt;- relevel(shoot_summary$Snail.Level, \"removal\")\nshoot_summary$Snail.Level &lt;- relevel(shoot_summary$Snail.Level, \"uncaged\")\n\n\nggplot(shoot_summary, aes(x=Snail.Level, \n                           y=Shoot.density..m2,\n                           fill=Nitrogen.level)) +\n  geom_col(color=\"black\", position=position_dodge()) +\n  geom_errorbar(aes(ymin=Shoot.density..m2, ymax=Shoot.density..m2+ci), position = position_dodge()) +\n  labs(title=\"Grazing impacts depend on nitrogen levels\",\n       x= \"Grazing level\",\n       y= expression(paste(\"# of shoots/\" ,m^{-2})))\n\n\n\n\n\n\n4\nFind an example of a factorial ANOVA from a paper that is related to your work. Make sure you understand the connections between the methods, results, and graphs. Briefly answer the following questions\n\nWhat was the dependent variable?\nWhat were the independent variables?\nWas the interaction significant?\n\nIf so, how did they interpret findings\nIf not, were the main effects significant?"
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html",
    "href": "content/solutions/5_Contingency_analysis_solutions.html",
    "title": "Compare proportions among groups",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html#overview",
    "href": "content/solutions/5_Contingency_analysis_solutions.html#overview",
    "title": "Compare proportions among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare proportions among groups lecture. ## Examples\nIssue is we often get data in spreadsheet format (expanded/long or wide/summarized, each shown below), but we need to get a vector or matrix for chisq.test and related functions.\n\nThe data\nFollowing the Everest example from class. Assume data is in a dataframe where each row is a group data point.\n\neverest &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\"),\n                      Oxygen = c(\"Used\", \"Used\", \"Not used\", \"Not used\"),\n                      Number = c(1045, 32, 88, 8))\n\nAssume data is in a dataframe where each row is an individual data point.\n\nlibrary(mirt)\n\nWarning: package 'mirt' was built under R version 4.2.3\n\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\neverest_expand &lt;- expand.table(everest)\n\n\n\ntests\nFirst, let’s ask if the same amount of people used or did not use oxygen. WE can use the table command to summarize. Note the chisq.test, by default, assumes each group is equally likely!\n\ntable(everest_expand$Oxygen)\n\n\nNot used     Used \n      96     1077 \n\nchisq.test(table(everest_expand$Oxygen)) \n\n\n    Chi-squared test for given probabilities\n\ndata:  table(everest_expand$Oxygen)\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nDong this with summarized data is actually harder\n\naggregate(Number~Oxygen, everest, sum)$Number\n\n[1]   96 1077\n\nchisq.test(aggregate(Number~Oxygen, everest, sum)$Number) \n\n\n    Chi-squared test for given probabilities\n\ndata:  aggregate(Number ~ Oxygen, everest, sum)$Number\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nBut this is better!\n\nbinom.test(table(everest_expand$Oxygen))\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we wanted to compare to past years where 10% of climbers did not use oxygen? Note table function splits into alphabetical order.\n\nbinom.test(table(everest_expand$Oxygen), p=.1)\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value = 0.04075\nalternative hypothesis: true probability of success is not equal to 0.1\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we want to determine if using oxygen impacts surival?\n\nchisq.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\nWarning in chisq.test(table(everest_expand$Oxygen, everest_expand$Survived)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nIssue (which we’ll address), but note same as\n\nchisq.test(table(everest_expand$Survived, everest_expand$Oxygen))\n\nWarning in chisq.test(table(everest_expand$Survived, everest_expand$Oxygen)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Survived, everest_expand$Oxygen)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 32, 88,  8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nKey is first argument must be all the info. This is different from (incorrect) approach like\n\nchisq.test(everest$Survived,everest$Oxygen)\n\nWarning in chisq.test(everest$Survived, everest$Oxygen): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  everest$Survived and everest$Oxygen\nX-squared = 0, df = 1, p-value = 1\n\n\nThis is comparing split among Survived and not to split (expected) using Oxygen!\nSo order has minimal input with 2 groups. Other test options necessitated by the warning\n\nfisher.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\np-value = 0.01284\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 1.144791 6.826869\nsample estimates:\nodds ratio \n  2.964765 \n\nlibrary(DescTools)\nGTest(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nG = 5.7466, X-squared df = 1, p-value = 0.01652\n\n\nWhat if we added another group? Like Enriched, Regular, None for oxygen.\n\neverest_enriched &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\", \"Y\", \"N\"),\n                      Oxygen = c(\"Regular\", \"Regular\", \"None\", \"None\", rep(\"Enriched\", 2)),\n                      Number = c(1045, 32, 88, 8, 15, 2))\neverest_enriched_expand &lt;- expand.table(everest_enriched)\n\nNow we compare\n\ntable(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\n\n   \n    Enriched None Regular\n  N        2    8      32\n  Y       15   88    1045\n\nchisq.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(table(everest_enriched_expand$Survived,\neverest_enriched_expand$Oxygen)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\nX-squared = 10.879, df = 2, p-value = 0.004343\n\n\nFisher again due to size\n\nfisher.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\np-value = 0.00586\nalternative hypothesis: two.sided\n\n\nNow we follow-up, and rows/columns matter. Note default is row and fdr method. I order results for ease of view\n\nlibrary(rcompanion)\n\nWarning: package 'rcompanion' was built under R version 4.2.3\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n  Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq p.adj.Chisq\n1      N : Y  0.00586      0.00586  0.0189      0.0189 0.00434     0.00434\n\n\nNot quite what we wanted. How about\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1430  0.1080      0.1620  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.2560\n1      1.0000\n\n\nand you can change methods\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\",\n                                                          method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1910  0.1080      0.2160  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.3420\n1      1.0000\n\n\nTo put in manually, we need a few extra things\n\neverest_table &lt;- as.table(matrix(c(2,8,32,15,88,1045), nrow = 2, byrow = T))\nrownames(everest_table) = c(\"N\", \"Y\")\ncolnames(everest_table) = c(\"Enriched\", \"None\", \"Regular\")\neverest_table\n\n  Enriched None Regular\nN        2    8      32\nY       15   88    1045"
  },
  {
    "objectID": "content/solutions/5_Contingency_analysis_solutions.html#lets-practice",
    "href": "content/solutions/5_Contingency_analysis_solutions.html#lets-practice",
    "title": "Compare proportions among groups",
    "section": "Let’s practice",
    "text": "Let’s practice\n\nHeart attacks\n\n1\nLet’s look at some heart attack data. Read in the data using\n\nheart_attacks &lt;- read.table(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/heartatk4R.txt\",header=T, stringsAsFactors = T)\n\nEvery entry is a person that has suffered a heart attack. More information on the dataset can be found at\nhttp://statland.org/Software_Help/DataDesk/datafile.htm\nWe want to again test if heart attacks occur equally across genders.\n\ntable(heart_attacks$SEX)\n\n\n   F    M \n5065 7779 \n\nbinom.test(7779, 7779+5065)\n\n\n    Exact binomial test\n\ndata:  7779 and 7779 + 5065\nnumber of successes = 7779, number of trials = 12844, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.5971385 0.6141184\nsample estimates:\nprobability of success \n             0.6056524 \n\n\nIf I assume males compose 50% of the population, I can test the null hypothesis that 50% of heart attacks occur in males using a binom.test to conduct a binomial test. I used the table command to determine the number of heart attacks in males and females and then used binom.test. The alternative is less than or greater than 50% of hear attacks occur in males. With a p-value of &lt;.001, I reject the null hypothesis. Data suggest that males are more likely to have heart attacks. Note this is better than\n\nchisq.test(table(heart_attacks$SEX), p=c(.50, .50))\n\n\n    Chi-squared test for given probabilities\n\ndata:  table(heart_attacks$SEX)\nX-squared = 573.48, df = 1, p-value &lt; 2.2e-16\n\n\nwhich is an approximate test.\n\nWhat if we know that males actually make up 50.8% of the population?\n\n\ntable(heart_attacks$SEX)\n\n\n   F    M \n5065 7779 \n\nbinom.test(7779, 7779+5065, .508)\n\n\n    Exact binomial test\n\ndata:  7779 and 7779 + 5065\nnumber of successes = 7779, number of trials = 12844, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.508\n95 percent confidence interval:\n 0.5971385 0.6141184\nsample estimates:\nprobability of success \n             0.6056524 \n\n\nNote I can amend the test proportion as noted here. Results do not change.\n\n\n2\nStill using the heart attack data, is survival independent of gender?\n\n#note what this does\ntable(heart_attacks$SEX, heart_attacks$DIED)\n\n   \n       0    1\n  F 4298  767\n  M 7136  643\n\n#then feed it to chisq.test (notice order here does not matter for 2x2 table)\nchisq.test(table(heart_attacks$SEX, heart_attacks$DIED))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks$SEX, heart_attacks$DIED)\nX-squared = 147.76, df = 1, p-value &lt; 2.2e-16\n\nchisq.test(table(heart_attacks$DIED, heart_attacks$SEX))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks$DIED, heart_attacks$SEX)\nX-squared = 147.76, df = 1, p-value &lt; 2.2e-16\n\n\nI used a chi2 to consider if survival was independent of sex. Our null hypothesis is that survival does not differ based on sex. the alternative is that it does. I found a chi21=147.76, which corresponds to a p-value of &lt;.001, so i reject the null hypothesis.\n\n\n3\nFor people that have a heart attack before they turn 30, is survival independent of gender?\n\nchisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                 heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))\n\nWarning in chisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], :\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], heart_attacks[heart_attacks$AGE &lt;     30, \"DIED\"])\nX-squared = 3.2597e-30, df = 1, p-value = 1\n\n#note warning on approximation, so check it\nchisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                 heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))$expected\n\nWarning in chisq.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], :\nChi-squared approximation may be incorrect\n\n\n   \n       0   1\n  F  7.8 0.2\n  M 31.2 0.8\n\n#several &lt;1, so use fisher.test\nfisher.test(table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], \n                  heart_attacks[heart_attacks$AGE &lt;30, \"DIED\"]))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(heart_attacks[heart_attacks$AGE &lt; 30, \"SEX\"], heart_attacks[heart_attacks$AGE &lt; 30, \"DIED\"])\np-value = 1\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 0.006425781         Inf\nsample estimates:\nodds ratio \n       Inf \n\n#so if you are young, no difference\n\nI amended the previous question’s code to only focus on individuals who were under the age of 30 when they suffered a heart. Otherwise the hypotheses remain the same. I attempted to use a chi2 test but was warned the approximation may be incorrect. Remember that no cells can have expected values of &lt;1 and &lt;20% should have expected values &lt;5. Upon checking 2 cells have expected values &lt;1, so I instead used Fisher’s Test.\nI found a p-value of 1, thus I fail to reject the null hypothesis.\n\n\n\nDolphins\n\n4\nData on dolphin behavior was collected off the coast of Iceland. Data is @\nhttp://www.statsci.org/data/general/dolpacti.txt\nSince this is a .txt file, not a .csv, you’ll need to use something like\n\ndolphin &lt;- read.table(\"http://www.statsci.org/data/general/dolpacti.txt\", sep=\"\", header = T, stringsAsFactors = T)\n\nMore info on data @\nhttp://www.statsci.org/data/general/dolpacti.html\nIs traveling independent of time of day? You’ll need to consider traveling vs not traveling due to different number of groups observed in each period. Carry out post-hoc tests if needed.\nI looked at the data and then just made a table manually\n\ndolphin\n\n   Activity    Period Groups\n1    Travel   Morning      6\n2      Feed   Morning     28\n3    Social   Morning     38\n4    Travel      Noon      6\n5      Feed      Noon      4\n6    Social      Noon      5\n7    Travel Afternoon     14\n8      Feed Afternoon      0\n9    Social Afternoon      9\n10   Travel   Evening     13\n11     Feed   Evening     56\n12   Social   Evening     10\n\ntravel_table &lt;- as.table(matrix(c(6, 28+ 38, 6, 9, 14, 9, 13, 66), nrow = 4, byrow = T))\n#Adding in row and column names will make everything easier to read at end.\ncolnames(travel_table) = c(\"travel\", \"not_travel\")\nrownames(travel_table) = c(\"morning\", \"noon\", \"afternoon\", \"night\")\n#now look at it\ntravel_table\n\n          travel not_travel\nmorning        6         66\nnoon           6          9\nafternoon     14          9\nnight         13         66\n\nchisq.test(travel_table)\n\nWarning in chisq.test(travel_table): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  travel_table\nX-squared = 33.665, df = 3, p-value = 2.331e-07\n\n#check outcome given warning\nchisq.test(travel_table)$expected\n\nWarning in chisq.test(travel_table): Chi-squared approximation may be incorrect\n\n\n             travel not_travel\nmorning   14.857143   57.14286\nnoon       3.095238   11.90476\nafternoon  4.746032   18.25397\nnight     16.301587   62.69841\n\nfisher.test(travel_table)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  travel_table\np-value = 9.192e-07\nalternative hypothesis: two.sided\n\nlibrary(rcompanion)\npairwiseNominalIndependence(travel_table, compare = \"row\", method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\n\n           Comparison p.Fisher p.adj.Fisher  p.Gtest p.adj.Gtest  p.Chisq\n1      morning : noon 4.96e-03     1.98e-02 3.94e-03    1.58e-02 4.74e-03\n2 morning : afternoon 7.88e-07     4.73e-06 4.01e-07    2.41e-06 3.65e-07\n3     morning : night 1.49e-01     2.98e-01 1.28e-01    2.56e-01 2.09e-01\n4    noon : afternoon 3.20e-01     3.20e-01 2.07e-01    2.56e-01 3.54e-01\n5        noon : night 7.22e-02     2.17e-01 5.16e-02    1.55e-01 8.35e-02\n6   afternoon : night 6.83e-05     3.42e-04 4.98e-05    2.49e-04 6.88e-05\n  p.adj.Chisq\n1    1.90e-02\n2    2.19e-06\n3    4.18e-01\n4    4.18e-01\n5    2.50e-01\n6    3.44e-04\n\n\nI tested the null hypothesis that traveling is independent of time of day (compared to the alternative hypothesis that it is not, and thus differs aross time periods) using chi2 test. However, a warning and subsequent check indicated too many cells had low expected values, so I instead used a Fisher’s test. A resulting p-value of &lt;.001 led me reject the null hypothesis. Since I was comparing more than two groups, I used a post-hoc test to see which periods were different and found that travel differed between morning and noon, morning and afternoon, and afternoon and night (using the p.adj.Fisher column).\n\n\n\nSmoking\n\n5\nUse data on smoking and exercise from\nhttp://www.r-tutor.com/elementary-statistics/goodness-fit/chi-squared-test-independence\nto determine if smoking is independent of exercise. You’ll need to input data manually. Carry out post-hoc tests if needed.\nI created a table from the data and tested it using a chi2 test to determine if smoking was independent of exercise (null hypothesis) or differed based on exercise levels (alternative). However, a warning led me to see the expected cell values were too small, so I instead used a Fisher’s test.\n\nsmoke &lt;- chisq.test(matrix(c(7, 1, 3, #spacing just for visual use\n                             87,18,84,\n                             12,3,4,\n                             9,1,7), nrow = 4, byrow = T))\n\nWarning in chisq.test(matrix(c(7, 1, 3, 87, 18, 84, 12, 3, 4, 9, 1, 7), :\nChi-squared approximation may be incorrect\n\nsmoke$expected #too small!\n\n          [,1]      [,2]      [,3]\n[1,]  5.360169  1.072034  4.567797\n[2,] 92.097458 18.419492 78.483051\n[3,]  9.258475  1.851695  7.889831\n[4,]  8.283898  1.656780  7.059322\n\nfisher.test(matrix(c(7, 1, 3, #spacing just for visuals\n                     87,18,84,\n                     12,3,4,\n                     9,1,7), nrow = 4, byrow = T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(7, 1, 3, 87, 18, 84, 12, 3, 4, 9, 1, 7), nrow = 4, byrow = T)\np-value = 0.4138\nalternative hypothesis: two.sided\n\n\nA p-value of .4138 meant I failed to reject the null hypothesis."
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#overview",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#overview",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Hypothesis testing starting with binomial tests lecture."
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#hypothesis-testing-and-the-binomial-distribution",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#hypothesis-testing-and-the-binomial-distribution",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Hypothesis Testing and the Binomial Distribution",
    "text": "Hypothesis Testing and the Binomial Distribution\n\nExample\nUsing the bat paper from class (Geipel et al. 2021), let’s consider how to analyze data showing all 10 bats chose the walking over the motionless model.\n\nbinom.test(10,10)\n\n\n    Exact binomial test\n\ndata:  10 and 10\nnumber of successes = 10, number of trials = 10, p-value = 0.001953\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6915029 1.0000000\nsample estimates:\nprobability of success \n                     1 \n\n\nWe use the binom.test function. We only need arguments for # of succeses and # of trials. By default it runs a 2-sided test against a null hypothesis value of p = .5. You can see how to update thee options by looking at the help file.\n\n?binom.test\n\nNote the confidence interval is assymetric since its estimated to be 1! We can see other options using the binom.confint function from the binom package.\n\nlibrary(binom)\nbinom.confint(10,10)\n\n          method  x  n      mean     lower    upper\n1  agresti-coull 10 10 1.0000000 0.6791127 1.043355\n2     asymptotic 10 10 1.0000000 1.0000000 1.000000\n3          bayes 10 10 0.9545455 0.8292269 1.000000\n4        cloglog 10 10 1.0000000 0.6915029 1.000000\n5          exact 10 10 1.0000000 0.6915029 1.000000\n6          logit 10 10 1.0000000 0.6915029 1.000000\n7         probit 10 10 1.0000000 0.6915029 1.000000\n8        profile 10 10 1.0000000 0.7303058 1.000000\n9            lrt 10 10 1.0000000 0.8252466 1.000000\n10     prop.test 10 10 1.0000000 0.6554628 1.000000\n11        wilson 10 10 1.0000000 0.7224672 1.000000\n\n\nAll of these correct for the fact that most intervals use a normal approximation, which as you remember from our earlier discussions is not good when sample sizes are small and/or the p parameter is extreme (close to 0 or 1)."
  },
  {
    "objectID": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#practice",
    "href": "content/solutions/3_Introduction_to_hypothesis_testing_via_binomial_test_solutions.html#practice",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Practice!",
    "text": "Practice!\nMake sure you are comfortable with null and alternative hypotheses for all examples.\n\n1\nAre people eared (do they prefer one ear or another)? Of 25 people observed while in conversation in a nightclub, 19 turned their right ear to the speaker and 6 turn their left ear to the speaker. How strong is the evidence for eared-ness given this data (adapted from Analysis of Biological Data)? * state a null and alternative hypothesis + Ho: proportion of right-eared people is equal to .5 + Ha: proportion of right-eared people is note equal to .5\n\ncalculate a test statistic (signal) for this data\n\n\n19/25 #sample proportion\n\n[1] 0.76\n\n\nThe signal from the data is the proportion of right-eared people 0.76\n\nMake you understand how to construct a null distribution\n\nusing sampling/simulation (code or written explanation)\n\n\n\nsampling_experiment = rbinom(10000, 25, .5)\nhist(sampling_experiment, breaks = 0:25, xlab = \"# of Right-eared people out of 25\", ylab = \"Probability of being drawn \\n from population of p = 0.5\", cex.main = 2, cex.axis = 1.5, cex.lab = 2)\n\n\n\n\n\nby using an appropriate distribution (code or written explanation)\n\n\nusing_distribution = dbinom(0:25,25,.5)\nusing_distribution\n\n [1] 2.980232e-08 7.450581e-07 8.940697e-06 6.854534e-05 3.769994e-04\n [6] 1.583397e-03 5.277991e-03 1.432598e-02 3.223345e-02 6.088540e-02\n[11] 9.741664e-02 1.328409e-01 1.549810e-01 1.549810e-01 1.328409e-01\n[16] 9.741664e-02 6.088540e-02 3.223345e-02 1.432598e-02 5.277991e-03\n[21] 1.583397e-03 3.769994e-04 6.854534e-05 8.940697e-06 7.450581e-07\n[26] 2.980232e-08\n\nsum(using_distribution)\n\n[1] 1\n\nNumber_righteared = c(0:25)\npdf = data.frame(Number_righteared, using_distribution)\nplot(0:25, using_distribution)\n\n\n\n\nEach of these show the expected distribution of signal under the null hypothesis. Note this implies multiple samples are taken. This is theory that underlies NHST (null hypothesis significance testing) and definition of p-value (coming up!).\n\nCalculate and compare p-values obtained using\n\nsimulation (calculation won’t be required on test, but make sure you understand!) (code or written explanation)\n\n\n\nlength(sampling_experiment[sampling_experiment &gt;= 19 | sampling_experiment &lt;= 6])/length(sampling_experiment)\n\n[1] 0.0123\n\n\n\nequations for binomial distribution (code or written explanation)\n\n\n(1-pbinom(18,25,.5)) * 2\n\n[1] 0.0146333\n\n\n\nR functions (required)(code)\n\n\nbinom.test(19,25, p=.5)\n\n\n    Exact binomial test\n\ndata:  19 and 25\nnumber of successes = 19, number of trials = 25, p-value = 0.01463\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.5487120 0.9064356\nsample estimates:\nprobability of success \n                  0.76 \n\n\nNote we can calculate a p-value using the simulated distribution, the actual distribution (which is exact in this case), and the test (which is usign the actual distribution!).\n\nCalculate a 95% confidence interval for the proportion of people who are right-eared\n\n\nlibrary(binom)\nbinom.confint(x=19, n=25, alpha=.05, method=\"all\") #use Agresti-coull \n\n          method  x  n mean     lower     upper\n1  agresti-coull 19 25 0.76 0.5624805 0.8882596\n2     asymptotic 19 25 0.76 0.5925865 0.9274135\n3          bayes 19 25 0.75 0.5854415 0.9037771\n4        cloglog 19 25 0.76 0.5420481 0.8842776\n5          exact 19 25 0.76 0.5487120 0.9064356\n6          logit 19 25 0.76 0.5584422 0.8880044\n7         probit 19 25 0.76 0.5666202 0.8934027\n8        profile 19 25 0.76 0.5724026 0.8967715\n9            lrt 19 25 0.76 0.5724301 0.8968455\n10     prop.test 19 25 0.76 0.5447916 0.8984194\n11        wilson 19 25 0.76 0.5657032 0.8850369\n\n#or\nbinom.confint(x=19, n=25, alpha=.05, method=\"agresti-coull\")\n\n         method  x  n mean     lower     upper\n1 agresti-coull 19 25 0.76 0.5624805 0.8882596\n\n\nOur 95% CI is .562 - .888. Note it does not include .5!\n\nHow do your 95% confidence interval and hypothesis test compare?\n\nThe p-value from all methods are &lt;.05, so I reject the null hypothesis that the proportion of right-eared people is equal to .5. The 95% 5% CI is .562 - .888. Note it does not include .5!\n\n\n2\nA professor lets his dog take every multiple-choice test to see how it compares to his students (I know someone who did this). Unfortunately, the professor believes undergraduates in the class tricked him by helping the dog do better on a test. It’s a 100 question test, and every questions has 4 answer choices. For the last test, the dog picked 33 questions correctly. How likely is this to happen, and is there evidence the students helped the dog?\nMAKE SURE TO THINK ABOUT YOUR TEST OPTIONS\n\n#use sided test as you only care if students helped the dog\nbinom.test(33,100, alternative=\"greater\", p=.25)\n\n\n    Exact binomial test\n\ndata:  33 and 100\nnumber of successes = 33, number of trials = 100, p-value = 0.0446\nalternative hypothesis: true probability of success is greater than 0.25\n95 percent confidence interval:\n 0.2523035 1.0000000\nsample estimates:\nprobability of success \n                  0.33 \n\n\nI chose to use a sided test since the professor wants to know if the students helped the dog.\nI found a p-value of .04, so I reject the null hypothesis that the proportion of correct answers is .25 (what I would expect by chance)."
  },
  {
    "objectID": "content/solutions/1_Getting_used_to_R_solutions.html",
    "href": "content/solutions/1_Getting_used_to_R_solutions.html",
    "title": "Getting used to R",
    "section": "",
    "text": "Overview\nThe focus of this overview is to get you used to tools we will be using in class. Before completing it you should have a basic understanding of using R. We will do an introduction in class (download help file). You should also be comfortable using Rstudio and github (see help file).\n\nRmd basics\nRmd files differ from R files in that they combine regular text with code chunks. This is a code chunk\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nCode chunks combine code with output. When combined with regular text/prose, this makes it easier to produce a range of documents. You set the output in the YAML header (the stuff between the 3 dashes you see at top of this document).\nAfter you write the file, you Knit it to turn the Rmd file into the selected output. Try it now. Note the first time you do this in a project you may be prompted to install a number of packages! If you are using a webservice you may also need to allow pop-ups in your browser. Don’t be surprised if a new window pops up (it should).\n\n\n\nThe knit button turns your .rmd file into other products\n\n\nThe Knit button saves the .Rmd file and renders a new version whose output depends on what you selected in the header. Here we have html_document, so if everything works a preview of a webpage like document should appear. The file also produces a github friendly .md file. This means you should only edit the Rmd file (leave the md and output files alone! They are automatically produced any changes you make there will be overwritten by your next knit).\nWhen you Knit a file, it runs in a totally new R instance. this means anything you only added in your instance (like working in the console) won’t be available. In other words, its the best way to see what a “new” user gets when they use your code.\nhowever, you don’t have to knit the file every time. if you just want to see output, note you can press the green button next to an R chunk.\n\n\n\nThe green arrows just runs the chunk in the console and shows the output\n\n\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nNow we’ll start changing the file to show you how rmarkdown works. First, amend the file by replacing the NAME and DATE spots in the header (top of the file between the — markers) with your name and the real date. Then Knit the file again. You should see your name in the new preview.\nRstudio has a Markdown Quick Reference guide (look under the help tab), but some general notes.\n\nPound/Hashtag signs denote headers\nyou can surround something double asterisks for bold or single asterisks for italics\nlists are denoted by numbers or asterisks at beginning of line (followed by space!)\n\nand can be indented for sublevels\n\nR code can be done inline, but is generally placed in stand-alone chunks\n\nthese will, by default, show the code and output\n\nlots of other options exist!\n\nThe main idea is Rmd files allow you to combine code, text, graphs, etc into multiple outputs that you can share (including with coding illiterate colleagues who just want output).\nTo practice working with Rmd files and R, work through the questions below. You can also get more help with this video\n\n\n\nPractice in R\n\n1\nLet x be defined by\n\nx &lt;- 5:15\n\nTry executing this chunk (in R studio, not the webview) by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter.\nThis will run the code in the Console. You may need to switch to Console (from Rmarkdown) in the lower right window area to see this. The executed code is also displayed in your processed file (hit Knit again to see this!).\nNote running this chunk has added an object named x to the Environment tab area (top right area of screen). But nothing was “returned” in the console. You prove this by typing x in the console. What does it return?\nDetermine what the “:” does! Complete the following sentence:\n\nx &lt;- 5:15\n\nThe : means “create a sequence counting by 1’s from a to b (in a:b)”.\n\n\n2\nNow try to guess the output of these commands\n\nlength(x)\nmax(x)\nx[x &lt; 5]\nx^2\nx[ x &lt; 8 & x &gt; 2]\n\nINSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. Then state what each of these does.\n\nlength(x)\n\n[1] 11\n\nmax(x)\n\n[1] 15\n\nx[x &lt; 5]\n\ninteger(0)\n\nx^2\n\n [1]  25  36  49  64  81 100 121 144 169 196 225\n\nx[ x &lt; 8 & x &gt; 2]\n\n[1] 5 6 7\n\n\nLength of x returns the number of elements in a vector. max returns the highest value. square brackets allows you to return (or work with) only portions of a vector. ^2 squares a value.\n\n\n3\nIs -1:2 the same as (-1):2 or -(1:2)? INSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Then state what each of these does.\n\n-1:2\n\n[1] -1  0  1  2\n\n(-1):2\n\n[1] -1  0  1  2\n\n-(1:2)\n\n[1] -1 -2\n\n\nThe first creates a sequence from -1 to 2 by ones (see question 1). The second does the same. The third creates a sequence from 1 to 2 then applies a negative to it.\n\n\n\nData input, plotting, and tests\nYou can read in a dataset from the internet following this protocol.\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nRun this chunk and note it has added an object named sleep to the environment.\nMake sure you see the object in the environment tab!\nInfo on the dataset is viewable @ http://www.statsci.org/data/general/sleep.html.\n\n4\nHow many rows does the sleep data set have (hint: ?dim)? What kind of data is stored in each variable?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\ndim(sleep)\n\n[1] 62 12\n\n\ndim returns the number of rows and columns (IN THAT ORDER) in a dataframe! So sleep has 62 rows. NOTE: If you look at the .Rmd code here, you can see how to put R output inline (instead of in chunks).\n\nstr(sleep)\n\n'data.frame':   62 obs. of  12 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n\n\nthe str function returns the size of the dataset and the class of each column. Note how we use the the $ notation to select columns.\n\n\n5\nChange the column named BodyWt to Body_weight”* in the sleep dataset.\nADD ANY R CHUNKS YOU USED TO COMPLETE THE TASK.\n\nnames(sleep)[names(sleep) %in% \"BodyWt\"] &lt;- \"Body_weight\"\n\n\n\n6\nProduce a plot of how TotalSleep differs between primates and other species. What is this plot showing?\nNote, as of early 2020 R no longer reads in strings as factors! This means the Primate column, which is full of “Yes”s and “No”s, reads in as words and R doesn’t know how to plot them. There are many ways to handle this. You can modify the read.csv command (add stringsAsFactors = T option), eg*\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nIf you do this, you’ll need to rechange anything you previously updated to the object (like renaming the BodyWt column).\nYou can also modify a single column for the actual object\n\nsleep$Primate &lt;- factor (sleep$Primate)\n\nor for a single command, eg (plot not actually shown!)\n\nplot(BodyWt ~ factor(Primate), data = sleep)\n\nNOTE YOU CAN ADD A PLOT TO THE DOCUMENT TOO! AMEND THE BELOW AS NEEDED.\n\nplot(cars)\n\n\n\n\nAnswer is\n\nplot(TotalSleep ~ Primate, sleep)\n\n\n\n\nor to clean it up (we’ll introduce ggplot2 in a few sessions to help with this)\n\nplot(TotalSleep ~ factor(Primate), sleep, main = \"Variance in sleep differs between primates and non-primates\", \n     xlab = \"Primate\", ylab = \"Total sleep (hours)\")\n\n\n\n\n\n\n7\nThe sleep dataset begs to have a linear model fit for it. Let’s consider. First plot how TotalSleep is explained by BrainWt. Are there any issues with the data? Exclude any outlier and fit a linear model to obtain the p-value for the model (hint: summary()). What does this imply?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\nFirst look for outliers (before fitting a model)\n\nplot(TotalSleep ~ BrainWt, sleep)\n\n\n\n\nWe have few measurements where BrainWt &gt;1000, so let’s exclude those for the model\n\nsleep_fit &lt;- lm(TotalSleep ~ BrainWt, sleep[sleep$BrainWt&lt;1000,])\nsummary(sleep_fit)\n\n\nCall:\nlm(formula = TotalSleep ~ BrainWt, data = sleep[sleep$BrainWt &lt; \n    1000, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.0342 -2.8719  0.1718  2.0426  7.8037 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 12.099991   0.632611  19.127  &lt; 2e-16 ***\nBrainWt     -0.014926   0.003833  -3.894 0.000278 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.021 on 53 degrees of freedom\n  (4 observations deleted due to missingness)\nMultiple R-squared:  0.2224,    Adjusted R-squared:  0.2078 \nF-statistic: 15.16 on 1 and 53 DF,  p-value: 0.0002782\n\n\nWe see a significant (p &lt;.05, don’t worry, we’ll see this later) relationship between BrainWt and TotalSleep, and it appears that TotalSleep decreases as BrainWt increases (note the negative estimate). We can visualize this using\n\nplot(TotalSleep ~ BrainWt, data = sleep[sleep$BrainWt &lt;  1000, ])\nabline(sleep_fit)\n\n\n\n\n\n\n\nEXTRA QUESTIONS\nnot required\n Dow Puffin Matthew Zalewski / CC BY (https://creativecommons.org/licenses/by/3.0)\n\n8\nSometimes data doesn’t have headers (column names),so you have to add them. Download a dataset on alcids (birds like puffins and auklets) from https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv.\nYou’ll need to modify the read.csv function by specifying header = False, then use the names function to name the columns [“year”, “a1_abund”, “NAO”, “a2_abund”, “a3_abund”, “a4_abund”, “a5_abund”, “a6_abund”]. Try it and check your input using the head command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\nalcids &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv\",header = F, stringsAsFactors = T)\nnames(alcids) &lt;- c(\"year\", \"a1_abund\", \"NAO\", \"a2_abund\", \"a3_abund\", \"a4_abund\", \"a5_abund\", \"a6_abund\")\nhead(alcids)\n\n  year a1_abund   NAO a2_abund a3_abund a4_abund a5_abund a6_abund\n1 1954       55 -2.52      100        1        0        8        0\n2 1955       44 -1.73      100        1        0       10        0\n3 1956       50  1.52      100        1        0        7        1\n4 1957      100 -1.02    18000        2       50        8        0\n5 1958        5 -0.37     1000        2       15       10        0\n6 1959      400 -1.54     1500        3      190        6        3\n\n\n\n\n9\nHere’s a sample dataset:\n\n\n\nDate\ngreenness\nRichness\nhabitat\n\n\n\n\n12-25-2009\n13766\n46\nforest\n\n\n01-01-2010\n50513\n60\nforest\n\n\n01-15-2010\n25084\n60\ngrassland\n\n\n\nEnter it into R (manually or via a .csv). (Hint: you have a piece of this in the code already). Check your input using the head() command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\nI did this by putting the data in a spreadsheet, saving it as a .csv file, and uploading it. You can see an example spreadsheet at https://docs.google.com/spreadsheets/d/1nOpd6QkJRG8tdn1b-Mmx8AVdwUIFAzzLw3SlJGb_LWA/edit?usp=sharing. From there you can download the file OR publish it to the web as a .csv (look under File &gt; Publish to web in the Google Sheets), and then read in the .csv file to R. Note I used stringAsFactors = T to have the habitat column read in as factors.\n\nexample_sheet &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRsRUBNxda2SEyfti8fAlGLbXjilR1SWYdmkOh1ZEIhadaqwkH6fP9aoWSPgIQEh0dd0isOxONTeAQc/pub?gid=0&single=true&output=csv\",\n                          stringsAsFactors = T)\n\nWarning in read.table(file = file, header = header, sep = sep, quote = quote, :\nincomplete final line found by readTableHeader on\n'https://docs.google.com/spreadsheets/d/e/2PACX-1vRsRUBNxda2SEyfti8fAlGLbXjilR1SWYdmkOh1ZEIhadaqwkH6fP9aoWSPgIQEh0dd0isOxONTeAQc/pub?gid=0&single=true&output=csv'\n\n# so you can see it\nhead(example_sheet)\n\n        Date greenness Richness   habitat\n1 12-25-2009     13766       46    forest\n2 01-01-2010     50513       60    forest\n3 01-15-2010     25084       60 grassland"
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#overview",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#overview",
    "title": "Relationships among numerical variables",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Relationships among numerical variabless lecuture."
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#example",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#example",
    "title": "Relationships among numerical variables",
    "section": "Example",
    "text": "Example\nFollowing the iris dataset from class\n\nlibrary(ggplot2)\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(size = 3) +\n  ylab(\"Sepal Length\")+ggtitle(\"Sepal length increases with petal length\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+\n  xlab(\"Petal length (cm)\") +\n  ylab(\"Sepal length (cm)\")\n\n\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\npar(mfrow = c(2,2))\nplot(iris_regression)\n\n\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\ncor.test(~ Sepal.Length + Petal.Length, data = iris,\n         method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\n\nbootstrap_iris &lt;- Boot(iris_regression)\n\nLoading required namespace: boot\n\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate    2.5 %    97.5 %\n(Intercept)  4.3066034 4.158061 4.4507961\nPetal.Length 0.4089223 0.369235 0.4472371"
  },
  {
    "objectID": "content/practice_problems/8_Relationships_among_numerical_variables.html#practice",
    "href": "content/practice_problems/8_Relationships_among_numerical_variables.html#practice",
    "title": "Relationships among numerical variables",
    "section": "Practice",
    "text": "Practice\n\n1\n\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at\n\nhttp://www.statsci.org/data/oz/ms212.txt\nWith more info at\nhttp://www.statsci.org/data/oz/ms212.html.\nIs there evidence that age, height, or weight impact change in pulse rate for students who ran (Ran column = 1)? For each of these, how much variation in pulse rate do they explain?\n\n\n2\n\n(from OZDASL repository, http://www.statsci.org/data/general/stature.html; reference for more information)\n\nWhen anthropologists analyze human skeletal remains, an important piece of information is living stature. Since skeletons are commonly based on statistical methods that utilize measurements on small bones. The following data was presented in a paper in the American Journal of Physical Anthropology to validate one such method. Data is available @\nhttp://www.statsci.org/data/general/stature.txt\nas a tab-delimted file (need to use read.table!) Is there evidence that metacarpal bone length is a good predictor of stature? If so, how much variation does it account for in the response variable?\n\n\n3\n\nData on medals won by various countries in the 1992 and 1994 Olympics is available in a tab-delimited file at\n\nhttp://www.statsci.org/data/oz/medals.txt\nMore information on the data can be found at:\nhttp://www.statsci.org/data/oz/medals.html\nIs there any relationship between a country’s population and the total number of medals they win?\n\n\n4\n\nContinuing with the Olympic data, is there a relationship between the latitude of a country and the number of medals won in summer or winter Olympics?\n\n\n\n5\n\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\n\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on age or height? If so, how do these factors impact FEV, and how much variance does each explain?\n\n\n6\n\nContinuing with the FEV data, produce plots that illustrate how height, age, and gender each impact FEV."
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html",
    "href": "content/practice_problems/6_Compare_means.html",
    "title": "Compare means among groups",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#overview",
    "href": "content/practice_problems/6_Compare_means.html#overview",
    "title": "Compare means among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture."
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#examples",
    "href": "content/practice_problems/6_Compare_means.html#examples",
    "title": "Compare means among groups",
    "section": "Examples",
    "text": "Examples\nWe will run ANOVA’s using the lm function to connect them to other test. First, build the model\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nThen use the object it created to test assumptions\n\npar(mfrow = c(2,2))\nplot(iris_anova)\n\n\n\n\nIf assumptions are met, check the p-value using the summary or Anova function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_anova, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the overall test is significant, carry out post hoc tests (Tukey shown here for all pairs, as most common)\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033  &lt; 1e-09 ***\nvirginica - setosa == 0        1.582      0.103  15.366  &lt; 1e-09 ***\nvirginica - versicolor == 0    0.652      0.103   6.333 4.79e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nIf assumptions are not met, we can use the Kruskal Wallis non-parametric test and associated post hoc tests.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\nor a bootstrap alternative\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\nFor 2 groups, the boot.t.test function in the MKinfer package is also an option."
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#just-for-practice",
    "href": "content/practice_problems/6_Compare_means.html#just-for-practice",
    "title": "Compare means among groups",
    "section": "Just for practice",
    "text": "Just for practice\n\n1\nUse the iris dataset in R to determine if petal length differs among species. Do this problems using ANOVA, Kruskal-Wallis, and bootstrapping methods. Make sure you can plot the data and carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n\n2\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv.\nAnalyze this data using the t.test function and the lm function to convince yourself that t-tests are special cases of ANOVAs, which are special cases of linear models!"
  },
  {
    "objectID": "content/practice_problems/6_Compare_means.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "href": "content/practice_problems/6_Compare_means.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "title": "Compare means among groups",
    "section": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.",
    "text": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n3\nData on sugar cane yield for multiple fields is available using\nread.table(“https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv”, header = T, stringsAsFactors = T)\nMore info on the data can be found at http://www.statsci.org/data/oz/cane.html. Is there evidence that location (DistrictPosition column) impacts yield (Tonn.Hect column)? If so, which areas are driving this distance?\n\n\n4\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on gender? If so, which gender has the higher FEV score? How much variance does gender explain?\n\n\n5\nThe following data are human blood clotting times (in minutes) of individuals given one of two different drugs.\n\n\n\nDrug B\nDrug G\n\n\n\n\n8.8\n9.9\n\n\n8.4\n9.0\n\n\n7.9\n11.1\n\n\n8.7\n9.6\n\n\n9.1\n8.7\n\n\n9.6\n10.4\n\n\n\n9.5\n\n\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\nUsing rank transform analysis\nUsing a permutation test\nUsing a bootstrap test\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\nUsing rank transform analysis\nUsing a permutation test\nUsing a bootstrap test\n\n\n\n6\n(Example from Handbook on Biological Statistics) Odd (stunted, short, new) feathers were compared in color to typical feathers in Northern Flickers (Colaptes auratus) (Wiebe and Bortolotti 2002) . Data is at\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\nTest the hypothesis that odd and typical feathers did not differ using\n\na Student’s t test and/or lm\na rank test\nbootstrapping\n\nNote we will return to this question next week!"
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html",
    "title": "Tests for continuous data from one sample",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html#overview",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html#overview",
    "title": "Tests for continuous data from one sample",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Tests for continuous data from one sample lecture.\n\nExamples\nFrom lecture! Consider if average height of males training at the Australian Institute of Sport is different than average of human population.\nThese are all one sample tests, but they differ in what we know. If we know the variance of our population, we use a z test (function in BSDA package).\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T)\nlibrary(BSDA)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'BSDA'\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nz.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6, sigma.x=7)\n\n\n    One-sample z-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nz = 14.292, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 184.1474 186.8643\nsample estimates:\nmean of x \n 185.5059 \n\n\nIf we don’t, we use a t-test\n\nt.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059 \n\n\nThese both assume the means of the data are normal! If we want to relax that assumption, we can use the Wilcoxon test (also known as Mann-Whitney test, signed binary transform, or other terms!). This assumes the distribution of means is symmetric.\n\nwilcox.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nV = 5052, p-value = 5.714e-16\nalternative hypothesis: true location is not equal to 175.6\n\n\nor the sign-test/media test.\n\nSIGN.test(sport[sport$Sex == \"male\", \"Ht\"], md = 175.6)\n\n\n    One-sample Sign-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\ns = 90, p-value = 8.882e-16\nalternative hypothesis: true median is not equal to 175.6\n95 percent confidence interval:\n 183.9000 187.4684\nsample estimates:\nmedian of x \n     185.55 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.9406  183.9 187.3000\nInterpolated CI       0.9500  183.9 187.4684\nUpper Achieved CI     0.9629  183.9 187.7000\n\n\nNote this is just transforming data to 1/0 and doing a binomial test!\n\nabove_175.6 &lt;- nrow(sport[sport$Sex == \"male\" & sport$Ht &gt; 175.6,])\nbinom.test(above_175.6, nrow(sport[sport$Sex == \"male\",]))\n\n\n    Exact binomial test\n\ndata:  above_175.6 and nrow(sport[sport$Sex == \"male\", ])\nnumber of successes = 90, number of trials = 102, p-value = 6.125e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.8035103 0.9377091\nsample estimates:\nprobability of success \n             0.8823529 \n\n\nWe can also bootstrap the data.\n\nnumber_of_simulations &lt;- 1000\nlibrary(ggplot2)\nboostrap_data&lt;- sport[sport$Sex == \"male\", \"Ht\"]\nboostrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\niris_bootstrap &lt;-sample(boostrap_data, length(boostrap_data), replace = T)\nboostrap_outcomes$mean[i] &lt;- mean(iris_bootstrap)\nboostrap_outcomes$sd[i] &lt;- sd(iris_bootstrap)\n}\nggplot(boostrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nand find associated quantile-based 95% confidence intervals:\n\nquantile(boostrap_outcomes$mean, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n184.0039 186.9901 \n\n\nor using functions in the boot library\n\nlibrary(boot)\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\nresults &lt;- boot(data=boostrap_data, statistic = function(x, inds) mean(x[inds]),\n   R=number_of_simulations)\nggplot(data.frame(results$t), aes(x=results.t)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means\")),\n       x= \"Mean value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\nquantile( results$t, probs=c(.025, .975) ) \n\n    2.5%    97.5% \n184.0016 187.0236 \n\nboot.ci(results)       \n\nWarning in boot.ci(results): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic         \n95%   (184, 187 )   (184, 187 )  \n\nLevel     Percentile            BCa          \n95%   (184, 187 )   (184, 187 )  \nCalculations and Intervals on Original Scale"
  },
  {
    "objectID": "content/practice_problems/4_Continuous_tests_for_1_population.html#lets-practice",
    "href": "content/practice_problems/4_Continuous_tests_for_1_population.html#lets-practice",
    "title": "Tests for continuous data from one sample",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nRecognizing and assessing normality\n\n1\nUsing the qqplot_example.R code, examine the following distributions and, for the continuous distributions (marked with a “*”), observe how a normal probability plot (qqplot) can be used to visually test for approximate normality.\n\n*Normal (u= 0; σ2= 1, 10, 100)\n*Student’s t (df = 1, 10, 30, & 100)\n*Chi-square (df= 1, 2, 5, 30, 50)\nBernoulli (P=0.1, 0.5, & 0.9)\nBinomial (P=0.05; N= 2, 5, 25, & 50); (P=0.25; N= 2, 5, 25, & 50); (P=0.50; N= 2, 5, 25, & 50); (P=0.75; N= 2, 5, 25, & 50); (P=0.95; N= 2, 5, 25, & 50)\nPoisson ( u= 2, 5, 10, 30, & 50)\n\nFor this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R”)\n\n\n2\nReview the central_limit_theorem.R code (remember\n\nlibrary(VGAM)\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\n\n\nAttaching package: 'VGAM'\n\n\nThe following objects are masked from 'package:boot':\n\n    logit, simplex\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nif you need to convince/remind yourself how common normality of means is for even non-normal data.\n\n\n\nWorking with data (note some sample sizes may be too small for these to all be good ideas!)\nMake sure you are comfortable with null and alternative hypotheses for all examples. You should also feel comfortable graphing the data.\n\n3\nSeven observers were shown, for a brief period, a grill with 161 flies impaled and were asked to estimate the number. The results are given by Cochran (1954). Based on five estimates, they were 183.2, 149.0, 154.0, 167.2, 187.2, 158.0, and 143.0. Test the null hypothesis that the mean of the estimates is 161 flies.\n\nAssuming variance = 275\nEstimating the variance from the data\nUsing rank transform analysis\nUsing binary transform analysis\n\nNote there are several ways to load the data! You can make a list (since the list is short):\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0 )\n\nor make a dataframe in a spreadsheet software (eg, Excel, Google Sheets) and then upload using a read.csv command. We did this in your introduction to R!\n\n\n4\nYields of 10 strawberry plants in a uniformity trial are given by Baker and Baker (1953) as 239, 176, 235, 217, 234, 216, 318, 190, 181, and 225 g. Test the hypothesis that µ = 205 * Assuming variance = 1500 * Estimating the variance from the data * Using rank transform analysis * Using binary transform analysis\n\n\n5\nEvolutionary geneticists predicts the family sex ratio will be 80% female in broods of eagles that successfully fledge &gt;3 young. Nests that fledge 3 or more chicks are very rare but a sample of 30 chicks are obtained from such nests and they yield 25 females and 5 males. Test the hypotheses that that: * a) the sex ratio is 50% females * b) the sex ratio is 80% females.\n\n\n6\nStudies of flying snakes have led researchers to posit the mean undulation rate is 1.4 Hz. You wish to test this hypothesis using the small sample of undulation rates shown below. Create a small dataset of the paradise tree snake undulation rates and choose and justify a test you can use to assess the data.\nUndulation rates (in Hz): 0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6\n\n\n7\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques. Data at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)"
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html",
    "title": "Estimation and ggplot2",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#overview",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#overview",
    "title": "Estimation and ggplot2",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Estimation lecture and the use of ggplots (lots of ggplot2 example code in the Summarizing data lecture\n\nggplot2 basics\nggplot2 is a great plotting package that allows a lot of control over your output. Let’s do some examples using the sleep dataset that we left off with last week. Load the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nggplot2 works in layers so you can or subtract as needed. Provided code is verbose here so you can see what its doing. First, install and call the package.\n\nlibrary(ggplot2)\n\nTo make a plot, first set a base layer using the ggplot function.\n\ndreaming_sleep_relationship &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming))\n\nHere we are naming a dataframe to use (first argument), then noting which columns to use for the x and y axis (under the aes argument, stands for aesthetics).\nNote when we do this we get a blank graph (if we name the ggplot output, we have to call it to see it!)\n\ndreaming_sleep_relationship\n\n\n\n\nNext we add data layers using geom_ commands. Let’s start with a scatter plot, which we make using the geom_point command.\n\ndreaming_sleep_relationship_scatter &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming)) + \n  geom_point()\n\nAgain, nothing is shown, but not the object is saved! We can call it\n\ndreaming_sleep_relationship_scatter\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can also just call it directly, but when/if we do this the object is not saved in the environment.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point()\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIf nothing extra is given, the geom_commands inherit everything from the ggplot command. So here we get a scatter plot of the relationship between TotalSleep and Dreaming. Note the axis labels are the column titles, which may not be what we want in the end in regards to readability.\nHowever, now you have a basic plot. You can also use other arguments in geom_layer commands to add to it. For example, let’s color these by primate\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Primate))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNow we’ve added information on primates. Since that require us to get more data from the dataset, we had to add another aes argument. Note this is different from this (which causes an error1)\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"Primate\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nError in `geom_point()`:\n! Problem while converting geom to grob.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! Unknown colour name: Primate\n\n\nand this\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"blue\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe first causes an error as primate isn’t a color. The second makes all points blue! Also note the 2nd method loses the legend as color now conveys no information.\nIn general, you have to put things you want to plot in the aes argument area and anything outside of that changes the entire plot. For example, we can change the size of all points using\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(size = 4)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis is also a good time to talk about renaming factor labels. You may want to change Primate levels to Yes and No for your graph. Lots of ways to do this, but the revalue function in the plyr package is nice (and we’ll use this suite of packages often, same person developed ggplot2, plyr, and reshape)\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\n\nNotice what I did above. I made a new column from an existing one using a name I might want on a legend. Now I can use it in a graph.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nI can also just change the legend title directly or change legend text, but often workign with the dataframe is easier for me.\nIf we wanted the levels of Primate in a different order, we can use the relevel function in the plyr package to set one as the “first” level (and then do this sequentially to get them in the right order if needed). You can also change level orders using the factor or ordered functions for multiple levels at once.\n\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\" )\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFinally, we can use the theme or related functions (like xlab, ylab, ggtitle) to change how the graph looks. Note, all the code here is verbose so you can change as needed, but you rarely need all this.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can also directly change legend title and colours with the scale_ commands\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIn general scale_[whatever you had aes commands]_manual lets you set colors or codes. To see color codes go to this chart\nYou can also facet a graph by another column. For example, I can split the graph I already made by Taxa\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\")) +\n  facet_wrap(~Taxa, ncol = 1)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNotice doing this and having legend may be redundant, so I can remove the legend\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\")) +\n  facet_wrap(~Taxa, ncol = 1) +\n  guides(colour=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nI also added a theme section to change the facet label. All this shows how you are focused on adding or layering levels in ggplot2.\nYou can save the most recent plot directly to your working directory using\n\nggsave(\"Fig1.jpg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nThis is useful when we need to send just an image to someone (or add it to a document). You can also just save using rstudio functionality.\nggplot2 is a great example of needing to undertand basic functionality without having to remember everything. The intro class lecture and accompanying code should help you get started. A few other points that often come up are noted below.\n\n\nHistograms\nFor histograms, you only need one axis (frequency is calculated automatically)\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNote we can just copy our theme info from above and modify as needed (or ggplot2 will largely skip un-needed info). You can also save and name a theme so you don’t have to do all this everytime.\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nFinally, remember you can subset the dataframes you feed to the ggplot functions (or any other function for that matter). For example, let’s just do a histogram of just primate sleep.\n\nggplot(sleep[sleep$Taxa == \"Primate\",], aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNot interesting, but you get the idea.\n\n\nBarcharts and confidence intervals\nEstimating is a key part of statistics and should include the value you are estimating and an estimate of uncertainty. Graphs typically show this using confidence intervals, which rely on samples of means following a normal distribution that we can describe. If we assume the estimate (not the data!) is normally distributed, we can assume things about uncertainty. Namely, we can build a 95% confidence interval around our estimate (meaning the true mean is in the range 95 out of 100 times we create a sample).\nNow’s let do these in R. Confidence intervals are often tied to barcharts. Although these are common in practice, they are not easy by default in R as statisticians don’t love them. That’s because they use a lot of wasted color. I’ll show this in a moments. However, since they are common I’ll show you how to build them.\nLet’s go back to the sleep dataset and consider the average total sleep time speed for each exposure level. First, lets change exposure to factors and label them\n\nstr(sleep) #just a reminder\n\n'data.frame':   62 obs. of  13 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n $ Taxa       : Factor w/ 2 levels \"Primate\",\"Non-primate\": 2 2 2 2 2 2 2 2 2 1 ...\n\nsleep$Exposure &lt;- factor(sleep$Exposure)\n\nCheck levels\n\nlevels(sleep$Exposure)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nand relabel if you want (just for example here)\n\nlevels(sleep$Exposure)&lt;- c(\"Least\",\"Less\", \"Average\", \"More\", \"Most\") \n\nNext, we need to get the average and standard deviation for each group (remember this is tied to the normal distribution!). If we wanted to this by hand, we could do something like thi (let’s just focus on least for an example, and note we have to remove NA data)\n\nmean(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T)\n\n[1] 12.94615\n\n\nThis is our estimate. The standard deviation of this estimate is\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(sleep[sleep$Exposure == \"Least\" & is.na(sleep$TotalSleep) == F, \"TotalSleep\"]))\n\n[1] 0.7833111\n\n\nwhich is equivalent to\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(na.omit(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"])))\n\n[1] 0.7833111\n\n\nWe also call this the standard error of the mean.\nFortunately, we can also do this using a function from the Rmisc package in R, as ggplot2 doesn’t have it built in (maybe because bar charts are a bad idea?).\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nsleep_by_exposure &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Exposure\", na.rm = T)\n\nInspect the table\n\nsleep_by_exposure\n\n  Exposure  N TotalSleep       sd        se       ci\n1    Least 26   12.94615 3.994119 0.7833111 1.613259\n2     Less 13   11.11538 3.957029 1.0974823 2.391209\n3  Average  4    8.57500 1.808084 0.9040419 2.877065\n4     More  5   10.72000 1.663430 0.7439086 2.065421\n5     Most 10    4.19000 1.776670 0.5618323 1.270953\n\n\nNow we can use this summarized data to make a graph that shows uncertainty (95% confidence intervals)\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nNow to show why barplots waste ink. Note we can show the same information with\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\nAll the exta color is nice, but its not really adding anything!"
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#lets-practice",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#lets-practice",
    "title": "Estimation and ggplot2",
    "section": "Let’s practice!",
    "text": "Let’s practice!\nLet’s return to the mammal sleep dataset that we left off with last week (Make sure you did the first assignment!).\nLoad the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nLast time you used the built-in plot functions to do some plots. Let’s replace those with ggplot2 and do some more.\n\n1\nFirst plot how TotalSleep is explained by BrainWt (remember the issues with the data). Use ggplot2 to plot the relationship.\n\n\n2\nNext color code each plot point by whether or not its a primate. In order to do this you can use the Primate column or (following class code) make a new column called Taxa to represent the information (hint:search for “ revalue”). Make sure axes are well-labeled.\n\n\n3\nLet’s work with histograms. * What type of variation do we see in total time spent sleeping? Create a histogram to explore this issue. * Facet the graph you created based on whether or not the animal is a primate (Primate column). * Now only graph the data for primates.\n\n\n4\nDevelop a properly-labeled bar graph with error bars to explore how total sleep changes with * Primate (relabeled as yes/no as Primate/Non-Primate; note there are multiple ways to do this!) – use a 95% confidence interval for the bar * Predation risk (as a factor!) – use 1 standard error for the bar. Note the difference!"
  },
  {
    "objectID": "content/practice_problems/2_Estimates_and_ggplot2.html#estimates-and-certainty-concepts",
    "href": "content/practice_problems/2_Estimates_and_ggplot2.html#estimates-and-certainty-concepts",
    "title": "Estimation and ggplot2",
    "section": "Estimates and Certainty Concepts",
    "text": "Estimates and Certainty Concepts\n\n5\nWhat does a 95% confidence interval mean?\n\n\n6\nTo make sure you understand the ideas of sampling, confidence intervals, and the central limit theorem, review the visualizations produced by UBC:\n\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CLT.htm\n\n\n\n7\nFor this question you’ll need the central_limit_theorem.R script from the code_examples folder. Download it to your computer and open it. Alternatively, go ahead and make a copy of the CUNY-Biostats repository. You won’t have write access but can keep one up-to-date on your machine/cloud (pull occassionally!).\nOnce you get the script, open it in Rstudio (it will be in another tab!). Make sure you have the VGAM library installed (if you open the script n Rstudio, it will likely prompt you at the top). Then use the Source button (next to the Run command we’ve been using for lines or segments). Source runs the entire code at once (similar to knitting an Rmd file) without showing any console output, but graphs and objects are still produced!\nYou can also do this from the web (included here). When you knit the file, output will appear in your final file. However, its nice to know what Source does in general.\n\nlibrary(VGAM)\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nThis script follows the UBC tutorial to show you how well the CLT (central limit theorem) works (and how it functions). This will be useful in coming to understand when you can trust tests based on the normality of means. The script produces output (graphs) that allow you to examine 6 distributions that differ in shape (skewness and kurtosis) and how those traits interact with sample size to influence the normality of means.\nSource it (or look for the graphs produced in your knitted file) and and then review the plots and consider how sample size interacts with the shape of underlying distributions to influence how quickly sample means approach normality. The noted distributions are:\n\nNormal(Z) (0,1) {no Kurtosis / no skewness / no truncation}\nDouble exponential (0,2) {high Kurtosis / no skewness / no truncation}\nUniform(0,1) {moderate Kurtosis / no skewness / double truncation}\nExponential(1,1) {high asymmetric Kurtosis / high skewness / single truncation}\nChi-square(df=4) {low Kurtosis / moderate skewness / single truncation}\nBinomial distribution (p=.7) {discrete distribution]"
  },
  {
    "objectID": "content/getting_started/getting_started.html",
    "href": "content/getting_started/getting_started.html",
    "title": "Before the first class",
    "section": "",
    "text": "Over the course of the semester/reading this book, our (ambitious) goals are to\nTo prepare for our first few lessons"
  },
  {
    "objectID": "content/getting_started/getting_started.html#concept-stuff",
    "href": "content/getting_started/getting_started.html#concept-stuff",
    "title": "Before the first class",
    "section": "Concept stuff",
    "text": "Concept stuff\n\nCheck out the class website\nWatch this video"
  },
  {
    "objectID": "content/getting_started/getting_started.html#tech-stuff",
    "href": "content/getting_started/getting_started.html#tech-stuff",
    "title": "Before the first class",
    "section": "Tech stuff",
    "text": "Tech stuff\n\nGet access to R!. You can make an account at Rstudio cloud (https://rstudio.cloud/). You can also install R (https://cran.r-project.org/) and Rstudio (https://www.rstudio.com/) on your machine, but I strongly recommend starting with Rstudio cloud.\nRstudio cloud is free for up to 25 hours/month, you don’t have to maintain it, and it gives gives a standard install (same on all machines, so your intro/ our training may be smoother). You can also do both. If you need help, videos are at :\n\nDownloading R\nDownloading Rstudio\nMaking a Rstudio cloud account\n\nJoin the github classroom we’ll be using for our sessions\n\nlook for email from Blackboard! \nWhen you visit the page it will ask you to connect or create a github repository. You can use any name (be anonymous or not) that you want. This is a free process.\n\n\n\nOptional (get a head start if you want)\nIt may be easier to open these intructions in a browser so you can follow along there while working in Rstudio!\nAfter you join the github classroom, you’ll make a clone of the repository onto your machine. First, find your copy of the repository. You can follow the github classroom link again, or log into github and then visit https://github.com/settings/repositories. Find the repository called data_science_intro_YOURGITHUBUSERNAME, and click on it. Then follow along below - find instructions for Rstudio cloud or Rstudio desktop depending on your setup.\n\nIf you are using Rstudio cloud…\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio cloud\nLog into your Rstudio cloud account. You’ll see something like this:\n\n\n\nRstudio cloud home screen\n\n\nTo copy a repository, select New Project, New Project from Github repo. Next you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!)\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the field asking for the URL of your github repository.\nNote you may need to enter your github username and password to create the repository.\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!\n\n\nIf you are using RStudio on your desktop (or via a server…anywhere that\nlooks like an RStudio screen)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio desktop\nTo start working on an assignment, open RStudio.\n\n\n\nSelect File &gt; New Project in Rstudio\n\n\nSelect file, new project, Version control. On the next screen select git. If this isn’t available, you may need to install git (free) on your system. You can download it at https://git-scm.com/download/.\nNext you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!).\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the Rstudio Repository URL space. You can select/edit what you want the repository to be called and where its stored (its just a folder on your computer). For example, I have a Repositories folder in my main hard drive where I save all of these. Then select Create project. Whatever you choose, the project will be saved in new folder in that location using the name you chose. Note you may need to enter your github username and password to create the repository.\nYou also may get an error/warning about personal access token! this happens at different points on different machines (thus why Rstudio cloud is nice). If you see this now, don’t worry. We’ll cover it (a known issue) in class.\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!"
  },
  {
    "objectID": "content/end_matter/acknowledgements.html",
    "href": "content/end_matter/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Many thanks to Bill Rice and Steve Gaines at UCSB for encouraging me to continue my interests in statistics.\nMy department at Baruch also supported me when I proposed the Biostatistics (ENV/BIO 2100) course in 2017 and taught for the first time in 2018.\nBaruch College’s Center for Teaching and Learning, as a channel for a statewide funding effort focuse on developed OER (open-educational resources) at CUNY and SUNY campuses, have supported the continued development of the class.\nThe class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!\n\nThis repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/chapters/summarizing_data.html",
    "href": "content/chapters/summarizing_data.html",
    "title": "Summarizing data",
    "section": "",
    "text": "Figure 1: XKCD: Data Trap. It’s important to make sure your analysis destroys as much information as it produces.\nOnce we have some data, the next step is often to summarize it. In fact, we’ve already done that in some ways. Some statistics like the mean may be considered a summary of the data. This may be useful because we prefer large datasets (remember good sampling!), but making sense of a list of numbers can be really hard! Summaries help us describe, and eventually compare, datasets, which we are using to infer something about a population.\nThink about it this way. We want to know if several species of iris (Iris versicolor, setosa and virginica) have similarly-shaped flowers. Since we can’t measure every flower on every plant from these species, we sample several sites and come up with the following data (using R’s built-in iris dataset, a dataset we will often use).\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\nOverwhelming, isn’t it? And this isn’t a huge dataset! There are only 150 rows, yet some datasets have tens of thousands!\nLet’s just look at the first few rows of the data\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\nIt’s really hard (or impossible) to just look at these numbers and infer anything about the population. Summary statistics help us get a better mental image of the distribution of the sample data.\nIt’s really hard (or impossible) to just look at these numbers and infer anything about the population. Summary statistics help us get a better mental image of the distribution of the sample data."
  },
  {
    "objectID": "content/chapters/summarizing_data.html#types-of-data",
    "href": "content/chapters/summarizing_data.html#types-of-data",
    "title": "Summarizing data",
    "section": "Types of data",
    "text": "Types of data\nWe can summarize data using visual (i.e., graphs) or numerical (e.g., summary statistics like the mean) approaches. The specific way we summarize the data also depends on the type of data. Note, the trait we are collecting data on may also be called a variable (since it varies across the population and thus sample).\n\nCategorical variables\nVariables can be categorical (e.g., eye color). If categorical variables have no clear hierarchical relationship (again, like eye color - one isn’t better than the other), then they are nominal variables. If the categories imply a rank or order (e.g., freshmen, sophomore, junior, senior; egg, larvae, pupae, adult) then they are ordinal variables).\n\n\nNumeric variables\nIf data values are based on numbers instead of categories, they are numeric variables. These can be divided into those are count-based (no fractions) - we call these discrete data- and those that can take on any values in a given range - like height. We call these continuous variables."
  },
  {
    "objectID": "content/chapters/summarizing_data.html#graphical-summaries",
    "href": "content/chapters/summarizing_data.html#graphical-summaries",
    "title": "Summarizing data",
    "section": "Graphical summaries",
    "text": "Graphical summaries\nVisual interpretations or displays of your data are an excellent way to let patterns, trends, and distributions easier to see. In this section we’ll go over a number of graphs. Consider this is a resource. I don’t expect you to know how to make each of these on your own immediately. We will actually introduce the software we are using to make these in later sections. Instead, you can return here later when you are actually making a graph for ideas (and code!). For your first read, focus on the images (not the code!)\nWhile the type of graph you should use will depend on the data (and you may have several options!) all graphs should have\n\nDescriptive title\n\nMove beyond Y vs. X. State any patterns you see in the title to help the viewer know what they are looking for! Honest interpretation of data is always paramount, but in producing a graph you will already be making visualization decisions.\n\nLabeled axes (measure and unit)\n\nWhat did you measure, and using what (e.g. Sepal length (cm)\n\nData points\n\nOther parts should only be included when needed.\n\nLegends\n\nOnly needed for graphs with multiple datasets where color, shape, or some other visual cue indicates something to the viewer.\n\nTrendlines\n\nCan be used to show the general/overall relationship between variables. If you use these, make sure to use the right ones! Don’t fit a straight line to a curved relationship!\n\n\n\nSingle variable\n\nNumerical data\n\nHistograms\nOccasionally you only want to show the distribution for a single numerical variable (or how the data themselves are distributed). For example, we could want to display sepal lengths for all the Iris virginica we sampled. We could do this using a histogram.\n\nlabel_size &lt;- 2\ntitle_size &lt;-2.5\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"], \n     main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))), \n     xlab = \"Sepal Length (cm)\", \n     cex.lab=label_size, cex.axis=label_size, cex.main=title_size, \n     cex.sub=label_size, col = \"blue\")\n\n\n\n\nFigure 4: Example of approximately normal data\n\n\n\n\nThe above plot is produced using functions available in all R installs. Many plots now use ggplot2, a package you have to install (don’t worry we’ll get there!). However, since you may come back to this later, I’ll also show how to make each of these graphs using ggplot2.\n\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 5: Example of approximately normal data\n\n\n\n\nHistograms put the data in bins (usually automatically set by software, but you can update!) and then show the number of samples that fell into each bin. This allows a quick estimate (look at the y, or vertical, axis) of how many samples were taken. The above images also allows us to begin to consider the bounds/range of the data (~4.5-8 cm), which gives information on the minimum and maximum values. We can also see lengths around 6-7 cm are most common.\n\n\nWhy do these graphs look slightly different? (Click the grey triangle to see the answer)\n\nMost programs, including R, have autobreak functions to separate the data into bins. Notice ggplot2 uses a different algorithm to bin the data. That also impacts what you see! Users, however, can override these, so it’s worth noting that differences in bin size can influence what distributions look like.\n\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],       main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),       xlab = \"Sepal Length (cm)\",       cex.lab=label_size, cex.axis=label_size, cex.main=title_size,       cex.sub=label_size, col = \"blue\") \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=3, main = \"Sepal length histogram, 3 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")  \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=10, main = \"Sepal length histogram, 10 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")\n\n\n\n\n\n\n\n(a) Auto breaks with R\n\n\n\n\n\n\n\n(b) 10 breaks\n\n\n\n\n\n\n\n(c) 3 breaks\n\n\n\n\nFigure 6: Charts\n\n\n\nA similar issue exists for qualitative data in regards to the categories that are combined/used.\n\nThis distribution of this data is approximately normal. We will define normality more later (equations!), but for now note the distribution is roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate…\nComparing the above graph to other distributions may be an easier approach. Consider these graphs.\n\ncardinals &lt;- round(rbeta(10000,10,2)*50+runif(10000,5,10),3)\nhist(cardinals, main=\"Weight of Westchester cardinals\", xlab = \"\\n Weight (g)\", ylab = \"Frequency (#)\\n\", col = \"red\", cex.lab=label_size, cex.axis=1.25, cex.main=title_size, cex.sub=label_size)\n\n\n\n\nFigure 7: Example of left-skewed data (plot)\n\n\n\n\n\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 8: Example of left-skewed data (ggplot2)\n\n\n\n\n\nparrots&lt;- round(c(rnorm(1000,400,10)),3)\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram( fill=\"green\", color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 9: Example of normal data\n\n\n\n\n\nblue_jays &lt;- round(rbeta(10000,2,8)*100+runif(10000,60,80),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 10: Example of right-skewed data\n\n\n\n\nThe cardinal Figure 8 data has a longer left tail and is not symmetric. We call this left- or negatively-skewed data (since it’s going lower on the x-axis). Compare that to the blue jay Figure 10 data; it has a longer right-tail and is positively- or right-skewed. Again, note this is all relative to symmetric data like you see with the parrots Figure 9, which is normally-distributed data.\nAll symmetric data is not normal, however. Look at the data on robin and woodpecker weights.\n\nrochester &lt;- round(c(runif(1000,75,85)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 11: Example of uniform data\n\n\n\n\n\nwoodpeckers &lt;- round(c(rnorm(100,60,4),rnorm(100,80,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 12: Example of bimodal data\n\n\n\n\nBoth these are roughly symmetric but clearly different from normally-distributed data (we will return to the woodpecker data!). The robin data is what we call uniformly distributed. There are really no tails, as it appears you are just as likely to see any number within the bounds as any other. Kurtosis is the statistical term for what proportion of the data points are in the tails. High kurtosis distributions have heavy tails with multiple outliers. The uniform distibution is an example of a low kurtosis distribution (it has no tails!).\nThis figure may also help.\n\n\n\nFigure 13: English: Plot of several symmetric unimodal probability densities with unit variance. From highest to lowest peak: red, kurtosis 3, Laplace (D)ouble exponential distribution; orange, kurtosis 2, hyperbolic (S)ecant distribution; green, kurtosis 1.2, (L)ogistic distribution; black, kurtosis 0, (N)ormal distribution; cyan, kurtosis −0.593762…, raised (C)osine distribution; blue, kurtosis −1, (W)igner semicircle distribution; magenta, kurtosis −1.2, (U)niform distribution.\n\n\nIf we consider the normal distribution (shown in black) to have 0 kurtosis, the uniform (pink) has less, and the double-exponential (red) has more.\nFigure 13\nFinally, the woodpecker data is what we call bimodal. It is symmetric in this case (not always true!), but it has a two clear peaks instead of a single central or skewed high point in the distribution.\nThese distributions helps us think about what we would expect to find in future samples (remember, we assume we have good samples!). To think about future sampling, we can change our y-axis from what we saw (frequency) to a probability density.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 14: Probability density distribution\n\n\n\n\nThese probability density distributions can be calculated from data (as seen above), but they can also be developed from equations. The benefits of using a distribution derived from an equation is that it is consistent and easy to describe (standardized). This is why many common tests we will learn rely upon the data (or some derivative of it) following a known distribution. For example, many parametric tests will rely upon the data (or means of the data, or errors…we’ll get there) following a normal distribution. We can see our parrot data (which came from a normal distribution!) is very close to a “perfect” normal distribution as define by an equation.\n\nparrots_df &lt;- data.frame(parrots)\ncolors &lt;- c(\"PDF from data\" = \"black\", \"normal curve\" = \"red\")\nggplot(parrots_df, \n       aes(x=parrots)) +\n  geom_histogram(aes(y = ..density..),fill=\"green\", color=\"black\") +\n  geom_density(aes(color=\"PDF from data\"))+\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Density\",\n       color=\"Source\")+\nstat_function(fun = dnorm, args = list(mean = mean(parrots_df$parrots), sd = sd(parrots_df$parrots)), aes(color=\"normal curve\"))+\n      scale_color_manual(values = colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 15: Comparing the distribution of the data to a perfect normal distribution\n\n\n\n\n\n\nBonus question: Why isn’t it perfect? (Click the grey triangle to see the answer!)\n\nThis is an easy example of sampling error!\n\n\n\nBox plots (aka, box and whisker plots)\nAnother way to visualize the distribution of numerical data for a single group is using box-and-whisker plots.\n\nggplot(iris[iris$Species == \"virginica\",],\n            aes(x=Species,y=Sepal.Length)) + geom_boxplot(size = 3) +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"\",\n       y= \"Sepal Length (cm)\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\nFigure 16: Example of approximately normal data\n\n\n\n\nThese plots show the values of the quartiles of the data. In this way they start combining numerical summaries (more to come!) and visual summaries. More to come, but for now imagine you had a 99 data points. If you arrange the data points from smallest to largest, the median of the data would be the middle (50th data point). If you took the bottom half of the data (first data to median), the first quartile would be the middle point (or, in this case, the average of the 25th and 26th data points). Similarly, the third quartile is the middle of the top half of the data set (or, if not one number, average of 75th and 76th data point). Note the median is also the 2nd quartile of the data!\nThe box in the box-and-whisker plot shows the first, second, and third quartiles, also known as the inter-quartile range (IQR). The whiskers extend to the minimum and maximum values of the dataset or, up to values within a set range. In ggplot, whiskers by default can only be as long as 150% of the IQR. This means extreme outliers are shown as individual dots. Typically, the most extreme values (minimum and maximum) plus the first, second, and third quartiles are together called the five number summary.\n\n“Easy” examples of five number summaries\n\nAssume we have data that goes from 1 to 99. The five number summary should be\n\nx &lt;- seq(1:1:99) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    25.5    50.0    50.0    74.5    99.0 \n\n\nNote the 1st and 3rd quartiles are averaged!\nSimilarly, consider the numbers 1-5\n\nx &lt;- seq(1:1:5) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       2       3       3       4       5 \n\n\n\n\n\n\nCategorical data\nFor categorical data, a bar chart fills a very similar role. Note, however, we don’t bin the data., and there is inherent order for some examples (nominal data). For example, we could examine the colors of our I. virginica. To do this, we’ll need to add some data to our iris data (notice this produces no output…)…\n\nset.seed(19)\ncolors &lt;- c(\"blue\", \"orange\", \"purple\")\niris$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\n\nand then summarize it…\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\n\nLoading required package: plyr\n\nI_viriginica_colors &lt;- summarySE(iris[iris$Species == \"virginica\",], measurevar = \"Sepal.Length\",\n                                 groupvars = \"Color\", na.rm = T)\n\nbefore we graph it.\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")))\n\n\n\n\nFigure 17: Distribution of flower colors\n\n\n\n\nOr better\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        col = colors)\n\n\n\n\nFigure 18: Distribution of flower colors (plot)\n\n\n\n\nUsing ggplot2\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 19: Distribution of flower colors (ggplot2)\n\n\n\n\nNote the legend may be superflous here (but consider accessiblity - should we add another distinguishing feature?):\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  guides(fill = \"none\")\n\n\n\n\nFigure 20: Let colors match traits if possible, but note everyone can’t see colors and sometimes they are not printed.\n\n\n\n\n\n\n**Barchart issues**\n\nNote all of the bar graphs above share a similar problem. People tend to like bars, but they are actually just using a lot of ink! We could get the same information about sepal lengths focusing on just the “top” of the bar:\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_freqpoly(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 21: Note you only really know the tops of the bar!\n\n\n\n\nWe can also just display the data!\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Species, y=Sepal.Length)) +\n  geom_point(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\nFigure 22: Displaying the data may be the easiest option for small-ish datasets.\n\n\n\n\n\n\n\n\nMultiple variables\nOften we collect multiple pieces of information instead of just one. This can occur for multiple reasons. We may want to consider differences in some variable/trait among groups. This means we have either numerical or categorical data from various groups, but note that groups themselves are now a piece of data! We can think of these analyses as impact of group (a category) on traits (numerical or categorical). We will eventually call these a t-test or ANOVA (when the trait we measure is categorical) ota \\(\\chi^2\\) test (when the trait is categorical). Either way, this is a case where we are collecting a single piece of data from multiple groups. Alternatively, we may collect data on multiple traits from a single group to see how they impact each other. We will eventually analyze this type of data using regression or correlation. Regardless of type, we can also graph this data.\n\nNumerical variables from multiple groups\nWhen we gather numerical data from various groups and wish to compare, we can extend our use bar charts and box-whisker plots by using shapes, colors, or other features to symbolize the groups. For example, we can illustrate the mean (coming up in numerical summaries) or other summary statistics using bar plots..\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_bar(stat = \"summary\", fun = \"mean\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n{#fig-bar_charts_all species width=672}\n\n\nor the distribution using stacked histograms…\n\nggplot(iris, aes(x=Sepal.Length)) +     geom_histogram(aes(fill=Species))+    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\",        x= \"Species\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n{#fig-stacked_histograms_all species width=672}\n\n\nor box-and-whisker plots.\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_boxplot(aes(fill=Species))+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\", x= \"Species\")\n\n{#fig-box_whisker_all species width=672}\n\n\nWe can also still just display the data for each group…\n\nggplot(iris, aes(y=Sepal.Length, x=Species, color=Species)) +\n  geom_jitter() +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n{#fig-point_all species width=672}\n\n\nWe also need to ensure the different groups are visible when distributions overlap. Sometimes stacked histograms (and similar graphs) make it hard to actually visualize each individual group. One option is to instead facet these graphs. Faceting means we produce different graphs for each group, treatment, etc, but they (typically) share axes. This makes it easier to compare the groups.\n\n ggplot(iris, aes(x=Sepal.Length)) + \n   geom_histogram(aes(fill=Species))+ \n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")+\n   facet_wrap(~Species, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n{#fig-faceted_histograms_all species width=672}\n\n\nAnother option is to show the cumulative frequency distribution for each group.\n\nggplot(iris, aes(Sepal.Length, colour = Species)) + stat_ecdf()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Cumulative frequency\")\n\n\n\n\nFigure 23: Cumulative frequency distributions can be useful in noting exactly where distributions diverge\n\n\n\n\n\n\nCategorical data from multiple groups\nFor our example, let’s return to our focus on the color of flowers for various species of iris. One option for this is to consider bar plots. These can be stacked…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 24: Bar plots are stacked by default and count the number of rows found in each category\n\n\n\n\nor not…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = position_dodge(width=0.5))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 25: Bar plots can also be grouped by adding the position_dodge argument\n\n\n\n\nOther options include divergent plots, but those are best for 2 groups of data. They also require the data to be summarized and somewhat transformed. For example, we could have blue or not blue flowers.\n\nlibrary(plyr)\niris$blue &lt;- revalue(iris$Color, c(\"blue\"=\"blue\", \"purple\"=\"not blue\", \"orange\"=\"not blue\"))\n\nThen we have to summarize the data.\n\niris_summary &lt;- data.frame(table(iris$blue, iris$Species))\nnames(iris_summary) &lt;- c(\"Blue\", \"Species\", \"Frequency\")\n\nand make not blue negative\n\niris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] &lt;- iris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] * -1\n\nthen plot it.\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 26: Divergent plots show how 2 categories differ among groups\n\n\n\n\nwhich we could flip by reversing all x/y arguments..\n\nggplot(iris_summary,aes(y=Species, x=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       y= \"Species\",\n       x= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 27: Reorienting graphs may help viewers better visualize differnces\n\n\n\n\nor using an additional argument (remember, a lot of this is for later reference!)\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\")) +\n  coord_flip()\n\n\n\n\nFigure 28: Note we get the same results by simply adding the argument coord_flip\n\n\n\n\n\n\ngeom_bar vs geom_col\n\ngeom_bar and geom_col are very similar commands, but geom_bar assumes its needs to do something to the data (like count it) by default, whereas geom_col assumes the data are summarized/ready to plot as is. The extra argument stat=identity above can usually make geom_bar behave like geom_col.\n\nIn the above cases, each group was measured the same number of times. However, if this isn’t true, visualizations may confound sampling size with summaries. In those cases, focusing on proportion (explained below!) of outcomes may be more useful (and will give you the exact same visualization if all groups were measured the same number of times!). This is sometimes called a mosaic plot; another way to make them (not shown here) is using the package ggmosaic.\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = \"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Proportion\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 29: For proportion-based visualizations, stacked bar plots may be easier to read than grouped. We just add the position=fill argument to make these.\n\n\n\n\nNote we could also facet this data if we had other variables. For example, assume sampled another set of populations to the west..\n\niris_new &lt;- iris\ncolors &lt;- c(\"pink\", \"orange\", \"yellow\")\niris_new$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\niris_both &lt;- rbind(iris,iris_new)\niris_both$Population &lt;- factor(c(rep(\"East\",nrow(iris)), rep(\"West\", nrow(iris_new))))\n\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\nFigure 30: Faceting can make patterns easier to compare.\n\n\n\n\nNote we can combined these ideas!\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\nFigure 31: We can add facets and proportions.\n\n\n\n\nFinally, we can end this section noting a pie chart is just a transformed bar chart.\n\niris_both$Share &lt;- \"\"\nggplot(iris_both,aes(x=Share)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Distribution of flower colors differ among populations of \",italic(\"I. species \"))),\n       y=\"\", \n       x=\"\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_grid(Population~Species) +\n coord_polar(theta=\"y\") \n\n\n\n\nFigure 32: We can add facets and proportions.\n\n\n\n\n\n\nRelationships among data from a single group\nInstead of collecting data on a single trait from multiple groups, we may collect data on multiple traits from a single group. For example, we could want to see if petal length is related to sepal width in I.virginica. This relationship could be visually summarized using a scatter plot.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length, y=Petal.Length)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\nFigure 33: Scatter plots show relationships among numerical variables.\n\n\n\n\nObviously we can (and will) combine many of the above approaches. For example, we may want to see if relationships among two numerical variables differ among groups (an ANCOVA!).\n\nggplot(iris,\n              aes(x=Sepal.Length, y=Petal.Length, color=Species)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\nFigure 34: We can add facets and proportions\n\n\n\n\nWe’ll get to these later in class, but I just want to note their existence here. Finally, if you are reading this for the first time, don’t worry about the tests (just like the code!). We will explain how all these tests are related when we get there!\nFinally, note data of this type may include time or dates. We’ll use a different dataset to illustrate this.\n\nairquality$Date &lt;-as.Date(paste(airquality$Month, airquality$Day,\"1973\", sep=\"/\"), format =\"%m/%d/%Y\")\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\nFigure 35: Scatter plots can also include temporal data\n\n\n\n\nWe can also add lines…\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  geom_line()+\n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\nFigure 36: Scatter plots can also include lines\n\n\n\n\nWe can even include multiple data sets!\n\nggplot(airquality, aes(x =Date,y =Temp)) + geom_point(aes(col =\"Temp\")) + geom_line(col=\"orange\") + geom_point(aes(y=Wind+50, col = \"Wind speed\")) + scale_y_continuous(sec.axis = sec_axis(~.-50, name = \"Wind (mph)\")) + geom_line(aes(y=Wind+50))+\n     labs(title=\"Environmental measurements over time\", \n       x= \"Date\",\n       y= expression(\"Temperature \" ( degree*F)))\n\n\n\n\nFigure 37: Scatter plots can also include multiple lines\n\n\n\n\n\n\nThere’s more to do and think about!\nThis just scratches the surface of potential ways to visualize data. For example, heatmaps can be used to show location specific data and we can build interactive or animated visualizations. However, the basic principles we’ve examined here should get you started.\nThe different approaches covered here also indicate there a lots way to display data! Whichever approach you use, you should ensure that you represent the data honestly and clearly. Sometimes that means you just display data (points)! You should also always consider possible ways the data/visualization could be misinterpreted and avoid them. Common mistakes include the decision about which baseline should be included. For example, should charts always include 0 on the y-axis? Not including 0 can may small differences appear large. However, including it can make important changes seem insignificant! Consider\n\nsmall_difference &lt;- data.frame(Treatment = c(\"a\",\"b\"), mean=c(37,40))\nlibrary(ggpubr)\n\nWarning: package 'ggpubr' was built under R version 4.2.3\n\n\n\nAttaching package: 'ggpubr'\n\n\nThe following object is masked from 'package:plyr':\n\n    mutate\n\nbp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, fill=Treatment))+\n  geom_bar(stat=\"identity\")\nsp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, color=Treatment))+\n  geom_point()\ncompare &lt;- ggarrange(bp, sp, labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1,common.legend = TRUE, legend=\"bottom\")\nannotate_figure(compare,\n                top = text_grob(\"Including a zero point can make a big difference!\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\nFigure 38: The decision of where to start the y-axis can have major impacts on interpretation\n\n\n\n\nIf this is changes in temperature, option B may be more useful (this could be a normal temperature (37 C) compared to a fever of 104 (40 C). However, if its a difference in a metabolic rate, it may have minor impacts (and thus we choose option A)!\nSimilarly, imagine we collected this data\n\ngood_fit_x &lt;- runif(100, 1, 50) \ngood_fit_y &lt;- rnorm(100,25,2) \ngood_data &lt;- data.frame(source = \"good\", x=good_fit_x, y=good_fit_y) \nbad_fit_x &lt;- runif(10, 20, 30) \nbad_fit_y &lt;- rnorm(10,95,1) \nbad_data &lt;- data.frame(source = \"outlier\", x=bad_fit_x, y=bad_fit_y) \nall_data &lt;- rbind (good_data, bad_data)\n\npoints &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  labs(title=\"Raw data\")\n\npoints_plus_curve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  geom_smooth(se = F) + \n    labs(title=\"Curve fit to data but points shown\")\n\ncurve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_smooth(se = F) +\n    labs(title=\"Only curve\")\ncompare &lt;- ggarrange(points, points_plus_curve, curve, labels = c(\"A\", \"B\", \"C\"),\n          ncol = 2, nrow = 2, common.legend = TRUE, legend=\"bottom\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nannotate_figure(compare,\n                top = text_grob(\"Same data, three visualizations\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\nFigure 39: This would likely indicate\n\n\n\n\nWhereas the raw data (panel A) may suggest some outliers that are concerning, by panel C we have “smoothed” the data and made an interesting pattern. In general, thought must be applied to individual situations regarding visualization style and nuance. Adding information on spread in the data will also help (coming up!)."
  },
  {
    "objectID": "content/chapters/summarizing_data.html#numerical-summaries",
    "href": "content/chapters/summarizing_data.html#numerical-summaries",
    "title": "Summarizing data",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\nWhile visual summaries give us a clearer picture of the data, numerical summaries can help distill a large dataset into several components that can then be analyzed or compared. A key point is we are rarely trying to say if 2 groups are exactly the same or if a trait value is exactly equal to something. Given sampling error, we know its unlikely we would get exactly the same values, and, more importantly, its really rare for 2 groups to be exactly the same. Instead, we are often comparing characteristics of the population data among group or to set values.\n\nCentral tendency\nOne common characteristic of a population is central tendency. Central tendency considers what are common values in a dataset by focusing on the center of the distribution. Mean, or the average or \\(\\mu\\) , is one measure of central tendency. Due to sampling error, we don’t know \\(\\mu\\), but we can estimate it. In general, we use Greek letters to denote the population values and standard(Latin) letters typically denote our estimate (sometimes with added symbols). For example, if we have n data points, our estimate of the mean \\(\\mu\\) is known as \\(\\overline{Y}\\) (read as “y-bar”) is\n\\[\n\\overline{Y} = \\frac{\\sum_{i=1}^{n} n_{i}}{n} \\sim \\mu\n\\]\nwhere \\(\\sim\\) means “approximately”. Other measures of central tendency include the mode (most common data point) or median (middle data point if all data were placed in ascending order (remember box plots!)).\nWhy do we need more than one measure of central tendency? Consider our cardinal data:\n\n# function to calculate mode\nfun.mode&lt;-function(x){as.numeric(names(sort(-table(x)))[1])}\n\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(cardinals), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(cardinals), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(cardinals), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 40: Skew impacts value of and relationships among various measures of central tendency\n\n\n\n\nNote the data is left-skewed. so the mean is pulled towards these outliers. The median may offer a better summary of the actual center. We see similar outcomes with right-skewed data.\n\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(blue_jays), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(blue_jays), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(blue_jays), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 41: Skew impacts value of and relationships among various measures of central tendency\n\n\n\n\nBut with symmetric data, we see the measures of central tendency align more\n\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(parrots), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(parrots), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(parrots), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 42: For symmetric data, measures of central tendency are more aligned.\n\n\n\n\n\n\nWhy is the mode not always on the highest bar?\n\nNote the mode is heavily/totally impacted by data precision and thus can lead to unusual matches with histograms. In our above example, cardinals were measured to 10-3 grams. However, the data was binned to levels of 10-2 grams. Due to this mismatch, the most common measurement of the raw data was 50.102, which occurred 6 times. However, more data points still fell in another bin!\n\nA special case where central tendency may not be the best way to describe a distribution is known as bimodal data. In this case, the distribution shows two, not one, clear peak. Remember the woodpecker Figure 12 data?\n\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram(aes(y=..density..), color=\"black\") +\n  geom_density()+\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Proportion\")+\n    theme_bw()+\n  geom_vline(aes(xintercept=mean(woodpeckers), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(woodpeckers), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(woodpeckers), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 43: Example of bimodal data with various measures\n\n\n\n\nNote the mode is (again) off, but the mean and median also represent uncommon individuals!\n\n\nSpread\nAlong with the central tendency, another set of numerical summaries focus on the spread of the data. In some ways these focus on how much of the data is in the tail (or how heavy the tail is). To illustrate this, consider the Figure 5 data.\n\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 44: Remember this example of approximately normal data?\n\n\n\n\nWe can instead plot the raw data\n\niris$sample &lt;- 1:nrow(iris)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point() +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")\n\n\n\n\nFigure 45: Note x-axis is just sample order!\n\n\n\n\nNow let’s add the mean\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point(color='blue') +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n  annotate(\"text\", label = \"mean\", x = 135, y = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") \n\n\n\n\nFigure 46: Mean shown in blue!\n\n\n\n\nNote the points differ in how far they are from the mean! For example, we could find another species with a very similar mean but different spread of the data.\n\niris_new &lt;- data.frame(Sepal.Length = runif(50,min=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])-.25, max=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.25), Species = \"uniforma\", sample=101:150)\niris_hypothetical &lt;- merge(iris, iris_new, all = T)\nggplot(iris_hypothetical[iris_hypothetical$Species %in% c(\"virginica\", \"uniforma\"),],\n              aes(y=Sepal.Length, x=sample, color=Species))+\n  geom_point() +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" and \", italic(\"uniforma \"), \"arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n    geom_hline(aes(yintercept=mean(iris_hypothetical[iris_hypothetical$Species == \"uniforma\", \"Sepal.Length\"])), color = \"red\")+\n  annotate(\"text\", label = \"I. virginica mean\", x = 135, y = mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") +\n  annotate(\"text\", label = \"I. uniforma mean\", x = 135, y = mean(iris_hypothetical[iris_hypothetical$Species == \"virginica\", \"Sepal.Length\"])-.13, color = \"blue\")+\n  scale_color_manual(values=c(\"blue\", \"red\"))\n\n\n\n\nFigure 47: Similar mean, very different distribution!\n\n\n\n\nThis spread could be quantified in multiple ways. Here we focus on the variance, which is defined as\n\\[\ns^2 = \\frac{\\sum_{i=1}^{n} (Y_{i}-\\overline{Y})^2}{n-1} \\sim \\sigma^2\n\\]\nAgain, the population parameter is \\(\\sigma^2\\), and the estimate is \\(s^2\\). This is effectively the average distance of each point from the mean squared!\n\nsegment_data &lt;- data.frame( x = 101:150, xend = 101:150, y=iris[iris$Species == \"virginica\", \"Sepal.Length\"], yend = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"]) )\nggplot(iris[iris$Species == \"virginica\",],\n              aes(y=Sepal.Length, x=sample))+\n  geom_point(color='blue') +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"), \" arranged by collection order\")),\n       y= \"Sepal length (cm)\",\n       x= \"Collection #\")+\n  geom_hline(aes(yintercept=mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])), color = \"blue\")+\n  annotate(\"text\", label = \"mean\", x = 135, y = mean(iris[iris$Species == \"virginica\", \"Sepal.Length\"])+.13, color = \"blue\") +\n  annotate(\"text\", label = \"square each red line \\n and find average!\", x = 145, y = 7.5 , color = \"red\") + geom_segment(data = segment_data, aes(x = x, y = y, xend = xend, yend = yend), color= \"red\", size = 1.1) \n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nFigure 48: Mean shown in blue!\n\n\n\n\nWhy \\(n-1\\) on the bottom, you might ask? Related reasons focus on degrees of freedom (we’ll get there) and bias. Our estimate of \\(s^2\\) is based on our sample mean. Since the sample mean can, at best, be the population mean, our variance estimate may be biased (too small). Dividing by \\(n-1\\) can be shown to correcthat. Alternatively, we are estimating one parameter from our data (again, \\(\\mu\\)), so we need to remove one degree of freedom from our calculation. However, some programs still \\(n\\) on the bottom. Note this will only really matter when \\(n\\) is small. In short, as another professor once told me, if the difference is based on whether you use \\(n\\) or \\(n-1\\) in your variance calculation, you likely have other problems.\nNote variance has odd (squared) units. If we take the square root of the variance, we get a value called the standard deviation.\n\\[\nstandard\\;deviation = sd= \\sqrt{variance}\n\\]\nThis metric is now in the same units as the mean (\\(\\mu\\)), so we can plot them easily on the same graph! This will become important later, especially when we discuss normal distributions.\n\n\nCoefficient of variation\nThe coefficient of variation, \\(CV\\), is found using the formula\n\\[\nCV = \\frac{s}{Y} * 100\\%\n\\]\nThis scales the variance (spread) of the data by the mean. The \\(CV\\) is unitless and can be used to compare various distributions.\n\n\nOdds and Ends: Quartiles, percentiles, other splits, maximum and minimum\nAs noted above in the discussion of five-number summaries, we can also find the assorted quartiles, minimum, and maximum of a dataset. This can be especially helpful when the mean isn’t a useful measure of central tendency (since variance and \\(CV\\) rely on the estimate of the mean!). For examples, see Figure 7. The original five number summary is\n\nsummary(cardinals)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.68   46.09   50.12   49.21   53.21   59.62 \n\n\nNote that if we shifted the bottom 10% of the values even further left (increasing the skew), the median stays the same, as does the IQR.\n\ncardinals_new &lt;- cardinals\ncardinals_new[cardinals_new &lt; quantile(cardinals_new, probs= .1)] &lt;- cardinals_new[cardinals_new &lt; quantile(cardinals_new, probs= .1)]-.4\n\nggplot(data.frame(cardinals_new), \n       aes(x=cardinals_new)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals (shifted)\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nsummary(cardinals_new)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  16.28   46.09   50.12   49.17   53.21   59.62 \n\n\n\n\n\nFigure 49: Shifted cardinal data\n\n\n\n\n\n\nProportions for categorical data\nFinally, if we have categorical instead of numerical data, we can find the proportion of data in each category. We mentioned this approach when producing mosaic plots. To find a proportion, you count the number of samples that fall in a given group and divided that by the total number sampled. Alternatively, you can assign a score of 0 for values that are not in the focal group and a score of 1 to samples that are - the average of these scores will give you the proportion.\nFor example, earlier we plotted how flower color differed among species and location.\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\nLet’s see where this came from. We can count the number of each color in each species in each population:\n\n\n\n\n  \n\n\n\nThen divide them by the number sampled for each species in each population:\n\nflower_prop_df &lt;- data.frame(prop.table(flower_table, margin = c(\"Population\", \"Species\")))\nnames(flower_prop_df)[4] &lt;- \"Proportion\"\nflower_prop_df$Population_species &lt;- paste(flower_prop_df$Population,flower_prop_df$Species)\nflower_prop_df &lt;- flower_prop_df[order(flower_prop_df$Population_species),]\nrow.names(flower_prop_df) &lt;- NULL\npaged_table(flower_prop_df[,1:4])"
  },
  {
    "objectID": "content/chapters/summarizing_data.html#next-steps",
    "href": "content/chapters/summarizing_data.html#next-steps",
    "title": "Summarizing data",
    "section": "Next steps",
    "text": "Next steps\nNow that we can summarize data, we can begin to connect summaries to statistics (and learn/remember some probability along the way!)."
  },
  {
    "objectID": "content/chapters/Probability.html",
    "href": "content/chapters/Probability.html",
    "title": "Probability",
    "section": "",
    "text": "We’ve already address probability. When we stated the 95% confidence interval means that if we make these intervals from 100 samples that we expect 95 of them to contain the true mean, we are discussing probability. An even easier example is flipping a coin. You probably know there is a 50% chance of a coin landing on heads. That doesn’t mean given flip will be half heads and half tails. Both of these statements refer to likely outcomes if we do something many, many times!"
  },
  {
    "objectID": "content/chapters/Probability.html#what-is-probability",
    "href": "content/chapters/Probability.html#what-is-probability",
    "title": "Probability",
    "section": "What is probability?",
    "text": "What is probability?\nTo put it specifically, the probability of an outcome is its true relative frequency, the proportion of times the event would occur if we repeated the same process over and over again. We can describe the probability if an outcome by considering all the potential outcomes and how likely each is. If we describe all the outcomes, the total probability must be equal to 1 (since frequency is typically measured as a fraction!). Some probability distributions can be described mathematically, others are a list of possible outcomes, and others are almost impossible to solve. The “impossible” ones require simulations, and we will return to this for our introduction to Bayesian analysis.\nThe simplest case is when we focus on outcomes for a single trait that falls into specific categories. These outcomes are often mutually exclusive, meaning only one can happen (like our heads and tails example!), and lead to discrete probability distributions (meaning each outcome has to be a specific value). Another example is rolling a 6-sided die. The die can only land on numbers 1 to 6 (so 2.57 is not an option!).\n\ndie_roll &lt;- data.frame(Number = 1:6, Probability = rep(1/6,6))\ndie_roll$Number &lt;- factor(die_roll$Number)\n\nlibrary(ggplot2)\nggplot(die_roll, aes(x=Number, y= Probability, fill=Number)) +\n  geom_col() \n\n\n\n\nin this example, the probability of rolling a 6 is .167. You may see this written as\n\\[\nP[roll=6]= \\frac{1}{6} \\sim .167\n\\]Obviously when you roll a die you don’t roll .167 of a 6. You roll a 1, 2, 3, 4, 5, or 6. Again, probability refers to the expected outcome over multiple attempts.\nCompare this to a continuous probability distribution, where the outcome can take any value in a given range.\n\nggplot(data = data.frame(x = c(-3, 3)), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), color = \"orange\")+\n  labs(y=\"Probability\", x=\"Outcome\")\n\n\n\n\nHere’s an odd outcome: Since the outcome can take on any value in a given range, the chance of it being a specific value is 0. Think about it this way - for any value you mention, I can zoom in more. For example, if you ask the probability of x in the above graph being equal to 0, we could zoom in to 0.0, or 0.00, or 0.000. At some limit of resolution, the area under the curve (which denotes the probability and would be found using integral calculus, which we won’t do here) would be equal to 0!\nThis may seem like an odd aside, but it is actually very important. It explains why when we will discuss probabilities the probability of an outcome being less than, more than, or between two values in upcoming chapters. For example, we can note (again) that for a normal distribution (what we see above and will (still eventually) define more appropriately) that 67% of the data falls within one standard devation for perfectly (very rare!) normally-distributed data.\n\n#function from https://dkmathstats.com/plotting-normal-distributions-in-r-using-ggplot2/\ndnorm_one_sd &lt;- function(x){\n  norm_one_sd &lt;- dnorm(x)\n  # Have NA values outside interval x in [-1, 1]:\n  norm_one_sd[x &lt;= -1 | x &gt;= 1] &lt;- NA\n  return(norm_one_sd)\n}\n\nggplot(data = data.frame(x = c(-3, 3)), aes(x)) +\n  stat_function(fun = dnorm, n = 101, args = list(mean = 0, sd = 1), color = \"orange\")+\n  labs(y=\"Probability\", x=\"Outcome\") + \n  stat_function(fun = dnorm_one_sd, geom = \"area\", fill = \"purple\")\n\n\n\n\n\nWhat if more than one thing is of importance?\nSometimes we focus on the probability of more than one outcome for a given event. This requires adding or combining probabilities. The first step in doing this is deciding if the outcomes are mutually exclusive. This means they can not occur in the same unit of focus. For example, we could ask the probability of rolling a 1 or a 6, or of being &gt;2 and &lt;-2. In both cases, a single outcome can’t be both of these things, so the outcomes are mutually exclusive. When this is the case, we simply add the probabilities. This is sometimes called the union of two outcomes.\nContrast this with when we want to know the probability of two things occurring that may occur in the same unit. For example, assume our die not only had dots on it, but these dots were a different color. For example, odd numbers were blue and even numbers were red.\n\ncolors &lt;- c(\"blue\" = \"blue\", \"red\" = \"red\")\ndie_roll$Color &lt;- NA\ndie_roll[as.numeric(as.character(die_roll$Number)) %% 2 == 0, \"Color\"] &lt;- \"blue\"\ndie_roll[as.numeric(as.character(die_roll$Number)) %% 2 != 0, \"Color\"] &lt;- \"red\"\nggplot(die_roll, aes(x=Number, y= Probability, fill=Color)) +\n  geom_col() +\n  scale_fill_manual(values = colors)\n\n\n\n\nNow, the probability of rolling any given group of numbers can be found by adding probabilities since the outcomes are mutually exclusive. Same for die color. However, what about the probability of rolling a blue (even) outcome or a 6? Note we can’t simply add these. Why not?\nBecause a single roll can result in a 6 and blue dots! So adding the probability of getting blue dots (.5) and of getting a 6 (.167) will double-count the 6. In other words, there is an an intersection of the possible outcomes. So, the probability of rolling a 6 or blue is equal to\n\\[\nP[roll=blue] + P[roll=6] - P[roll=6 \\ and \\ blue]= \\frac{1}{2} + \\frac{1}{6} -\\frac{1}{6}\n\\]\nThis is sometimes called the general addition principle.\nIf we are measuring multiple outcomes (note this slightly different than the probability of two or more outcomes for a specific event), we need to consider if the events are independent. This means the outcome of one does not influence the outcome of the other. If this is true, the probability of both events occurring can be found by simply multiplying the probability of each (the multiplication rule). For example, consider the probability of flipping a coin twice and seeing a heads followed by a tails. We can write out all the options (T, HH, TH, TT); assuming independence, the probability for each is \\(\\frac{1}{4}\\). We can also say the probability of heads on the first flip is \\(\\frac{1}{2}\\) and the probability of tails on the second flip is \\(\\frac{1}{2}\\); multiplying these yields \\(\\frac{1}{2}\\).\nConsider instead that we roll 2 dice and measure the sum of the rolls. Since one roll does not influence the other, these are independent events. As noted above, we can work out the probability distribution by writing out all possible outcomes:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n*Fi\n\nrst\nDic\ne\n**\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n\n\n\n* Sec\n\nond\nDic\ne\n**\n1\n( 1 ,1)\n( 1 ,2)\n( 1 ,3)\n\n\n*(1\n,\n4\n\n)\n**\n( 1 ,5)\n( 1 ,6)\n\n\n\n2\n( 2 ,1)\n( 2 ,2)\n\n\n*(2\n,\n3\n\n)\n**\n( 2 ,4)\n( 2 ,5)\n( 2 ,6)\n\n\n\n3\n( 3 ,1)\n\n\n*(3\n,\n2\n\n)\n**\n( 3 ,3)\n( 3 ,4)\n( 3 ,5)\n( 3 ,6)\n\n\n\n4\n\n\n*(4\n,\n1\n\n)\n**\n( 4 ,2)\n( 4 ,3)\n( 4 ,4)\n( 4 ,5)\n( 4 ,6)\n\n\n\n5\n( 5 ,1)\n( 5 ,2)\n( 5 ,3)\n( 5 ,4)\n( 5 ,5)\n( 5 ,6)\n\n\n\n6\n( 6 ,1)\n( 6 ,2)\n( 6 ,3)\n( 6 ,4)\n( 6 ,5)\n( 6 ,6)\n\n\n\nNow assume we want to know the probability of the sum of the dice being equal to 5. If we assume independence, the the probability of rolling a sum of 5 (highlighted cells above) is \\(\\frac{4}{36}\\).\nWe could also simulate the outcome\n\nlibrary(reshape2)\nnumber_of_rolls &lt;- 100000\nsum_of_rolls &lt;- data.frame(index = 1:number_of_rolls, Sum = NA)\nfor (i in 1:number_of_rolls){\n  dice_roll_trial &lt;- sample(1:6, size = 2, replace = TRUE)\n  sum_of_rolls$Sum[i] &lt;- sum(dice_roll_trial)\n}\nsum_of_rolls_df &lt;- dcast(sum_of_rolls, Sum ~ \"Probability\", length )\n\nUsing Sum as value column: use value.var to override.\n\nsum_of_rolls_df$Probability &lt;- sum_of_rolls_df$Probability/number_of_rolls\nggplot(sum_of_rolls_df, aes(x=Sum, y=Probability)) +\n  geom_col(fill=\"orange\", color=\"black\") +\n  labs(y=\"Probability\")+\n    scale_x_continuous(breaks = c(2:12))\n\n\n\n\nNotice here we find the probability of rolling a sum of 5 is 0.11041 which is very close to \\(\\frac{4}{36}\\).\nTo find the probability using math, we have to note that the dice rolls are independent. For example, even though we only want a 4 on the second dice if we roll a 1 on the first dice, the roll of the first die does not influence the roll of the second. We should also note the desired outcomes are mutually exclusive. So we can find the probability of each happening and then add them. It’s easy to see how probability can get complicated!"
  },
  {
    "objectID": "content/chapters/Probability.html#conditional-probability",
    "href": "content/chapters/Probability.html#conditional-probability",
    "title": "Probability",
    "section": "Conditional Probability",
    "text": "Conditional Probability\nUnlike our coin example, sometimes a first event occurring does influence the probability of a second event.\n\n\n\nXKCD Conditional Risk: The annual death rate among people who know that statistics is one is six.\n\n\nIn a similar vein, although the risk of shark attack is low, it increases dramatically if you swim in the ocean.\nUnlike our previous examples, we now have 2 events (lets call them A and B), and the probability of both occurring is equal to\n\\[\nP[A \\ and \\ B] = P[A] \\ P[B|A]\n\\]\nwhich can be read as “the probability of A and B occurring is equal to the probability of A multiplied by the probability of B given A occurs”. Note if A and B are independent, this reduces to the multiplication rule.\nWe can extend this by noting\n\\[\nP[A \\ and \\ B] = P[A] \\ P[B|A] \\\\\nP[A \\ and \\ B] = P[B] \\ P[A|B] \\\\\nP[A] \\ P[B|A] = P[B] \\ P[A|B] \\\\\nP[A|B] = \\frac{P[B|A]*P[A]}{P[B]}\n\\]\nThis rule is known as Bayes’ Theorem. We will return to this when we discuss Bayesian analysis, but we can use it here for demonstration.\nFor our lightning example, we could use some (pretend) numbers to understand the risk and Bayes’ Theorem. First, let A be the probability of being outside in a lightning storm. B is then the probability of getting struck by lightning, , and P[B|A] is the probabiity of getting struck by lightning given that you are outside in a lightning storm (hint: it’s much higher than the P[B]).\nHere’s anoher similar (in concept) example. Medical trials are designed to test the effectiveness of drugs or treatments. In these trials, drug efficacy is considered by comparing outcomes in people who receive the drug or treatment compared to those who receive a placebo (such as a sugar pill). Note this only works if participants do not know which group (drug vs placebo) they are in (why?). In a given trial, people who receive the drug recover 60% of the time (or avoid some other adverse outcome). This may seem good, but it’s only relevant when compared to the placebo group. What if people receiving the placebo recovered 80% of the time? Also, if we know the probability of recovering without the drug, we can consider the total probability of recovery. For now, let’s assume that 20% of people who receive the placebo recover.\nWe could use a tree diagram to consider possible options:\n\nlibrary(DiagrammeR)\n\nWarning: package 'DiagrammeR' was built under R version 4.2.3\n\nbayes_probability_tree &lt;- function(prior, true_positive, true_negative, label1 = \"Prior\", \n                                   label2 = \"Complimentary Prior\", label3 = \"True Positive\",\n                                   label4 = \"False Negative\", label5 = \"False Positive\",\n                                   label6 = \"True Negative\") {\n  \n  if (!all(c(prior, true_positive, true_negative) &gt; 0) && !all(c(prior, true_positive, true_negative) &lt; 1)) {\n    stop(\"probabilities must be greater than 0 and less than 1.\",\n         call. = FALSE)\n  }\n  c_prior &lt;- 1 - prior\n  c_tp &lt;- 1 - true_positive\n  c_tn &lt;- 1 - true_negative\n  \n  round4 &lt;- purrr::partial(round, digits = 5)\n  \n  b1 &lt;- round4(prior * true_positive)\n  b2 &lt;- round4(prior * c_tp)\n  b3 &lt;- round4(c_prior * c_tn)\n  b4 &lt;- round4(c_prior * true_negative)\n  \n  bp &lt;-  round4(b1/(b1 + b3))\n  \n  labs &lt;- c(\"X\", prior, c_prior, true_positive, c_tp, true_negative, c_tn, b1, b2, b4, b3)\n  \n  tree &lt;-\n    create_graph() %&gt;%\n    add_n_nodes(\n      n = 11,\n      type = \"path\",\n      label = labs,\n      node_aes = node_aes(\n        shape = \"circle\",\n        height = 1,\n        width = 1,\n        x = c(0, 3, 3, 6, 6, 6, 6, 8, 8, 8, 8),\n        y = c(0, 2, -2, 3, 1, -3, -1, 3, 1, -3, -1))) %&gt;% \n    add_edge(\n      from = 1,\n      to = 2,\n      edge_aes = edge_aes(\n        label = label1\n      )\n    ) %&gt;% \n    add_edge(\n      from = 1, \n      to = 3,\n      edge_aes = edge_aes(\n        label = label2\n      )\n    ) %&gt;% \n    add_edge(\n      from = 2,\n      to = 4,\n      edge_aes = edge_aes(\n        label = label3\n      )\n    ) %&gt;% \n    add_edge(\n      from = 2,\n      to = 5,\n      edge_aes = edge_aes(\n        label = label4\n      )\n    ) %&gt;% \n    add_edge(\n      from = 3,\n      to = 7,\n      edge_aes = edge_aes(\n        label = label5\n      )\n    ) %&gt;% \n    add_edge(\n      from = 3,\n      to = 6,\n      edge_aes = edge_aes(\n        label = label6\n      )\n    ) %&gt;% \n    add_edge(\n      from = 4,\n      to = 8,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 5,\n      to = 9,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 7,\n      to = 11,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) %&gt;% \n    add_edge(\n      from = 6,\n      to = 10,\n      edge_aes = edge_aes(\n        label = \"=\"\n      )\n    ) \n  message(glue::glue(\"The probability of having {label1} after testing {label3} is {bp}\"))\n  print(render_graph(tree))\n  invisible(tree)\n}\n\n#first example\nbayes_probability_tree(prior = 0.5, true_positive = 0.8, true_negative = 0.8, label1 = \"medicine\", label2 = \"placebo\",\n                       label3 = \"cured\", label4 = \"not cured\",\n                       label5 = \"cured\", label6 = \"not cured\")\n\nThe probability of having medicine after testing cured is 0.8\n\n\nThis tree let’s us consider multiple things. We can see the probability of being cured is .5, but 80% of those come from the group receiving medicine (again, the P[being cured|given medicine]). WE could also derive this using Bayes Theorem.\n$$ P[being  cured|medicine] = \\ P[being  cured|medicine] = \\ P[being  cured|medicine] = .8\n$$\nOne more example. Instead of medical trials, let’s focus on medical screenings. These are used to identify patients who have a condition, but there are no perfect tests. A test may give a false positive, meaning it says a condition exists when it does not. A test can also give a false negative, meaning it finds a condition does not exist when it really does. Both of these present issues for patients and explain why series of tests are often used before more invasive procedures are employed.\nFor example, assume a procedure is used to assess skin cancer. This cancer occurs at a frequency of .00021 in the general population. The test is fairly accurate; if a patient has cancer, the screening will correctly identify if 95% of the time. However, the probability of a false positive is .01. Given these numbers, how worried should a person be about a positive test?\nAlthough the test seems to be good, note the prevalence of a false positive is far higher than the prevalence of cancer! This means most positives will likely be false. To quantify this, let A be the probability of cancer and B be the probability of a positive screening. So,\n\\[\nP[A|B] = \\frac{.95 \\ * .00021}{.95 \\ * \\ .0021+.01*.9779} \\\\\nP[A|B] = .169\n\\]\nIn other words, only 17% of people with positive screenings actually have cancer.\nTo show this in a probability tree:\n\nbayes_probability_tree(prior = 0.0021, true_positive = 0.95, true_negative = 0.99, label1 = \"cancer\", \n                       label2 = \"not cancer\",\n                       label3 = \"positive\", \n                       label4 = \"negative\",\n                       label5 = \"positive\", \n                       label6 = \"negative\")\n\nThe probability of having cancer after testing positive is 0.16625"
  },
  {
    "objectID": "content/chapters/Probability.html#related-ideas",
    "href": "content/chapters/Probability.html#related-ideas",
    "title": "Probability",
    "section": "Related Ideas",
    "text": "Related Ideas\nFalse results are integral to the ideas of test specificity and sensitivity Lalkhen and McCluskey (2008). A specific test will yield few false negatives, while a sensitive test will yield few false positives. Put another way (from Lalken & McCluskey (2008): “A test with 100% sensitivity correctly identifies all patients with the disease”, and ” a test with 100% specificity correctly identifies all patients without the disease”. True and false results also impact predictive values.\n\n\n\n\n\n\n\n\n\nCondition\n\n\n\n\n\n\nTest Outcome\nPresent\nAbsent\n\n\nPositive\nTrue Positive\nFalse positive\n\n\nNegative\nFalse negative\nTrue Negative\n\n\n\nSensitivity=\nTrue Positive/ Condition present\nSpecificity =\nTrue negative/\nCondition negative\n\n\n\nThese ideas can also be related to power. We will return to this visualization in future chapters.\n\n\n\nA 3D visualisaion of PPV, NPV, Sensitivity and Specificity. Luigi Albert Maria, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons"
  },
  {
    "objectID": "content/chapters/Probability.html#next-steps",
    "href": "content/chapters/Probability.html#next-steps",
    "title": "Probability",
    "section": "Next steps",
    "text": "Next steps\nNow that we’ve discussed probability, we can move into the wild world of p-values and discuss how they relate to estimation!"
  },
  {
    "objectID": "content/chapters/Introduction.html",
    "href": "content/chapters/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "“Why is statistics a required course for someone who wants to be a dentist/doctor/ nurse?”\nThis is a common question (or at least thought) for many students. I hope to convince you this semester you at least need to understand statistics as part of the scientific method (and you should realize the scientific process informs all those jobs - in fact it can inform any job or task where you are searching for an answer or better method).\nFor example, doctors prescribe medicine to patients, but how do they know these medicines work? Some doctors carry out research, but many rely on published guidelines, which themselves rely on research. So a new drug or treatment is proposed- but who decides it’s worth using? Researchers carry out trials to determine the efficacy of the treatment. In doing this they have to consider how to design an experiment (what do they collect? from whom?) and analyze the resulting data so they can trust the results.\n\n\n\nFigure 1: XKCD: Control Group\n\n\nOther students in our class may be interested in a more environment- or resource management- focused career (e.g., wildlife rehabilitation, carbon mitigation expert, researcher). Regardless of your goal, any question should be informed by this approach. For example,\n\nDoes an environmental factor cause cancer?\nDo potential toxins really harm the enviroment?\nIs organic food really healthier?\nDoes exposing organisms reared in captivity to predator cues lead to more successful releases?\n\nZhu et al. (2023)\n\n\nAt its heart, statistics is about turning data into information that we can use to make decisions or better understand the world around us. Data can come from experiments we are running. This offers a clear connection to field and lab science, and its what we will focus on for most of this class. Data and theories can also be used to develop models that produce output ; this isn’t real-world data, but it offers very useful insight on what we think will happen if something occurs (and something we can test with other field data!). For example, restoration projects may focus on small-scale plots that undergo different restoration protocols. Data produced from monitoring these plots may be used to develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions.\nAbove I used words like know (how do they know these medicines work? )and predict (develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions). While we may use words like these that are related our findings interchangeably at times, its important to note the different. Statistics (and related models) generally give us estimates about how the real world works. Put another way, if we knew everything about the world, we wouldn’t need to use statistics because we wouldn’t need estimates.\nThe reasons we don’t usually know everything include\n\nthe world is complicated (some questions can’t be directly tested)\nit’s not possible to measure everything\n\nBecause of this, statistics is also focused on trying to describe populations of interest or find signals (impacts of treatments, medicines, or restoration practices, for example) amidst the noise (variation in outcomes that are always common!). When considering relationships among variables, noise may occur because there are lots of things impacting the outcome of interest. For example, restoration protocol may impact the trajectory of an oyster reef, but so too may local factors like temperature an and salinity. Noise can also occur because of sampling error - since we don’t measure everything, our estimate of relationship or population traits may be imperfect.\nIn the next session we’ll start to discuss how we can use data to make estimates about a population (and answer questions like what is a population and what are we trying to estimate). However, a final aside to finish this section - we often think about statistics happening after an experiment, survey, or other thing we get data from is finished. However, part of statistics is experimental design! Statistics should inform how you setup an experiment. In fact, the best idea (which seldom happens!) is that you simulate the type of data you expect to get from your experiment and then analyze that before you actually run the experiment. This ensures you are measuring what you need to measure and setting things up correctly! As the famous quote (to statisticians) states,\n\nTo consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of. -Ronald Fisher\n\n\n\n\n\nReferences\n\nZhu, Jennifer, J. Stephen Gosnell, Laila Akallal, and Micah Goltsman. 2023. “Fear Changes Traits and Increases Survival: A Meta-Analysis Evaluating the Efficacy of Antipredator Training in Captive-Rearing Programs.” Restoration Ecology 31 (3): e13674. https://doi.org/10.1111/rec.13674."
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html",
    "href": "content/chapters/Compare_proportions_among_populations.html",
    "title": "Comparing proportions among groups",
    "section": "",
    "text": "Now that we’ve covered hypothesis testing for both discrete and continous data, we’ll extend these ideas to compare differences among groups. In addition considering these differences, the same test we’ll let us consider if proportions follow a given ratio."
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#example-back-to-the-birds",
    "href": "content/chapters/Compare_proportions_among_populations.html#example-back-to-the-birds",
    "title": "Comparing proportions among groups",
    "section": "Example: Back to the birds",
    "text": "Example: Back to the birds\nLet’s return to our bird example Klem (1989). We previously found that purple finches did not strike windows at proportions that might be predicted by population demographics using a binomial test. However, what if instead we wanted to compare the collision rate of old vs young birds among several species?\n\n\n\nCephas, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\n\n\nLet’s start simple and just compare purple finches and dark-eyed juncos.\n[Becky Matsubara from El Sobrante, California, CC BY 2.0 &lt;https://creativecommons.org/licenses/by/2.0&gt;, via Wikimedia Commons&gt;, via Wikimedia Commons] (/images/Dark-eyed_Junco_(Oregon)_(39651044095).jpg){fig-alt=“Dark-eyed Junco (Junco hyemalis), Sobrante Ridge Regional Reserve, Richmond, California.”}\nKlem’s sample of finches totaled 18, with 9 being older (after hatching year). For juncos, 4 of 11 sampled birds were older. We could put this data in a table.\n\n\n\n\nObserved\n\n\n\n\n\n\n\nFinch\nJunco\nRow Totals\n\n\n\n9\n4\n13\n\n\n\n9\n7\n16\n\n\nColumn Totals\n9\n9\nN = 29\n\n\n\nFirst, we could plot our data\n\nbirds_original &lt;- data.frame(Age = c(\"Old\",\"Young\",\"Old\", \"Young\"),\n                      Species = c(\"Junco\", \"Junco\", \"Finch\", \"Finch\"),\n                      Number = c(4, 7, 9, 9))\nlibrary(ggplot2)\nggplot(birds_original, aes(x= Species, y = Number)) +\n  geom_col(aes(fill = Age)) + \n  labs(x=\"Species\", \n       y=\"Frequency\", \n       main =\"Age at collision for juncos and finches\")\n\n\n\n\nGiven the different sampling sizes, a mosaic plot might help in visually comparing ratios.\n\nggplot(birds_original, aes(x= Species, y = Number)) +\n  geom_col(aes(fill = Age), position = \"fill\")+\n    labs(x=\"Species\", \n       y=\"Proportion\", \n       main =\"Age at collision for juncos and finches\")\n\n\n\n\nBefore we test this, we need to decide on an hypothesis. Although both species were predicted to occur at 3:1 ratios in the wild, that’s not what we are considering here. Instead, we want to know if the likelihood of old vs young birds being in our samples differed for the species. Put another way, we are asking if the proportion of young vs old is contingent on species. These tests are often called contingency analysis, and the table we started with may be referred to as a to as a contingency table.\nIf the proportion of old vs young birds differ among species, it could be because the age structure of the focal populations are different or because the birds differ in their relationship to glass at different ages. However, we are still testing a distribution-based parameter.\n\\[\n\\begin{split}\nH_O: p_{finches} = p_{juncos} \\\\  \nH_A: p_{finches} \\neq p_{juncos} \\\\\n\\textrm{ where p is likelihood of sampled bird being older}\\\\\n\\end{split}\n\\]\nPut another way,we want to test if p is independent of species.\n\\[\n\\begin{split}\nH_O: \\textrm{Probability of older bird hitting window is independent of species} \\\\  \nH_A: \\textrm{Probability of older bird hitting window is dependent of species} \\\\  \n\\end{split}\n\\]\nThis formulation is important, because it helps form our predictions under the null hypothesis. What would we expect if p did not differ among species? If age and species were independent, we could expect\n\\[\n\\textrm{Pr[ Old AND Given speciesuse] = Pr[given species] * Pr[Old]}\n\\]\nSince we have 13/29 birds are old, we should expect\n\n\n\n\nObserved\n\n\n\n\n\n\n\nFinch\nJunco\nRow Totals\n\n\n\n18 * 13/29\n11 * 13/29\n13\n\n\n\n18 * 16/29\n11 * 16/29\n16\n\n\nColumn Totals\n9\n9\nN = 29\n\n\n\nIn order to carry out a sampling experiment to consider noise from this expected outcome, we have to determine the p parameter to use for our population. This is because under the null hypothesis, there is only one population- any observed difference is just due to chance!\nHowever, we have an issue - we don’t know p. In our binomial experiment it was set by our null hypothesis. Now we are comparing p among species, but that doesn’t set a population distribution.\nTo fix this, we go back to our normal approximations. We have shown for large sample sizes the binomial distribution follows the central limit theorem, with \\(Np\\) and \\(p\\) both showing a normal distribution.\n\nsample_size=c(\"1\",\"5\",\"10\", \"20\", \"40\", \"80\")\nnumber_of_simulations &lt;- 1000\nsampling_experiment &lt;- setNames(data.frame(matrix(ncol = length(sample_size), nrow = number_of_simulations)), sample_size)\n\nfor(k in 1:length(sample_size)){\nfor(i in 1:number_of_simulations){\nsampling_experiment[i,k] = rbinom(n=1, size=as.numeric(sample_size[k]), prob=.7)\n}\n}\nlibrary(reshape2)\nsampling_experiment_long &lt;- melt(sampling_experiment, variable.name = \"Sample_size\", value.name = \"mean\")\n\nNo id variables; using all as measure variables\n\nsampling_experiment_long$Sample_size &lt;- factor(sampling_experiment_long$Sample_size, levels =c(\"1\",\"5\",\"10\", \"20\", \"40\", \"80\"))\nlevels(sampling_experiment_long$Sample_size) &lt;- paste(\"Sample size of \", levels(sampling_experiment_long$Sample_size))\n\nggplot(sampling_experiment_long,aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=paste(\"Observed number of successes from \", number_of_simulations, \" random draws\"),\n       subtitle = \"Binomial distribution, p=.7\",  \n       x= \"Mean\",\n       y= \"Frequency\")+\n    facet_wrap(~Sample_size, nrow = 2)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nSo, we can replace the binomial distribution in our sampling experiment with a normal population. To use this approach, we estimate a value for p, \\(\\hat{p}\\), from the data, and let\n\\[\n\\begin{split}\n\\mu = Np \\\\\n\\sigma_\\mu =\\sqrt{Np(1-p)}\n\\end{split}\n\\]\nWe then draw only 1 draws this distribution. Why only 1? Because we need to keep the sample sizes the same, so the row and column totals are set! Remember this for a moment. After we draw 1 number, we fill in the rest.\n\nnum_of_simulations &lt;- 10000\nsimulations &lt;- r2dtable(num_of_simulations,c(13,16),c(18,11))\nchi_sq_stats &lt;- data.frame(chisq = rep(NA, num_of_simulations))\nfor(i in 1:num_of_simulations){\nchi_sq_stats$chisq[i] &lt;- chisq.test(matrix(unlist(simulations[i]),nrow=2, byrow=T))$statistic\n}\n\ncolors &lt;- c(\"distribution\" = \"green\", \"simulated data\" = \"orange\")\nggplot(chi_sq_stats, aes(x=chisq)) +\n  geom_histogram(aes(y=..count../sum(..count..), color = \"simulated data\", fill=\"simulated data\")) +\n  labs(y=paste(\"Probability under \", num_of_simulations, \" simulations\", \nsep =\"\"), x=expression(chi^2), color=\"Source\")+guides(fill=F)+\n  scale_color_manual(values = colors)+\n  scale_fill_manual(values=colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOnce we carry out the sampling experiment, we can Z-transform our cell data(because they are normal now!). The results for a single cell would follow a N(0,1) distribution (the Z). If we wanted, we could square these outcomes (which would then follow a \\(\\chi^2\\) distribution, by definition), and, since we have 4 cells, add them. The resulting variate would follow a \\(\\chi^2\\) distribution with 1 degree of freedom (since we drew 1 numbers for the free “cell” in our table). Finally, because of all the p’s above, we could actually rewrite all of this as\n\\[\nV=\\sum_{i=1}^{n}{\\frac{{(Observed-Expected)}^2}{Expected}} \\textrm{where n is number of cells}\n\\]"
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#contingency-analysis-using-the-chi2-test",
    "href": "content/chapters/Compare_proportions_among_populations.html#contingency-analysis-using-the-chi2-test",
    "title": "Comparing proportions among groups",
    "section": "Contingency analysis using the \\(\\chi^2\\) test",
    "text": "Contingency analysis using the \\(\\chi^2\\) test\nThe resulting test is called a \\(\\chi^2\\) test. Note this takes count-based data and uses a continuous distribution to describe it, so it’s an approximate test.\n\nggplot(chi_sq_stats, aes(x=chisq)) +\n  geom_histogram(aes(y=..count../sum(..count..), color = \"simulated data\", fill=\"simulated data\")) +\n  stat_function(fun = dchisq, args = list(df = 1),aes(color =\"distribution\")) +\n  labs(y=paste(\"Probability under \", num_of_simulations, \" simulations\", \nsep =\"\"), x=expression(chi^2), color=\"Source\")+guides(fill=F)+\n  scale_color_manual(values = colors)+\n  scale_fill_manual(values=colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWe can carry out this test in R using the chisq.test function.\nThis function requires a matrix of aggregated values (counts for each cell). Currently we have a data frame (birds). To make this work, we have a few options.\nWe can input the data directly as a matrix, specifying the string, the number of rows and columns, and how we entered the data in regards to rows (remember ?chisq.test)\n\nchisq.test(matrix(c(9,4,9,7), 2, 2, byrow=T))\n\nWarning in chisq.test(matrix(c(9, 4, 9, 7), 2, 2, byrow = T)): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(9, 4, 9, 7), 2, 2, byrow = T)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nIf the data is in wide data frame (meaning more than one measured outcome per row, so measuring the young and old as columns in the data frame) or we make it look like that, we can use the data directly from the data frame. Consider the difference in format. This is long data (one measure per row):\n\nbirds_original\n\n    Age Species Number\n1   Old   Junco      4\n2 Young   Junco      7\n3   Old   Finch      9\n4 Young   Finch      9\n\n\nand this wide\n\nlibrary(reshape2) \nbirds_wide &lt;- dcast(birds_original, Age~Species) \n\nUsing Number as value column: use value.var to override.\n\nbirds_wide\n\n    Age Finch Junco\n1   Old     9     4\n2 Young     9     7\n\n\nWe can make the matrix with wide data\n\nchisq.test(matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2))\n\nWarning in chisq.test(matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(birds_wide$Junco, birds_wide$Finch), nrow = 2)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nFor our 2x2 table, notice the order of input does not matter (because it wouldn’t impact the expected values. Consider\n\nchisq.test(matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2))\n\nWarning in chisq.test(matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(birds_wide$Finch, birds_wide$Junco), nrow = 2)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nUsing cbind is also an option.\n\nchisq.test(cbind(birds_wide$Finch, birds_wide$Junco))\n\nWarning in chisq.test(cbind(birds_wide$Finch, birds_wide$Junco)): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  cbind(birds_wide$Finch, birds_wide$Junco)\nX-squared = 0.11002, df = 1, p-value = 0.7401\n\n\nAs long as we specify the table, we are ok. Note each of these tests notes 1 df. The degrees of freedom associated with this test are based on the number of free cells (or, alternatively, the number of cells minus the parameters you had to fill in!). This typically can be calculated as (# of columns -1)*(# of rows -1). They each also note a p-value greater than .05. This would suggest we should fail to reject the null hypothesis.\nEach result also tells you this is an approximation (as we already noted!). Since the test is approximate, by default R applies Yate’s continuity correction to data focused on 2x2 tables. Some argue this correction is too strict, and you can turn it off in R (correct=F argument). You can also choose to simulate the outcome instead (simulate.p.value = T), but note this will still be an approximate answer since we can’t do every single sample.\nThe output also indicate the results may be incorrect? Why? In order for our normal approximation to work, we need large samples and a \\(\\hat{p}\\) that is not near 0 or 1. Together, these mean our expected values for most cells (actually, &gt;80%) can not be less than 5., and no cell can have an expected value of less than 1. If these assumption are not met(or are close), R will warn us. We can check expected values using\n\nchisq.test(matrix(c(9,4,9,7), 2, 2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(9, 4, 9, 7), 2, 2, byrow = T)): Chi-squared\napproximation may be incorrect\n\n\n         [,1]     [,2]\n[1,] 8.068966 4.931034\n[2,] 9.931034 6.068966\n\n\nIn this case, 25% of the cells (1/4) has an expected value of less than 5."
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#other-options",
    "href": "content/chapters/Compare_proportions_among_populations.html#other-options",
    "title": "Comparing proportions among groups",
    "section": "Other options",
    "text": "Other options\n\nFisher’s test\nIf this is the case for a 2x2 table, we can use a Fisher’s test instead\n\nfisher.test(matrix(c(9,4,9,7), 2, 2, byrow=T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(9, 4, 9, 7), 2, 2, byrow = T)\np-value = 0.7021\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  0.2997173 11.0799590\nsample estimates:\nodds ratio \n  1.716435 \n\n\nAs opposed to resampling from a null distribution, Fisher’s test considers all (or lots) of ways the data could be re-arranged (or permuted) and then computes a p-value using that approach. This means Fisher’s test works for any sample size. It is an exact test if all possible combinations are considered (but they rarely are).\nNotice the output reports the odds ratio. This ratio is found by dividing odds in one group by odds in another (thus a ratio). Odds are the probability of one outcome over another. For our data, this could be considered (old/young(finches)) divided by (old/young(juncos)), (9/9)/(4/7)=63/36. This is close to what we saw in the output; slight differences occur since the fisher.test function returns a conditional estimate of the odds ratio.\nNote odds differ from relative risks, which compare the probability of an event occurring (or not) among 2 groups. The results are similar for rare events (think about why!) but not for common events. For more, see Altman, Deeks, and Sackett (1998) Davies, Crombie, and Tavakoli (1998) or this [video and paper]{https://www.bmj.com/content/348/bmj.f7450}(target=“_blank”) Grant (2014).\n\n\nG test\nAnother option, the G test, uses a slightly different approach as well. Instead of resampling, the test uses likelihood to compare outcomes. Likelihood asks how likely we were to observed a given set of data given parameter values.\nFor an easy example of likelihood, let’s go back to a one-sample example and focus on just our new finch data. We have 9 old and 9 young birds, so we have a signal of .5 for p. We can use likelihood to calculate how likely our data was under multiple values of p (ranging from 0 - 1, the only options here) and compare the likelihood of those outcomes White (n.d.).\n\n\n\n\n\nSimilar to calculating sum square errors from models, what is most likely is what we saw, but we know there is always noise in the data. Thankfully, it turns out the ratio of likelihood values follow a \\(\\chi^2\\) distribution and can thus provide a p-value to compare possible models. We will return to likelihood-based approaches later, in fact, as they can be used for any dataset we can generate a model for and can be used to compare multiple models.\nFor our current contingency analysis, we can develop a model where a species parameter impacts the likelihood and one where it does not (not fully shown here, but shown by Patrone (2022)).\nThe GTest function from the DescTools package to employ this test.\n\nlibrary(DescTools)\nGTest(x = matrix(c(9,7,9,4), 2, 2, byrow = T))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  matrix(c(9, 7, 9, 4), 2, 2, byrow = T)\nG = 0.51774, X-squared df = 1, p-value = 0.4718"
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#what-about-more-than-2-groups",
    "href": "content/chapters/Compare_proportions_among_populations.html#what-about-more-than-2-groups",
    "title": "Comparing proportions among groups",
    "section": "What about more than 2 groups?",
    "text": "What about more than 2 groups?\nThese ideas can be extended to compare more than 2 groups with a few important caveats.\n\nThe Fisher test is even less exact since all permutations of the data can seldom be explored\nMore importantly, if we reject the null hypothesis we need to do follow-up tests.\n\nLet’s explore this idea with the Klem data. In addition to considering impacts of age, Klem also recorded the sex (coded as male/female) for each bird. He had data on 4 species.\n\n\n\n\nObserved\n\n\n\n\n\n\n\n\nFinch\nJunco\nRobin\nCardinal\n\n\n\n6\n5\n7\n7\n\n\n\n12\n7\n11\n3\n\n\n\nWe can use the same approaches to test this.\n\nchisq.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow =\nT)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\nX-squared = 3.7909, df = 3, p-value = 0.2849\n\n\nNote our sample size is still a potential issue, but only 1/8 cells has a predicted value less than 1.\n\nchisq.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow =\nT)): Chi-squared approximation may be incorrect\n\n\n          [,1]     [,2]      [,3]     [,4]\n[1,]  7.758621 5.172414  7.758621 4.310345\n[2,] 10.241379 6.827586 10.241379 5.689655\n\n\nwhich means the approximation is fine. We could use the other tests if we preferred.\n\nfisher.test(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\np-value = 0.2941\nalternative hypothesis: two.sided\n\nGTest(matrix(c(6,5,7,7,12,7,11,3), nrow=2, byrow=T))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  matrix(c(6, 5, 7, 7, 12, 7, 11, 3), nrow = 2, byrow = T)\nG = 3.8087, X-squared df = 3, p-value = 0.2829\n\n\nRegardless, we see all p&gt;.05. What does this mean?\n\nPost-hoc comparisons: Controlling for the FWER\nWhen we compared one group to a set value or two groups to each other, this was easy: it meant our focal parameter was the same between the groups or between expected and observed values. For more than 2 groups, it means the parameters is also means the parameter of interest does not differ among the groups. In other words, our null hypothesis is\n\\[\nH_O: p_{finch} = p_{junco} = p_{cardinal} = p_{robin}\n\\]\nwhere p is the proportion of the population that are males. Here, this means all species have similar male/female ratios (at least given our samples). This is an example of a very useful insignificant result. This study would have been interesting regardless of outcome.\nHowever, let’s imagine we had data on another species (catbirds in the table below).\n\n\n\n\nObserved\n\n\n\n\n\n\n\n\n\nFinch\nJunco\nRobin\nCardinal\nCatbird\n\n\nMale\n6\n5\n7\n7\n30\n\n\nFemale\n12\n7\n11\n3\n7\n\n\n\nWhen we run the test (notice I immediately checked expected values, or assumptions, which is a good habit to get into)\n\nchisq.test(matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T))\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, :\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, byrow = T)\nX-squared = 17.179, df = 4, p-value = 0.001784\n\nchisq.test(matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T))$expected\n\nWarning in chisq.test(matrix(c(6, 5, 7, 7, 30, 12, 7, 11, 3, 7), nrow = 2, :\nChi-squared approximation may be incorrect\n\n\n          [,1]     [,2]      [,3]     [,4]     [,5]\n[1,] 10.421053 6.947368 10.421053 5.789474 21.42105\n[2,]  7.578947 5.052632  7.578947 4.210526 15.57895\n\n\nWe now have a significant p-value (.002). What does this mean now?\nA significant p-value from a multi-population test means the parameter is not the same for all groups. However, it does not necessarily mean the parameter is different for every group. Remember, our null hypothesis is (now)\n\\[\nH_O: p_{finch} = p_{junco} = p_{cardinal} = p_{robin} = p_{catbird}\n\\]\nWe would reject this if we have evidence any of these qualities are not true. For example, focusing on catbird comparisons for now, we may find\n\\[\n\\begin{split}\np_{catbird} \\neq p_{junco} \\\\\np_{catbird} \\neq p_{cardinal} \\\\\np_{catbird} \\neq p_{robin} \\\\\np_{catbird} \\neq p_{finch} \\\\\n\\end{split}\n\\]\nor we may find\n\\[\n\\begin{split}\np_{catbird} \\neq p_{junco} \\\\\np_{catbird} \\neq p_{cardinal} \\\\\np_{catbird} = p_{robin} \\\\\np_{catbird} = p_{finch} \\\\\n\\end{split}\n\\]\nEither of these outcomes would reject the null hypothesis that proportions were the same for all species, but they mean different things.\nIn general, after we show using an overall, or omnibus, test that there is a difference among populations, we need to determine which ones actually differ from the others. We do this using post-hoc comparisons to compare specific groups.\nWe can technically choose which comparisons to focus on. For example, you can do compare all possible pairs or just certain combinations. Why would this matter?\nThe answer has to do with family-wise error rate (FWER). Remember, for every test we run we have an \\(\\alpha\\)% chance of a type 1 error. If we run many tests, the likelihood of making a type 1 error increases (the rate of increase depends on how independent the tests are, but we need to control for it.\n\n\n\nXKCD 882: Significant\n\n\nFor this reason, we modify our “used” \\(\\alpha\\) for our post-hoc tests. There are many approaches to doing this, but they all depend on how many tests we run - so the more post-hoc comparisons we include, the harder it may be to find a significant difference among focal pairs.\nTo illustrate this, we will first use a very simple method that is no longer recommended but is useful as a starting point. One options is to control the FWER by dividing \\(\\alpha\\) by the number of post-hoc tests we intend to run. For the above example, if we do all pairs comparisons we would be running 10 comparison (4+3+2+1…). So instead of using .05 as a cutoff, we would use .005.\nFirst, it helps to make a table with row and column names (which are slightly different than headers and very different than a column of names in R).\n\nbird_ratio_table &lt;- matrix(c(6,5,7,7,30,12,7,11,3,7), nrow=2, byrow=T)\ncolnames(bird_ratio_table) &lt;- c(\"Finch\", \"Junco\", \"Cardinal\", \"Robin\", \"Catbird\")\nrownames(bird_ratio_table) &lt;- c(\"Male\", \"Female\")\n\nThen we can run the test with the pairwiseNominalIndependence function from the rcompanion package. Note the function needs a table or matrix and to know which method to use to compare rows or columns. Looking at the table\n\nbird_ratio_table\n\n       Finch Junco Cardinal Robin Catbird\nMale       6     5        7     7      30\nFemale    12     7       11     3       7\n\n\nLet’ s us see we want to compare columns.\n\nlibrary(rcompanion)\n\nWarning: package 'rcompanion' was built under R version 4.2.3\n\nbonf_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"bonf\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nbonf_correct\n\n           Comparison p.Fisher p.adj.Fisher  p.Gtest p.adj.Gtest p.Chisq\n1       Finch : Junco  0.71200       1.0000 0.643000     1.00000 0.93800\n2    Finch : Cardinal  1.00000       1.0000 0.729000     1.00000 1.00000\n3       Finch : Robin  0.11400       1.0000 0.059900     0.59900 0.14200\n4     Finch : Catbird  0.00082       0.0082 0.000505     0.00505 0.00141\n5    Junco : Cardinal  1.00000       1.0000 0.879000     1.00000 1.00000\n6       Junco : Robin  0.23100       1.0000 0.180000     1.00000 0.36900\n7     Junco : Catbird  0.02300       0.2300 0.011200     0.11200 0.02390\n8    Cardinal : Robin  0.23600       1.0000 0.111000     1.00000 0.23700\n9  Cardinal : Catbird  0.00471       0.0471 0.001950     0.01950 0.00476\n10    Robin : Catbird  0.42400       1.0000 0.461000     1.00000 0.74600\n   p.adj.Chisq\n1       1.0000\n2       1.0000\n3       1.0000\n4       0.0141\n5       1.0000\n6       1.0000\n7       0.2390\n8       1.0000\n9       0.0476\n10      1.0000\n\n\nThe test then shows all-pair comparisons with regular (what we should compare to .005 now, but we don’t usually know that!) and adjusted p-values (which have compensated for multiple tests so we can use our normal .05 cutoff- use this one!) for each test we have covered (you should use a post-hoc that matches what you did for the overall, or omnibus, comparison).\nYou can order and display these differently if it helps. For example, if we used the \\(\\chi^2\\) test.\n\nbonf_correct[order(bonf_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")]\n\n           Comparison p.adj.Chisq\n4     Finch : Catbird      0.0141\n9  Cardinal : Catbird      0.0476\n7     Junco : Catbird      0.2390\n1       Finch : Junco      1.0000\n2    Finch : Cardinal      1.0000\n3       Finch : Robin      1.0000\n5    Junco : Cardinal      1.0000\n6       Junco : Robin      1.0000\n8    Cardinal : Robin      1.0000\n10    Robin : Catbird      1.0000\n\n\nWe see that catbirds different from finches and cardinals in the proportion of males and females, while all other species do not differ. Note the un-adjusted p-value for this comparison pair is the same we would have found from just comparing the two groups\n\nchisq.test(matrix(c(6,30,12,7), nrow=2, byrow=T))\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(6, 30, 12, 7), nrow = 2, byrow = T)\nX-squared = 10.189, df = 1, p-value = 0.001413\n\nbonf_correct[bonf_correct$Comparison==\"Finch : Catbird\", \"p.Chisq\"]\n\n[1] 0.00141\n\n\nHowever, this comparison is very conservative. Many other options exist, and we will explore two here.\nThe sequential Bonferroni, or Holm’s, method, allocates your \\(\\alpha\\) to accept as many tests as signficant as possible while still controlling for the FWER. To do this, it orders the post-hoc tests by p-value, smallest to largest. It then rejects the null hypothesis attached to the smallest p-value and subtracts that p-value from \\(\\alpha\\). It continues to do this until \\(\\alpha\\) is too small to reject the next smallest p-value. I think of it as buying p-values with \\(\\alpha\\).\nWe can use this approach by simply changing the method. Let’s also order our results again for viewing.\n\nholm_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nholm_correct[order(holm_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")]\n\n           Comparison p.adj.Chisq\n4     Finch : Catbird      0.0141\n9  Cardinal : Catbird      0.0428\n7     Junco : Catbird      0.1910\n3       Finch : Robin      0.9940\n1       Finch : Junco      1.0000\n2    Finch : Cardinal      1.0000\n5    Junco : Cardinal      1.0000\n6       Junco : Robin      1.0000\n8    Cardinal : Robin      1.0000\n10    Robin : Catbird      1.0000\n\n\nAlthough we still reject the same null hypotheses, notice the adjusted p-value for the junco:catbird comparison is slightly lower. This is due to the “holm” approach.\nA final approach we will demonstrate is called the False Discovery Rate, or FDR, approach. It’s similar to the Holm’s approach in that it starts by ordering the post-hoc tests by p-value, smallest to largest. However, it then rejects the null hypothesis attached to the largest p-value that is &lt; \\(\\alpha\\) and subsequently rejects all null hypotheses attached to smaller p-values. It is thus less conservative but basically attempts to maximize the number of hypotheses you reject given a set \\(\\alpha\\).\n\nfdr_correct &lt;- pairwiseNominalIndependence(bird_ratio_table, compare=\"col\", method = \"fdr\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nfdr_correct[order(fdr_correct$p.adj.Chisq), c(\"Comparison\", \"p.adj.Chisq\")]\n\n           Comparison p.adj.Chisq\n4     Finch : Catbird      0.0141\n9  Cardinal : Catbird      0.0238\n7     Junco : Catbird      0.0797\n3       Finch : Robin      0.3550\n8    Cardinal : Robin      0.4740\n6       Junco : Robin      0.6150\n1       Finch : Junco      1.0000\n2    Finch : Cardinal      1.0000\n5    Junco : Cardinal      1.0000\n10    Robin : Catbird      1.0000\n\n\nAgain, we reject the same null hypotheses, but again you also observe a slight change in p-values. This indicates the important point here is controlling for the FWER. In later chapters we will expand this idea further by focusing on specific subsets of tests or comparisons, although these approaches are less commonly used."
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#goodness-of-fit-tests",
    "href": "content/chapters/Compare_proportions_among_populations.html#goodness-of-fit-tests",
    "title": "Comparing proportions among groups",
    "section": "Goodness of fit tests",
    "text": "Goodness of fit tests\nAbove we focused on comparing proportions among multiple groups using the \\(\\chi^2\\) test. This same approach (comparing expected vs observed values) can also be used to see if a single sample follows a specific distribution. In general, these tests are used to test hypotheses in the form of:\n\\[\n\\begin{split}\nH_O: \\textrm{data come from a particular discrete probability distribution} \\\\\nH_A: \\textrm{data do not come from a particular discrete probability distribution} \\\\\n\\end{split}\n\\]\nFor example, we used a binomial test in earlier chapters to see if our observed number of old (9) and young (9) finches matched a probability of .75.\n\nbinom.test(x=9, n=18, p=.75)\n\n\n    Exact binomial test\n\ndata:  9 and 18\nnumber of successes = 9, number of trials = 18, p-value = 0.02499\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.2601906 0.7398094\nsample estimates:\nprobability of success \n                   0.5 \n\n\nNote we instead consider what we observed vs what we expected using a \\(\\chi^2\\) test.\n\nchisq.test(c(9,9), p=c(.75,.25))\n\nWarning in chisq.test(c(9, 9), p = c(0.75, 0.25)): Chi-squared approximation\nmay be incorrect\n\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(9, 9)\nX-squared = 6, df = 1, p-value = 0.01431\n\n\nBoth p values are &lt; .05, so we reject the null hypothesis, \\(H_O: p=.75\\) . However, the p values are different? Do you remember why?\nThe \\(\\chi^2\\) test is an approximation! Thus, we prefer the binomial test to the \\(\\chi^2\\) test when we only have 2 categories (binomial data) but for more groups we can use the \\(\\chi^2\\) test. Since we are still using a \\(\\chi^2\\) test, these goodness-of-fit tests have the same assumptions as contingency analysis. If this isn’t true, we can combine categories as needed (note the binomial distribution is the extreme form of combining categories!), or we can use a G-test.\nThe main issue with goodness-of-fit tests is understanding how many degrees of freedom should be used for the null distribution. It usually depends on how many parameters you are estimating. Note, if parameters are determined outside of R, the software may not give appropriate answers.\nFor example, Klem wanted to know if bird strikes differed among months. The null hypothesis was no difference among months, which he tested by assuming a single probability described the likelihood of strikes regardless of month. An alternative (attached to a full model) would have assumed different probabilities for different months.\nIn this case, we estimated one parameter (p), or the number of collisions in one month is determined by the others due to our sample size, so we have 12-1=11 degrees of freedom. If we instead compared our data to a binomial distribution, we might need to estimate p and have one value set by the others. Another common use of goodness-of-fit tests is to determine if the number of offspring (or seeds) match ratios predicted by Punnet square crosses.\nAnother common distribution that data are tested against is the Poisson distribution. It describes the probability that a certain number of events occur in a block of time (or space), when those events happen independently of each other and occur with equal probability at every point in time or space. The Poisson distribution thus matches a null hypothesis that incidents are randomly distributed in space or time. The Poisson distribution is an extension of binomial that occurs when p is very low and n is large. When this occurs, note N-S ~ N (and a few other things happen), which lead to the entire distribution being described by a single parameter \\(\\mu \\approx Np\\), which is the mean and variance.\nThese traits also allow you to determine if data are random, clumped, or uniform. If the mean of a dataset is approximately the same as the variance, the points may be randomly distributed. If the variance is much greater than the mean, the data may be clumped. Alternatively, if the variance is much less than the mean, the data may be uniformly distributed."
  },
  {
    "objectID": "content/chapters/Compare_proportions_among_populations.html#next-steps",
    "href": "content/chapters/Compare_proportions_among_populations.html#next-steps",
    "title": "Comparing proportions among groups",
    "section": "Next steps",
    "text": "Next steps\nOur following chapters will extend ideas about testing differences among populations, including post-hoc tests, to continuous data."
  },
  {
    "objectID": "content/chapters/Binomial.html",
    "href": "content/chapters/Binomial.html",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "",
    "text": "In this chapter will build on our previous exploration of estimation by considering the world of hypothesis testing. These are different but related ideas, and we’ll end the section showing why. Along the way we will introduce the p-value. We will do all this while considering binomial tests, which are some of the simplest data we will see."
  },
  {
    "objectID": "content/chapters/Binomial.html#example-does-age-of-birds-impact-their-likelihood-of-colliding-with-glass",
    "href": "content/chapters/Binomial.html#example-does-age-of-birds-impact-their-likelihood-of-colliding-with-glass",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Example: Does age of birds impact their likelihood of colliding with glass?",
    "text": "Example: Does age of birds impact their likelihood of colliding with glass?\nLet’s start with an example. Klem Klem (1989) wanted to know if various factors (e.g., age, sex) of birds impacted the probability they would collide with glass windows. He collected data from several areas. In one of his samples, he found 18 purple finches collided with glass windows. 9 of these were in their hatching year (we’ll call them younger), and 9 were older. Is there any evidence that age impacts the probability of a purple finch colliding with the glass?\n\n\n\nCephas, CC BY-SA 3.0 &lt;https://creativecommons.org/licenses/by-sa/3.0&gt;, via Wikimedia Commons\n\n\nWhat have we done with data like this so far? You should know to calculate the proportion of each category impacting the probability of either category being represented in the sample. For example, since there were 9 older birds and 18 total, the proportion of older birds in the sample was:\n\n9/18\n\n[1] 0.5\n\n\nWe could also graph this, but it wouldn’t be very interesting:\n\nlibrary(ggplot2)\nfinch_data &lt;- data.frame(age = c(\"younger\", \"older\"), collisions = c(9,9))\nggplot(finch_data, aes (x=age, y = collisions))+\n  geom_col()+\n  labs(x=\"Age\", y= \"Collisions\", title = \"No apparent difference in sample based on age\")\n\n\n\n\nAnd although we haven’t discussed it, you should understand we could develop a confidence interval fr this type of data (we’ll do so below). That would tell us the range of proportions we might typically expect. But does that really answer the question of whether age impacts likelihood of colliding with glass?"
  },
  {
    "objectID": "content/chapters/Binomial.html#welcome-to-hypothesis-testing",
    "href": "content/chapters/Binomial.html#welcome-to-hypothesis-testing",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Welcome to hypothesis testing",
    "text": "Welcome to hypothesis testing\nTo answer that question, we have to move to hypothesis testing. This approach focuses on if a given value we found in the data (we’ll call it a signal) is really different (or significantly different) from what we would expect to see for a a given set of circumstances given the sampling error we now know to expect when we sample.\nThe given set of circumstances are described by a null hypothesis (this is why this approach is sometimes called NHST, or null hypothesis significance testing). We often abbreviate this as Ho. Let’s start by comparing this to estimation. Given our data, we could develop a 95% confidence interval (theoretically) that you should now understand will capture the true signal of the data about 95% of the time (here we are using proportion as opposed to mean, but it works). That’s a slightly different approach than asking if the true mean is equal to a given number, which is what hypothesis testing asks. Both deal with sampling error and explain why we can’t simply say an estimate being different than a given value proves there is a difference (make sure you understand why!).\nFor hypothesis testing in general, we again generate a known population that we draw from multiple times (should sound familiar), but this time the population parameters are set by a null hypothesis. Then we compare the spread of signals from those multiple draws (which exist due to sampling error!) to what we actually observed to determine how likely our draw was given the null hypothesis was true. If it’s unlikley to have occured by chance under the null hypothesis, we consider that evidence the null hypothesis is not correct and (eventually) reject it.\nYou can typically think of a null hypothesis as a hypothesis of no difference, affect, or relationship. Let’s walk through this with our bird example, where our null hypothesis would state age (measured as a category here!) has no impact on collisions. Given that, what would we expect to see in our sample?\nThis is a tricky question (that I chose on purpose!). Many approaches to this question start with a 50/50 expectation (like flipping a coin), but I’ve found that confuses students into thinking that is always the answer. Instead, think about what we would expect to see if age had no impact on collisions. We would not necessarily expect a 50/50 split in older and younger birds because that may not be what the population looks like. In fact, previous research has suggested the population is split closer to 3:1, with 3 older birds for every younger bird. This means if age has no impact on collisions, we should see about (due to sampling error!) 3 older birds for every younger bird in our samples of birds that hit glass.\nWhat did we actually see? We saw 5 old birds and 5 young birds. That is not a 3:1 split, but its also a small sample size. If we had a population with a 3:1 split and randomly selected 10 birds from it, how rare would it be to get 5 younger and 5 older birds? That’ (close) to what we are asking.\nIn this case, our null hypothesis is comparing our signal to a set value. This is common when we measure a single group and want to compare it to something. So our null hypothesis could be written as conceptually as age does not impact the probabilty a bird collides with glass. However, its often better (in order to connect it to tests!) to write it using numbers. In this case, we could write\n\\[\nH_O: p=.75\n\\]\nwhere p is the probability of a bird in our sample being old (for a single draw), or what we expect on average over larger samples (a proportion!). Remember, to find a proportion, you count the number of samples that fall in a given group and divided that by the total number sampled. Alternatively, you can assign a score of 0 for values that are not in the focal group and a score of 1 to samples that are - the average of these scores will give you the proportion.\nNote we could instead focus on young birds and get:\n\\[\nH_O: p=.25\n\\]\nWe also have alternative hypotheses (abbreviated HA)to accompany each of these. Our alternative is just the opposite of the null. Together, they encompass all the probability space. It is usually just as simple as switching signs. For example, if we focus on older birds, we get\n\\[\n\\begin{split}\nH_O: p=.75 \\\\  \nH_A: p \\neq .75\n\\end{split}\n\\]\nThe above ideas stay the same for all NHST approaches! We always use the null hypothesis to generate a “known” population (sometimes called the null population, draw samples from it, and then compare it to what we actually observed. What changes based on data type is how we generate the sample and multiple draws."
  },
  {
    "objectID": "content/chapters/Binomial.html#binomial-data",
    "href": "content/chapters/Binomial.html#binomial-data",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Binomial data",
    "text": "Binomial data\nThis example focuses on independent data points (one does not impact any others) that can be divided into 2 outcomes (young and old in our example). That is known as binomial data (so if data can be divided into two categories, we call it binomial data). A special case of binomial data exists when we only get one organism in our sample (e.g., one bird, one coin flip). We call this Bernoulli data.\nFor any type of data, we can simulate a distribution under the null hypothesis. For this example, we could put 4 pieces of paper in a hat, 3 labelled older and 1 labelled younger. We can then draw a sample of 18 (the number we actually observed) by drawing a piece of paper, writing down what it says, returning it to the hat, and repeating the process 9 more times to get single sample. For each sample, you could then calculate the observed proportion of older birds. You could visualize the spread of those results using a histogram. It’s important to realize this is doable without a computer (think it through), but it would take a lot of time because you need a lot of samples (we’ll come back to this).\nFor now, let’s do it with the computer. Let’s also take a shortcut: Instead of younger and older, let’s label the pieces of paper 0 and 1. We will also call the 0’s failures and the 1’s successes. Then we can sum the draws and divide by 10 to get the proportion of successes (make sure you understand why!). For now, let’s do a 1000 random draws of 18.\n\nset.seed(42)\nchoices &lt;- c(rep(0,1),rep(1,3))\nnumber_of_draws &lt;- 18\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_proportion\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_proportion[i] = sum(sample(choices,number_of_draws, replace=T))/number_of_draws\n}\n\nLet’ s take a look at the first few draw\n\nhead(sampling_experiment$observed_proportion)\n\n[1] 0.6111111 0.7222222 0.8333333 0.8333333 0.6111111 0.7222222\n\n\nNote we see some variation. Also note it is impossible to get a proportion of .75. Why? We only sampled 18 individuals, so we can’t get any outcomes that aren’t some form of a whole number less than 18 divided by 18. This seems simple, but it’s a reminder that your signal being different than your hypothesized value is not sufficient to reject the null hypothesis!\nNow let’s plot the proportions from our sampling experiment:\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nJust looking at this, it seems getting a proportion of .5 is unlikely. It only occurred 14 times. However, we also need to note how often more extreme outcomes occurred. Why?\nMore extreme values (the same or further distance away from the hypothesized value as our observed signal were) are also useful in considering if the null hypothesis is valid. When we move to continuous distributions, it’s also impossible to get a certain value (as mentioned in the probability section).\nIn this example, our observed proportion was .5. That’s .25 away from the value under the null hypothesis (.75), so we should all simulations that were . 5 or less or 1 or more. That only happened 22 times. So, in taking 1000 random draws from our null population, we only saw what we actually observed (or something more extreme) 0.022% of the time.\n\nsampling_experiment$Proportion = ifelse(sampling_experiment$observed_proportion &lt;= .5, \n                                  '&lt;= .5', ifelse(sampling_experiment$observed_proportion &gt;= 1, '&gt;.5 & &lt; 1', '&gt;= 1'))\n\n\n\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOr to think about as or more extreme..\n\nsampling_experiment$Proportion2 = ifelse(abs(sampling_experiment$observed_proportion-.75) &gt;= abs(9/18-.75), 'as or more extreme', 'not as or more extreme')\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion2)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\", \n       fill = \"Proportion\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "content/chapters/Binomial.html#welcome-to-the-p-value",
    "href": "content/chapters/Binomial.html#welcome-to-the-p-value",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Welcome to the p-value",
    "text": "Welcome to the p-value\nThis is a p-value. Don’t get confused! We will get p-values from multiple tests, but the binomial distribution also has a p parameter (the proportion). They are not the same.\nExplaining p-values is hard! You can see some statisticians try to explain the concept here.\nA smaller p-value therefore means it is less likely to obtain your observed signal, or something more extreme, by chance when the null hypothesis is true. Traditionally, a p-value of less than .05 is thought to be sufficient evidence to reject the null hypothesis. This comparison value is sometimes called the \\(\\alpha\\) (alpha), or significance, level. So if our p-value is &lt; .05, we often say we have significant evidence against HO. While we now often get specific p-values from software, historically people used tables to find ranges (less than .05, for example)."
  },
  {
    "objectID": "content/chapters/Binomial.html#understand-what-this-implies",
    "href": "content/chapters/Binomial.html#understand-what-this-implies",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Understand what this implies!",
    "text": "Understand what this implies!\nNote our p-value is the probability we would get a signal like we observed by chance if the null hypothesis was true. This means for an \\(\\alpha\\) of .05,we would expect to see something this extreme by chance 1 time out of 20! In other words, we can have errors. Think about it this way:\n\n\n\n\n\n\n\n\n\nBiological reality\n\n\n\n\n\nDecision (based on analysis of sample data)\nHO True\nHO False\n\n\nReject HO\nType I error (P[ɑ])\nPower (1- \\(\\beta\\) )\n\n\nDo not reject HO\nCorrect (P[1- ɑ])\nType II Error ( Pr\n[\\(\\beta\\)])\n\n\n\n\\(\\alpha\\) sets the limit we are ok with for rejecting HO when it is true (a Type 1 error). Alternatively, a Type II error is when we do not reject HO even when it’s is false. Importantly, \\(\\alpha + \\beta \\neq 1\\)! Instead, \\(\\alpha + (1-\\alpha)\\) is the probability space for HO, and \\(\\beta + (1-\\beta)\\) (or \\(\\beta + power\\)) is the probability space for HA. How they overlap depends on the signal, as the the distribution of signals under HA is close to what we already estimated for confidence intervals! You can visualize the relationship using the image below. Note the code is hidden given it’s length!\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\nWarning: The `show_guide` argument of `layer()` is deprecated as of ggplot2 2.0.0.\nℹ Please use the `show.legend` argument instead.\n\n\n\n\n\nThe key point is the experimenter sets HO and \\(\\alpha\\). Here we clearly see that in a typical test (like what we illustrated above) \\(\\alpha\\) is split among the top and bottom of the distribution of signals under HO to create rejection regions. Note if we decrease \\(\\alpha\\), which we can, we also decrease the power of the test! On a related note, we can return to an earlier image\n\n\n\nA 3D visualisaion of PPV, NPV, Sensitivity and Specificity. Luigi Albert Maria, CC BY-SA 4.0 &lt;https://creativecommons.org/licenses/by-sa/4.0&gt;, via Wikimedia Commons\n\n\nand note that power is equal to sensitivity!\nThese issues come up in power analysis, which is way of using prior estimates of the distribution of signals to determine appropriate sample sizes needed to detect significant results. Another form of power analysis occurs after a test is carried out, but this basically rehashing the p-value Levine and Ensom (2001) Heckman, Davis, and Crowson (2022).\nThis all points to a central idea of NHST. Larger sample sizes let you pick up smaller differences among groups! We will develop this below and consider relationships among significance and importance!"
  },
  {
    "objectID": "content/chapters/Binomial.html#can-we-do-this-without-running-a-sampling-experiment-every-time",
    "href": "content/chapters/Binomial.html#can-we-do-this-without-running-a-sampling-experiment-every-time",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Can we do this without running a sampling experiment every time?",
    "text": "Can we do this without running a sampling experiment every time?\nAs shown above, we can always use simulations to obtain a p-value. However, without a computer (and even with) it’s cumbersome. We also have to redo it for every change (for example, what if our sample contained 19 instead of 18 birds?). Another option is to find an algorithm that can be used to calculate a distribution that is very close to what we saw with the simulation.\nIn the case of our binomial data, very close actually means exact. The binomial data is an example of data where we can fully describe the probability outcomes a sample may take. The binomial distribution allows calculations of how often you would expect s successes for a set number of trials (n-s) if a population had a proportion of p for the focal trait. This means we use the binomial distribution to calculate our probabilities.\nLet’s not derive this fully, but just think about it. We have a proportion of success p, so (1 - p) is equal to the probability of failure (since we only have 2 options). For variance, we noted we find the average squared distance from the focal parameter value (in this case, a proportion).\nFor a single draw (what we call Bernoulli data), if we assume a success is equal to 1 and a failure to zero, we could “simply” multiply the likelihood of each our outcomes by their average squared distance from the mean\n\\[ \\begin{split} \\sigma^2 = (0-p)^2(1-p)+(1-p)^2(p)\\\\ which \\ eventually \\ reduces \\  to \\\\ \\sigma^2 =p(1-p) \\end{split} \\]\nSince we are assuming each data point is independent ( remember the multiplication rule?), the probability distribution of getting S successes from N draws will be\n\\[ Pr[S] =p^S(1-p)^{N-S} \\]\nand the variance will be\n\\[\n\\sigma_\\mu^2 =Np(1-p)\n\\]\nsince when you add independent events, you multiply the variances.\nSince we don’t care about the order of successes and failures in the sample, we have to think about combinations (not developed here), or how many ways one can arrange s successes in n draws. Putting it together, we can write the binomial distribution as\n\\[\nP[n \\ successes] = {n\\choose s}p^s(1-p)^{n-s}\n\\]\nUsing this distribution we can ask for the probability of obtaining any given number of successes for a given sample size. We can then find how likely we were to see a signal as more extreme than what we actually observed in the data by chance if the null hypothesis is true (p-value!). The dbinom function in R uses this distribution.\n\nsum(dbinom(0:9,18,.75))+dbinom(18,18,.75)\n\n[1] 0.02498549\n\n\nThis distributional assumptions also powers the binomial test (also called the exact binomial test). In R, we can use the binom.test function to carry it, with the arguments\n\nx=number of successes\n\nnow you see why we called them successes!\n\nn = total number of trials\np= expected proportion under the null hypothesis\n\n\nbinom.test(x=9, n=18, p=.75)\n\n\n    Exact binomial test\n\ndata:  9 and 18\nnumber of successes = 9, number of trials = 18, p-value = 0.02499\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.2601906 0.7398094\nsample estimates:\nprobability of success \n                   0.5 \n\n\nNote for this test the default value for p is .5 (equal chance), so if you don’t enter it that’s what will be used.\nNotice all our p-values are fairly close. P-values obtained using the distributional assumptions match exactly., and that obtained by simulation is very close. It should also be noted that although the p-value obtained by simulation will vary slightly each time, while those obtained using the binomial distribution will stay the same."
  },
  {
    "objectID": "content/chapters/Binomial.html#impact-of-sample-size",
    "href": "content/chapters/Binomial.html#impact-of-sample-size",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Impact of sample size",
    "text": "Impact of sample size\nNow that we can “easily” run a binomial test, let’s do it a few times to see the impact of sample sizes. For example, we could see the same proportion/signal (50%) of older birds in our sample, but if we only collected 8 individuals we would not be able to reject HO. Note what happens to our simulation outcomes:\n\nnumber_of_draws &lt;- 8\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_proportion\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_proportion[i] = sum(sample(choices,number_of_draws, replace=T))/number_of_draws\n}\nsampling_experiment$Proportion = ifelse(sampling_experiment$observed_proportion &lt;= .5, \n                                  '&lt;= .5', ifelse(sampling_experiment$observed_proportion &gt;= 1, '&gt;.5 & &lt; 1', '&gt;= 1'))\n\n\nggplot(sampling_experiment,\n              aes(x=observed_proportion, fill=Proportion)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed proportions from 1000 random draws\",\n       x= \"Proportion\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nSo now, we find that outcomes that are as or more extreme than what we saw in the actual data occur 2 times. So, in taking 1000 random draws from our null population, we only saw what we actually observed (or something more extreme) 0.002% of the time. Similarly,\n\nbinom.test(4,8,p=.75)\n\n\n    Exact binomial test\n\ndata:  4 and 8\nnumber of successes = 4, number of trials = 8, p-value = 0.1138\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.1570128 0.8429872\nsample estimates:\nprobability of success \n                   0.5 \n\n\nleads to a p-value which is &gt;.05, so we fail to reject HO. Again, this relates to how sampling error interacts with sample size, much as we saw when constructing confidence intervals. This means we have to differentiate between statistical significance and importance.\nGiven a large enough sample size, we can detect very small differences from our parameter value under the null hypothesis. For example, what if data from another population of finches showed 780 older birds out of a sample of 1000 birds that collided with windows. If we assume the population distribution in regards to age is the same, we are still testing\n\\[\n\\begin{split}\nH_O: p=.75 \\\\  \nH_A: p \\neq .75\n\\end{split}\n\\]\nIn our sample, we found a signal of 0.78, which is very close to .75. However, we find a p-value of\n\nbinom.test(780,1000, p = .75)\n\n\n    Exact binomial test\n\ndata:  780 and 1000\nnumber of successes = 780, number of trials = 1000, p-value = 0.02843\nalternative hypothesis: true probability of success is not equal to 0.75\n95 percent confidence interval:\n 0.7530202 0.8053200\nsample estimates:\nprobability of success \n                  0.78 \n\n\nIs the slight increase in older birds really important to understanding the population? Maybe, or maybe not. The point is we have to understand the difference between estimates and significance and the more nebulous idea of importance."
  },
  {
    "objectID": "content/chapters/Binomial.html#estimates-and-p-values-work-together",
    "href": "content/chapters/Binomial.html#estimates-and-p-values-work-together",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Estimates and p-values work together",
    "text": "Estimates and p-values work together\nThis is one way estimates and NHST work together. Estimate focuses on the sample (Given sampling error, where do we think true parameter lies?). Hypothesis testing focuses on the likelihood of the signal given the null distribution (how likely were we to observe data that we did, a la the p-value), but gives no information about the actual difference (which could be important for determining if something really matters!)."
  },
  {
    "objectID": "content/chapters/Binomial.html#one-sided-tests",
    "href": "content/chapters/Binomial.html#one-sided-tests",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "One-sided tests",
    "text": "One-sided tests\nIn introducing the p-value (and estimation) we focused on two-sided (or two-tailed) tests. This means we considered deviations from our value under the null hypothesis (for p-values) or via sampling error (for confidence intervals) based on their magnitude, and not direction. However, we can instead decide we want to consider differences to one “side” of our value of interest. Following this idea, we have 3 options for our null and alternative hypotheses (note C is a constant value here!):\n\n\n\n\n\n\n\n\n\n\n\n*Two-sided (\ntypical)**\n\nFocused on signals greater than predicted in null\nFocused on signals less than predicted in null\n\n\nHO\np = C\np &lt;= C\np &gt;= C\n\n\nHA\np \\(\\neq\\) C\np &gt; C\np &lt; C\n\n\n\nFor example, Claramunt et al Claramunt, Hong, and Bravo (2022) wished to consider if roads impaired bird movement. To do they considered if banded birds were more likely to be recapture in one of 3 areas across a road from their original location or one of 6 on the same side on which they were captured. They were only interested if roads reduced bird movement, so they were justified in using a sided test. These tests move all the rejection region to one side. You can run these by adding an alternative argument to binom.test\n\nbinom.test(116,641, p=.33, alternative = \"less\")\n\n\n    Exact binomial test\n\ndata:  116 and 641\nnumber of successes = 116, number of trials = 641, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is less than 0.33\n95 percent confidence interval:\n 0.0000000 0.2078378\nsample estimates:\nprobability of success \n             0.1809672 \n\n\nHere we reject HO, where\n\\[\n\\begin{split}\nH_O: p&gt;=.33 \\\\\nH_A: p &lt; .33\n\\end{split}\n\\]\nHowever, sided or tailed tests should be rarely used? Why? Because it can be too tempting to use a sided test after observing the data! A signal that is not significant at the \\(\\alpha\\) =.05 level using two-sided tests can be significant as a one-tailed test.\nIf you do use these, note they correspond to confidence bounds instead of intervals. Again, the full rejection region is placed on one side of the estimate."
  },
  {
    "objectID": "content/chapters/Binomial.html#tying-it-all-together",
    "href": "content/chapters/Binomial.html#tying-it-all-together",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Tying it all together",
    "text": "Tying it all together\nLet’s return to our bird collision example and connect estimation and p-values (and teach you how to estimate confidence intervals for binomial data).\nRemember, we found 9 older birds in our sample of 18. This means our estimate for the proportion of older birds 0.5. Just like for continuous data, we can consider sampling error in our estimate. Let’s think about how that might happen.\n\n\nIn short, the standard error of p is\n\\[\nSE(p) = \\sqrt{\\frac{p(1-p)}{N}}\n\\]but since we don’t know p, we use our estimate\n\\[\nSE(\\hat{p}) = \\sqrt{\\frac{(\\hat{p}(1-\\hat{p})}{N}}\n\\]\nTo find out a little more, click here.\n\nFor a single draw (Bernoulli data), if we assume a success is equal to 1 and a failure to zero, we could “simply” multiply the likelihood of each our outcomes by their average squared distance from the mean\n\\[\n\\begin{split}\n\\sigma^2 = (0-p)^2(1-p)+(1-p)^2(p)\\\\\nwhich \\ eventually \\ reduces \\  to \\\\\n\\sigma^2 =p(1-p)\n\\end{split}\n\\]\nIf we move to N independent draws, we predict the average observed outcome (or the mean number of successes!) will be\n\\[\n\\mu_S = Np\n\\]\nSince we are assuming each data point is independent, the variance of N draws will be\n\\[\n\\sigma_\\mu^2 =Np(1-p)\n\\]\nso\n\\[\n\\sigma_\\mu =\\sqrt{Np(1-p)}\n\\]\nNotice in doing this we went from a proportion to a number of successes! Now we can use our typical equation for standard error of the means\n\\[\n[\\sigma_{\\mu_s} = \\frac{\\sigma}{\\sqrt{N}} = \\frac{\\sqrt{(Np(1-p)}}{\\sqrt{N}}  = \\sqrt{\\frac{(p(1-p)}{N}} \\ ] \\sim [s_{\\overline{Y}} = \\frac{s}{\\sqrt{N}} =   \\frac{\\sqrt{(N\\hat{p}(1-\\hat{p})}}{\\sqrt{N}} = \\sqrt{\\frac{(\\hat{p}(1-\\hat{p})}{N}}]\n\\]\nThis is actually a bit tricky as it assumes some connections between categorical and continuous data, and many ways have been proposed to do this (Subedi and Issos 2019), but this gets us close.\n\nIt turns out our estimate of the standard error may be biased, especially for small sample sizes or extreme (close to 0 or 1) values of p. For that reason, several ways have been suggested to calculate confidence intervals (Subedi and Issos 2019) . Note, for example, the binom.confint function in the binom package gives multiple outcomes. For the function,\n\nthe first argument is the number of successes\nthe second argument is the number of trials\n\n\nlibrary(binom)\nbinom.confint(9,18)\n\n          method x  n mean     lower     upper\n1  agresti-coull 9 18  0.5 0.2903102 0.7096898\n2     asymptotic 9 18  0.5 0.2690160 0.7309840\n3          bayes 9 18  0.5 0.2835712 0.7164288\n4        cloglog 9 18  0.5 0.2592888 0.7005143\n5          exact 9 18  0.5 0.2601906 0.7398094\n6          logit 9 18  0.5 0.2841566 0.7158434\n7         probit 9 18  0.5 0.2812976 0.7187024\n8        profile 9 18  0.5 0.2808406 0.7191594\n9            lrt 9 18  0.5 0.2808092 0.7191908\n10     prop.test 9 18  0.5 0.2903102 0.7096898\n11        wilson 9 18  0.5 0.2903102 0.7096898\n\n\nFor now, we will use method labelled the Agresti-Coull method, which adjusts for slight bias in other estimates and is useful across sample sizes.\n\nusing_distribution &lt;- dbinom(0:18,18,.75)\nfinches &lt;- data.frame (Number = 0:18, Probability = using_distribution)\nfinches$Proportion &lt;- finches$Number/18\nfinches$criteria &lt;- \"retain\"\nfinches$criteria[pbinom(finches$Number, 18, .75) &lt; .025] &lt;- \"reject\"\nfinches$criteria[(1-pbinom(finches$Number, 18, .75)) &lt; .025] &lt;- \"reject\"\nproportion_observed = data.frame(Proportion = 9/18, Probability = .15)#sets height\nggplot(finches, aes(x = Proportion, y = Probability)) + \n  geom_bar(stat=\"identity\", aes(fill = criteria)) + \n  geom_segment(x = .29031, xend = .70968,y= .15 , yend =.15) +\n  geom_vline(xintercept = .75, color = \"blue\") + geom_vline(xintercept = 9/18, color = \"black\") +\n  geom_point(data= proportion_observed) +\n  ggtitle(\"Comparing p-values and confidence intervals for finch problem\")\n\n\n\n\nNote we see our rejection region in red; it also contains our estimate! Similarly, the 95% confidence interval for our estimate does not contain the paramater value under the null hypothesis!"
  },
  {
    "objectID": "content/chapters/Binomial.html#next-steps",
    "href": "content/chapters/Binomial.html#next-steps",
    "title": "The one where we introduce hypothesis testing via binomial tests",
    "section": "Next steps",
    "text": "Next steps\nMake sure you understand the above concepts (i.e., how p-values are is related to null hypotheses and how to interpret them!). Our following chapters will extend this idea to different types of data, starting with continuous data from a single sample in the next chapter."
  },
  {
    "objectID": "content/chapters/Acquiring_data.html",
    "href": "content/chapters/Acquiring_data.html",
    "title": "Acquiring data",
    "section": "",
    "text": "Let’s start our statistics journey by thinking about the simplest scenario: We want to know something about a group. An example might be the average (or mean, we will define later if needed!) value for some trait, the minimum value, or the maximum value. We could also wish to know about the distribution of values for that trait in the group. These traits of the group are called statistics:\n\nthe numerical facts or data themselves - Dictionary.com\n\nThis means we have a target trait we are focused on, and we have defined a group of interest. We can call this group of interest a population. Note that while the term population may have specific meanings in some fields (such as ecology), here population is just the group of interest. It could be a population of Goliath grouper in Florida, a population of flowers in Virginia, or people from a certain country or demographic group. We could want to know something about all of these groups!\nAs we’ve already noted, in a perfect world we know everything (or at least our trait value) for every member of the focal population. However, we often don’t or can’t measure every member of a population. It may be too difficult or expensive to measure every member of the population. In fact, we may not even know how large the population is!\nIn the cases where we can’t measure every member of the population, we collect data on the focal trait(s) from a sample. A sample is the subset of the population of interest. Data can be collected from samples used in experimental studies, where researchers manipulate something to see how it impacts the focal trait. Researchers may expose organisms to different stimuli in a controlled lab, field, or mesocosm study to see what happens. For example, researchers interested in impacts of an invasive crayfish (Pacifastacus leniusculus) on Mazama newts (Taricha granulosa mazamae) collected newts and crayfish.; they then placed either just newts or newts and crayfish in in large tanks to observe interactions Girdner et al. (2018).\n\n\n\nFigure 1: Experimental mesocosms used to evaluate Mazama newt and signal crayfish behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists observed the interaction between newts and crayfish in tanks designed to mimic natural habitat.\n\n\nData can also be collected from observational studies, where researchers simply measure outcomes and other traits without manipulating anything. For example, scientists interested in impacts of climate change on species ranges surveyed sites for species presence and abundance and compared it to historical data (Sagarin et al. (1999)).\nDifferent types of studies change what we can use the data for. In general, experimental studies are more commonly used to ascertain causation (something makes something happen), whereas observational studies are used to assess correlation (something happens when something else happens). However, these can be hard to disentangle, especially since studies can only be observational since experiments would be unethical or impossible to carry out. As XKCD puts it\n\n\n\nFigure 2: XKCD: Correlation. Title text (text that pops up when you hover over the comic): Correlation doesn't imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’.\n\n\n\nCorrelation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’ - XKCD #552\n\nOnce we have the sample, we can measure the trait of interest in it, and use that to estimate the statistic of interest for the actual population. This is the science of statistics, which can actually be defined as\n\nthe practice or science of collecting and analyzing numerical data in large quantities, especially for the purpose of inferring proportions in a whole from those in a representative sample. - Oxford English Dictionary\n\nIf the whole idea of statistics is to infer something about the population from our sample, we need to make sure the sample is representative of the population. That means it should not be biased. Bias occurs if the trait values we measure in our sample differ from the population in a consistent way. This can happen with samples of convenience, or when researchers select samples that are easy to measure but may not be representative of the population. Classic examples include estimating the amount of time students spend studying by surveying students at a campus library.\nBias may also be related to issues of independence. In a good sampling design, every member of the population has the same chance of being included in a sample. Samples of convenience violate this premise, and often the underlying issue is that the samples are not independent. A perfect solution is to randomly choose members of the population to be in the sample, but that is often not possible. Again, it requires knowing every member of the population! Indepence also means each data point is not related to any others!\n\n\n\nFigure 3: XKCD: Slope Hypothesis Testing. Don’t worry, we’ll come back to significance - but what is the independence issue?\n\n\nIn some cases linkages among samples are impossible to avoid. We will cover ways to address that using blocking factors or random effects later.\nNotice in discussing bias we are not directly focusing on the quality of the measurements! For that, we could discuss accuracy (how well we measure the underlying trait in regards to its true value, which we typically don’t know) and precision (how repeatable our measurement technique is). Obviously we need good data to make good estimates, but these ideas are different from our current focus on picking a good sample.\nEven if we have a proper way to measure a trait (accurate and precise) in a good sample (not biased), we will still be producing an estimate of the population statistic! This is due to sampling error. Sampling error refers to the fact that every sample will produce a slightly different estimate of the statistic. Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their length, and use it calculate the average fish length. If we took a different sample, do you think it would have exactly the same average?\nWe can demonstrate this in R - you won’t understand the code below yet, so just trust me for now, but this will let you start seeing code and thinking about how to use it.\nLet’s generate a population of fish. We’ll store their lengths in a vector called lengths.\n\nlengths &lt;- rnorm(n=1000, mean = 10, sd=1)\n\nThe average length of fish in this population is 10.02 cm. We can then simulate a sample from this population. In fact, let’s simulate 2 and compare the means of each.\n\nsample_1 &lt;- sample(lengths,50)\nsample_2 &lt;-sample(lengths, 50)\n\nThe mean length for fish in sample 1 is 9.99 cm, while that in sample 2 is 10 cm (Note: if you view this on the webpage you will see a number, but in the actual qmd file you see R code here - this is an example of merging code and text!). These are both close to the true value, but they are also both slightly different - this is sampling error!\nSampling error always exists, and a major part of statistics is to quantify it. One thing that reduces sampling error is to have large samples! Remember, if we measure every member of the population we don’t even need statistics, so the closer we get to that (implying larger samples) the better!"
  },
  {
    "objectID": "content/chapters/Acquiring_data.html#how-do-we-get-data",
    "href": "content/chapters/Acquiring_data.html#how-do-we-get-data",
    "title": "Acquiring data",
    "section": "",
    "text": "Let’s start our statistics journey by thinking about the simplest scenario: We want to know something about a group. An example might be the average (or mean, we will define later if needed!) value for some trait, the minimum value, or the maximum value. We could also wish to know about the distribution of values for that trait in the group. These traits of the group are called statistics:\n\nthe numerical facts or data themselves - Dictionary.com\n\nThis means we have a target trait we are focused on, and we have defined a group of interest. We can call this group of interest a population. Note that while the term population may have specific meanings in some fields (such as ecology), here population is just the group of interest. It could be a population of Goliath grouper in Florida, a population of flowers in Virginia, or people from a certain country or demographic group. We could want to know something about all of these groups!\nAs we’ve already noted, in a perfect world we know everything (or at least our trait value) for every member of the focal population. However, we often don’t or can’t measure every member of a population. It may be too difficult or expensive to measure every member of the population. In fact, we may not even know how large the population is!\nIn the cases where we can’t measure every member of the population, we collect data on the focal trait(s) from a sample. A sample is the subset of the population of interest. Data can be collected from samples used in experimental studies, where researchers manipulate something to see how it impacts the focal trait. Researchers may expose organisms to different stimuli in a controlled lab, field, or mesocosm study to see what happens. For example, researchers interested in impacts of an invasive crayfish (Pacifastacus leniusculus) on Mazama newts (Taricha granulosa mazamae) collected newts and crayfish.; they then placed either just newts or newts and crayfish in in large tanks to observe interactions Girdner et al. (2018).\n\n\n\nFigure 1: Experimental mesocosms used to evaluate Mazama newt and signal crayfish behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists observed the interaction between newts and crayfish in tanks designed to mimic natural habitat.\n\n\nData can also be collected from observational studies, where researchers simply measure outcomes and other traits without manipulating anything. For example, scientists interested in impacts of climate change on species ranges surveyed sites for species presence and abundance and compared it to historical data (Sagarin et al. (1999)).\nDifferent types of studies change what we can use the data for. In general, experimental studies are more commonly used to ascertain causation (something makes something happen), whereas observational studies are used to assess correlation (something happens when something else happens). However, these can be hard to disentangle, especially since studies can only be observational since experiments would be unethical or impossible to carry out. As XKCD puts it\n\n\n\nFigure 2: XKCD: Correlation. Title text (text that pops up when you hover over the comic): Correlation doesn't imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’.\n\n\n\nCorrelation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’ - XKCD #552\n\nOnce we have the sample, we can measure the trait of interest in it, and use that to estimate the statistic of interest for the actual population. This is the science of statistics, which can actually be defined as\n\nthe practice or science of collecting and analyzing numerical data in large quantities, especially for the purpose of inferring proportions in a whole from those in a representative sample. - Oxford English Dictionary\n\nIf the whole idea of statistics is to infer something about the population from our sample, we need to make sure the sample is representative of the population. That means it should not be biased. Bias occurs if the trait values we measure in our sample differ from the population in a consistent way. This can happen with samples of convenience, or when researchers select samples that are easy to measure but may not be representative of the population. Classic examples include estimating the amount of time students spend studying by surveying students at a campus library.\nBias may also be related to issues of independence. In a good sampling design, every member of the population has the same chance of being included in a sample. Samples of convenience violate this premise, and often the underlying issue is that the samples are not independent. A perfect solution is to randomly choose members of the population to be in the sample, but that is often not possible. Again, it requires knowing every member of the population! Indepence also means each data point is not related to any others!\n\n\n\nFigure 3: XKCD: Slope Hypothesis Testing. Don’t worry, we’ll come back to significance - but what is the independence issue?\n\n\nIn some cases linkages among samples are impossible to avoid. We will cover ways to address that using blocking factors or random effects later.\nNotice in discussing bias we are not directly focusing on the quality of the measurements! For that, we could discuss accuracy (how well we measure the underlying trait in regards to its true value, which we typically don’t know) and precision (how repeatable our measurement technique is). Obviously we need good data to make good estimates, but these ideas are different from our current focus on picking a good sample.\nEven if we have a proper way to measure a trait (accurate and precise) in a good sample (not biased), we will still be producing an estimate of the population statistic! This is due to sampling error. Sampling error refers to the fact that every sample will produce a slightly different estimate of the statistic. Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their length, and use it calculate the average fish length. If we took a different sample, do you think it would have exactly the same average?\nWe can demonstrate this in R - you won’t understand the code below yet, so just trust me for now, but this will let you start seeing code and thinking about how to use it.\nLet’s generate a population of fish. We’ll store their lengths in a vector called lengths.\n\nlengths &lt;- rnorm(n=1000, mean = 10, sd=1)\n\nThe average length of fish in this population is 10.02 cm. We can then simulate a sample from this population. In fact, let’s simulate 2 and compare the means of each.\n\nsample_1 &lt;- sample(lengths,50)\nsample_2 &lt;-sample(lengths, 50)\n\nThe mean length for fish in sample 1 is 9.99 cm, while that in sample 2 is 10 cm (Note: if you view this on the webpage you will see a number, but in the actual qmd file you see R code here - this is an example of merging code and text!). These are both close to the true value, but they are also both slightly different - this is sampling error!\nSampling error always exists, and a major part of statistics is to quantify it. One thing that reduces sampling error is to have large samples! Remember, if we measure every member of the population we don’t even need statistics, so the closer we get to that (implying larger samples) the better!"
  },
  {
    "objectID": "content/chapters/Acquiring_data.html#next-steps",
    "href": "content/chapters/Acquiring_data.html#next-steps",
    "title": "Acquiring data",
    "section": "Next steps",
    "text": "Next steps\nNow that we have data, we’ll discuss summarizing it in the next section (and actually define mean and some of the other terms we’ve started to use!)."
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html",
    "href": "content/chapters/Compare_means_among_populations.html",
    "title": "Comparing means among groups",
    "section": "",
    "text": "In the last chapter we introduced the idea of comparing parameters among populations. Now we will extend those ideas to instances when continuous data is collected."
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#example-back-to-the-iris",
    "href": "content/chapters/Compare_means_among_populations.html#example-back-to-the-iris",
    "title": "Comparing means among groups",
    "section": "Example: Back to the iris",
    "text": "Example: Back to the iris\nWhen we introduced NHST for continuous data, we focused on sepal length from I. virginica.\n\nset.seed(42)\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nand tested if it was equal to a given value (7.0 cm)\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\nWe then considered how to assess these types of hypotheses using z, t, Wilcoxon, and sign tests.\nHowever, as we noted in the last chapter, we often instead have data from multiple populations. For example, we may have data from 3 species of flowers. We commonly see this data plotted as a bar chart with error bars\n\n\nLoading required package: lattice\n\n\nLoading required package: plyr\n\n\n\n\n\nWhat do we test now and how?"
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#welcome-to-anovas",
    "href": "content/chapters/Compare_means_among_populations.html#welcome-to-anovas",
    "title": "Comparing means among groups",
    "section": "Welcome to ANOVAs",
    "text": "Welcome to ANOVAs\nAs previously noted, we can’t compare heights among group. Height is a random variable, and it’s highly unlikely they will be exactly the same. Seeing the actual data may help us remember this.\n\nggplot(iris, aes(y=Sepal.Length, x=Species, color=Species)) +\n  geom_jitter() +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\nSo we typically focus on a parameter that describes the distribution of a focal trait, such as the mean. Just like binomial data, our hypotheses are then\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length, \\ setosa} = \\mu_{sepal \\ length, \\ virginica} = \\mu_{sepal \\ length, \\ versicolor}\\\\  \nH_A: \\mu_{sepal \\ length, \\ setosa} \\neq \\mu_{sepal \\ length, \\ virginica} \\neq \\mu_{sepal \\ length, \\ versicolor}\\\\\n\\end{split}\n\\]\nGiven that, our overall idea is to consider if the data are better explained by an overall group average or by species-specific averages. To visualize this, we could use\n\ncolors &lt;- c(\"group means\" = \"black\", \"overall average\" = \"orange\")\nggplot(iris, aes(Species,Sepal.Length)) + \n  geom_jitter(aes(colour=Species), size = 3) +\n  geom_errorbar(aes(ymin=Sepal.Length, ymax=Sepal.Length, color=\"group means\"), \n                data = function_output) +\n    geom_hline(aes(yintercept=mean(Sepal.Length),  color = \"overall average\"))+\n  scale_color_manual(values=colors)+\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\", \n       color= \"Focus\")\n\n\n\n\nLike our earlier considerations of variance and SSE, the data will obviously be fit better by species-specific averages. Its impossible for them to do worse than the overall average, and at worst they all are the group average. However, we should also remember that these are samples, so we know sampling error is an issue. Therefore, we have to consider if the species-specific averages do enough of a better job explaining the data to warrant using them. To put this in our SSE and hypothesis framework, we need to consider if a more complicated view of the world is worth it.\nTo test this, we can (as always) carry out a sampling experiment. The general idea is that species does snot matter (just like we saw in contingency analysis). Given that, we can draw samples that match our respective sample sizes for each population from a single population. The mean can be set as the pooled mean for the data (since under the null tested factors don’t matter). Since we don’t know or set sigma, we can again estimate it from the data. One such sample might look like\n\nvariance_estimate &lt;- sum((function_output$N -1) * (function_output$sd)^2)/(sum(function_output$N)-length(function_output$N))\nmean_sepal &lt;- mean(iris$Sepal.Length)\nsimulated_data &lt;- data.frame(Species=c(rep(\"setosa\", 50), \n                                       rep(\"versicolor\", 50),\n                                       rep(\"virginica\",50)),\n                             Sepal.Length=rnorm(150, mean_sepal, \n                                          sd= sqrt(variance_estimate)))\n\nfunction_output &lt;- summarySE(simulated_data, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(simulated_data, aes(Species,Sepal.Length)) + \n  geom_jitter(aes(colour=Species), size = 3) +\n  ylab(\"Sepal Length (cm)\")+ggtitle(\"Sepal Length of various iris species\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\")) +\n  geom_errorbar(aes(ymin=Sepal.Length, ymax=Sepal.Length, color=\"group means\"), \n                data = function_output) +\n    geom_hline(aes(yintercept=mean(Sepal.Length),  color = \"overall average\"))+\n  scale_color_manual(values=colors)\n\n\n\n\nAs expected, under the null hypothesis the overall and species-specific averages are closer. Now that we have the data, however, we are stuck with a new question: What is our test statistic?\nIn general, using a difference among means makes sense for cases when we have only 2 populations. This will be used when we introduce t-tests. However, it does not work for 3+ populations, so we will need a different approach.\nANOVAs offer an approach that can be used for any group of 2+ populations when certain assumptions are met. ANOVAs stands for analysis of variance which may seem odd given our hypotheses are focused on means. However, the idea (not fully developed here) is that we can get an overall estimate of variance by\n\ncalculating variance for each point around its respective group-specific mean\n\nthis leads to 3 estimates of variance, which we can multiple by (n-1) to account for differences in sample size and then divide by the number of groups to get an overall estimate of variance\n\nthis is referred to as mean square error\n\n\n\\[\n\\begin{split}\n\\textrm{Remember, }s^2 = \\frac{\\sum_{i=1}^{n} (Y_{i}-\\overline{Y})^2}{n-1} \\sim \\sigma^2\\\\\n\\textrm{So if we have j groups, for each group we can see}\\\\\ns_j^2 = \\frac{\\sum_{i=1}^{n_j} (Y_{ij}-\\overline{Y_j})^2}{n_j-1} \\sim \\sigma_j^2\\\\\n\\textrm{which we can combine to estimate }\\sigma_{overall}\\\\\n\\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2 ...(n_j-1)s_j^2}{n_1+n_2+...n_j-1} = s_{overall}^2\\\\\n\\end{split}\n\\]\ncalculating variance for each group mean around the overall mean\n\nthis is called mean square treatment\n\n\n\\[\n\\begin{split}\n\\frac{\\sum_{j=1}^{j} (\\overline{Y_j}-Y_{overall}{i})^2}{j-1} = \\frac{s^2}{n} \\\\\n\\textrm{where j is the number of groups. This can be multiplied by n to get }s^2 \\\\\n\\end{split}\n\\]\nIn other words, variance among groups should be equal to variance within groups. You should also note this means we can partition the variance for any given observation as its distance from its group mean and its group means distance from the overall\nUnder the null hypothesis, the ratio of these estimates should tend towards 1. We can see this using a sampling experiment.\n\n#sample\n  ratio &lt;- data.frame(rep = 1:10000, mse = rep(NA,10000), \n                      msg = rep(NA,10000), ratio = rep(NA,10000))\nfor(i in 1:10000){\n    setosa &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    versicolor &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    virginica &lt;- rnorm(50, mean_sepal, sd= sqrt(variance_estimate))\n    mean_overall &lt;- mean(c(setosa, versicolor, virginica))\n    ratio$mse[i] &lt;- (49 * var(setosa) + 49 * var(versicolor) + 49 * var(virginica))/(150 - 3)\n    ratio$msg[i] &lt;- (50 * (mean(setosa)-mean_overall)^2 + \n                 50 * (mean(versicolor)-mean_overall)^2 + \n                 50 * (mean (virginica)-mean_overall)^2)/2\n    ratio$ratio[i] &lt;- ratio$msg[i]/ratio$mse[i]\n}\n  \nsummary(lm(Sepal.Length~Species, iris))$fstatistic[1]\n\n   value \n119.2645 \n\nggplot(ratio, aes(ratio)) +\n    geom_histogram(aes(y=..count../sum(..count..)), fill = \"orange\", bins=15)+\n    labs(main = \"Ratio under null hypothesis\", y= \"Probability\")\n\nWarning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(count)` instead.\n\n\n\n\n\nUsing this approach, we could determine how unusual our data were (get a p-value!). However, finding a distribution that approximates this shape would make future work easier. It turns out all the squared terms above lead to this being a rato of \\(\\chi^2\\) distributions, where the numerator has degrees of freedom j-1 (# of groups - 1) and the numerator had degrees of freedom n-j-1; the “lost” degrees of freedom are used to estimate group and overall means.\n\nggplot(ratio, aes(ratio)) +\n    geom_histogram(aes(y=..count../sum(..count..)), fill = \"orange\", bins = 15) +\n    labs(main = \"Ratio under null hypothesis\", y= \"Probability\")+\n    stat_function(fun = df, args = list(df1 =2, df2 = 147), color = \"green\")   \n\n\n\n\nIn our data, we found a signal of 119.264502184505! This is going to lead to a very low p-value."
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#welcome-to-the-linear-model",
    "href": "content/chapters/Compare_means_among_populations.html#welcome-to-the-linear-model",
    "title": "Comparing means among groups",
    "section": "Welcome to the linear model",
    "text": "Welcome to the linear model\nAn ANOVA is just one case of a linear model. We will fully explore these later, but noting this now is useful in that all linear models have the same sets of assumptions. In general, linear models assume the residuals of the model are are independent, identically distributed, and follow a normal distribution. You’ll sometime see this written as\n\\[\n\\epsilon \\approx i.i.d.\\ N(\\mu,\\sigma)\n\\] But what does this mean?\nResiduals are the distance between a measurement and its model-predicted value. A closely related term, error, is actually the distance between a measurement and the unknown population mean for a group. Linear models assume the residuals are independent of each other (this follows from independent data points) and that their spread (around their predicted values) is normally distributed and similar for all points.\nUnderstanding this explains two key points. The residuals, not the data, need to be normally distributed. Also, we have to build the model to get the residuals, then we check the assumptions.\nWe can do this in R using the lm function. This approach also lets us use a single set of functions to build many model types. As always, there are many ways to do anything in R, so there are specific ANOVA functions that we will not introduce here.\nFor our data, we can build an lm object\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nthen use plot to check the assumptions.\n\nplot(iris_anova)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese 4 plots focus on the residuals (not the data).\n\nThe Residuals vs fitted plot allows us to see if the residuals are identically distributed - we want to see a flat red line and no structure to the residuals in regards to their spread or location. Note we only have 3 fitted values here (matching our 3 group means), so will see “lines” of data in one-way ANOVAs (another name for what we are doing here).\n\nThe Q-Q Residuals plot allows us to assess normality - points should be on the line\nThe other 2 graphs give show different forms of residuals against the fitted values. We will return to them later.\n\nIf our assumptions are met, we can look at the output. One way to do this is using the summary function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nThis output may be confusing, however. The overall p value shown in the bottom right is for the entire model - that works for now, but soon won’t. We also see individual p values for 2 levels of species, plus an odd intercept term.\nThese are model artifacts and may be confusing. R lets the first factor level (typically alphabetical) be an intercept for the linear model, and then considers the other factor levels as deviations from that. It also shows if all the resulting Estimates are significantly different from 0. Note this means a significant intercept term does not mean your groups actually differ.\nGiven these issues, why use the summary command? It does present some other useful information. For example, the R2 values is a measure of how variation the model explains. It can range from 0 (the model explains nothing) to 1 (all residuals are zero, in this case meaning all members of a given species have the exact same height). The adjusted-R2 value is similar, but it adjusts the measure to account for the fact more complex models will always explain more variation.\nYou can also remove the intercept to get group estimates for all groups\n\nsummary(lm(Sepal.Length~Species-1, iris))\n\n\nCall:\nlm(formula = Sepal.Length ~ Species - 1, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \nSpeciessetosa       5.0060     0.0728   68.76   &lt;2e-16 ***\nSpeciesversicolor   5.9360     0.0728   81.54   &lt;2e-16 ***\nSpeciesvirginica    6.5880     0.0728   90.49   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.9925,    Adjusted R-squared:  0.9924 \nF-statistic:  6522 on 3 and 147 DF,  p-value: &lt; 2.2e-16\n\n\nNote these match our group means, which is good, but the overall p value is now less useful (it compares our data to a null that assumes everything is equal to 0), and the output is still confusing.\nSince we are doing an omnibus test, what we typically want is a single p value associated with our factor of interest (species in this case). To get that, we’ll use the Anova function from the car package.\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_anova, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nWhat does type=“III” mean\n\nResiduals can be calculated in multiple ways. For simple models (those with one variable) most calculations lead to the same answer. When we start adding multiple factors to a model and/or interactions, however, they differ. In short, Type I residuals consider the order in which factors are added to a model, and type 2 do not consider interactions. We will stick with type III for this class.\n&lt;&gt;\nDoing this we see Species has a significant impact on explaining variation in the data (and our very high F value). So we reject the null hypothesis that mean sepal length does not differ among species. Now what?"
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#post-hoc-tests",
    "href": "content/chapters/Compare_means_among_populations.html#post-hoc-tests",
    "title": "Comparing means among groups",
    "section": "Post-hoc tests",
    "text": "Post-hoc tests\nJust like for a multi-population \\(\\chi^2\\) tests, we need to do follow-up tests to compare groups while controlling for the FWER. For linear models (and more), we will use the glht function from the multcomp package to conduce these tests.\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nOur first approach uses a new (to us) method. It is not exactly Tukey’s method (very confusing) but is closely related to it. Tukey’s method is focuses on all possible pair-wise comparisons and controls for the FWER using a studentized range approach (not fully developed here, but similar to z-transform but focused on the range of means and using the estimated standard deviation; similar to t-statistic in this aspect and also developed by Student). It is also called Tukey’s Honestly Significant Difference/HSD, Tukey-Kramer method, and many other names. In glht, specifying “Tukey” tells the program to do all possible pairs comparison (like Tukey’s method). The post-hoc control for FWER, however, uses a slightly different approach that can handle interactions (still to be explained) and some other things a little bit easier.\nUsing this approach we see that all species differ significantly from all others; the output also provides estimates of the differences, which match up with our model summary output.\nWe can also use the methods we previously discussed such as Bonferroni and FDR. These requre us to set up the comparisons, which also means we can limit our number of tests if so desired. For example, we could focus only on differences with I. virginica.\n\ncompare_virginica_only &lt;- glht(iris_anova, linfct = mcp(Species = \n                                                                c(\"virginica - versicolor = 0\", \n                                                                  \"virginica - setosa = 0\")))\n\nAfter setting up the comparison, we can specify the method to use to correct for FWER,\n\nsummary(compare_virginica_only, test=adjusted(\"holm\")) \n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nvirginica - versicolor == 0    0.652      0.103   6.333 2.77e-09 ***\nvirginica - setosa == 0        1.582      0.103  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- holm method)\n\nsummary(compare_virginica_only, test=adjusted(\"fdr\")) \n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nvirginica - versicolor == 0    0.652      0.103   6.333 2.77e-09 ***\nvirginica - setosa == 0        1.582      0.103  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- fdr method)\n\n\nNote for our small number of tests and relatively large differences in means and large sample sizes, differences in p values are minimal.\nThere are instances when FWER are not an issue and thus p values do not need to be adjusted. This occurs when we explore orthogonal contrasts."
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#a-little-deeper-into-linear-models",
    "href": "content/chapters/Compare_means_among_populations.html#a-little-deeper-into-linear-models",
    "title": "Comparing means among groups",
    "section": "A little deeper into linear models",
    "text": "A little deeper into linear models\nLet’s return to linear models to help explain orthogonal contrasts (and some other things). Linear models are a sysem of equations (a matrix), where\n\\[\n\\begin{split}\nY=X\\beta+\\epsilon, \\textrm{ where }\\\\\n\\textrm{Y is our observations (an nx1 matrix)}\\\\\n\\textrm{X is a matrix showing our explanatory variables (an nxk matrix)}\\\\\n\\beta \\textrm{ is our coefficient matrix(an kx1 matrix)}\\\\\n\\epsilon \\textrm{is a matrix (an nx1) of residuals)}\\\\\n\\end{split}\n\\]\nIn our case, \\(\\beta\\) is simply a 3x1 matrix where each entry is a species average (or one is an intercept and other two are distances from it - same thing) and X is a matrix with dummy variables (1 or 0) indicating which group each observation belongs too. X is sometimes called a model or design matrix. We can see this using R. First, we can pull the design matrix from our model object\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(iris_anova)))\n\n\n\n  \n\n\n\nWe can also pull the model coefficients, which form our \\(\\beta\\) matrix, and place them in the correct orientation.\n\nmatrix(as.numeric(iris_anova$coefficients), ncol=1)\n\n      [,1]\n[1,] 5.006\n[2,] 0.930\n[3,] 1.582\n\n\nSo for our first observation, which is\n\niris[1,]\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n\n\nWe would multiply (remember, rows get multiplied by columns in matrices)\n\n1*5.006 + 0*.930+0*1.58\n\n[1] 5.006\n\n\nThis explains why all our fitted values are one of three values! We can also see our observation minus prediction\n\niris[1,\"Sepal.Length\"]-1*5.006 + 0*.930+0*1.58\n\n[1] 0.094\n\n\nmatches our first model residual\n\niris_anova$residuals[1]\n\n    1 \n0.094 \n\n\nUnderstanding this general setup explains a few things. When models get more complicated you may see errors or warnings related to singularity. This occurs when XTX isn’t invertible(linear algebra!), which it needs to be to find \\(\\beta\\). This occurs if columns in your design matrix are not independent and are actually linear combinations of each other. This happens when you have highly related measurements (we’ll discuss correlation eventually so you can actually measure this!). We will use similar manipulations to eventually find the \\(\\hat{H}\\) matrix when we consider Cook’s Distance (in regression chapter). Degrees of freedom are similarly related to the number of estimated coefficients the model required (the number of rows in the \\(\\beta\\) matrix).\nReturning to our contrasts, note when we do post-hoc tests we are effectively testing for differences in \\(\\beta\\) values. We can put these “tests” in a similar system of equations/matrix. For these tests, the coefficients have to equal 0. For pair comparisons, that means we have 1 for one coeffcient and -1 for the other (for example, (1,-1,0). However, we can also compare one coefficient to the average of the others (2,-1,-1). We could write these two contrasts as\n\\[\n\\begin{bmatrix}\n1 & -1 & 0 \\\\\n2 & 1 & 1 \\\\\n\\end{bmatrix}\n\\]\nA group of contrasts are orthogonal if the sum of the multiplied coefficients from each column equals zero. In this case\n\n1*2 + -1*1 + 0*1\n\n[1] 1\n\n\ndoes not equal 0, so these are not orthogonal contrasts. This is also because I can add add the first and third column and get the second (columns are not independent). However, if we instead carried out these contrasts\n\\[\n\\begin{bmatrix}\n2 & -1 & -1 \\\\\n0 & 1 & -1\\\\\n\\end{bmatrix}\n\\]\nthey would be independent. There are other options as well, as we can always find a number of orthogonal contrasts equal to the number of groups being compared minus one.\nResulting p values would not required correction for FWER. We can specify contrasts like this using glht. Below I do the same matrix, but note I set the maximum entry to 1 so that estimate of mean differences aren’t doubled.\n\ncontr &lt;- rbind(\"setosa - versicolor - virginica\" = c(1, -.5,-.5),\n               \"versicolor - virginica\" = c(0,1,-1))\nsummary(glht(iris_anova, linfct = mcp(Species = contr)), test=adjusted(\"none\"))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: User-defined Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nsetosa - versicolor - virginica == 0 -1.25600    0.08916 -14.086  &lt; 2e-16 ***\nversicolor - virginica == 0          -0.65200    0.10296  -6.333 2.77e-09 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- none method)"
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#displaying-output-of-post-hoc-tests",
    "href": "content/chapters/Compare_means_among_populations.html#displaying-output-of-post-hoc-tests",
    "title": "Comparing means among groups",
    "section": "Displaying output of post-hoc tests",
    "text": "Displaying output of post-hoc tests\nOutput from post-hoc tests is often displayed using compact letter display. Groups that are not significantly differently share the same letter (so in this case they all have different letters).\n\ncld_output &lt;- fortify(cld(compare_cont_tukey))\ncld_output$Species &lt;- cld_output$lhs\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nfunction_output &lt;- merge(function_output, cld_output)\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")+\n  geom_text(aes(label=letters,y=Sepal.Length+3*ci))\n\n\n\n\nOther options include plotting the differences in means\n\nplot(compare_cont_tukey)\n\n\n\n\n\nemmeans: another option\nAnother popular package for conducting posthoc comparison in R is emmeans. The package has a great starters guide here"
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#t-test-connections",
    "href": "content/chapters/Compare_means_among_populations.html#t-test-connections",
    "title": "Comparing means among groups",
    "section": "T-test connections",
    "text": "T-test connections\nSo far we have focused on comparing means among multiple groups. This can include include comparing means between only 2 groups (which we already do for the post-hoc tests). In doing this we also introduced new post-hoc tests and the ideas of a linear model.\nThe linear model framework will unify most of the remaining tests we learn in class. In fact, several tests we’ve already learned can be formulated this way. This is extremely useful given we want statistics to be a related set of tests in a comprehensive framework.\nThere are many ways to teach statistics, however, and a long history of tests. Many textbooks and approaches build up from one sample tests by moving to two-sample t-tests. These tests bridge the logic noted above and the approach we used for single-sample t-test. This is because the t-distribution is a special case of the F distribution. It occurs when the square root of an F distribution with 1 degree of freedom in the numerator is considered. Thus the degrees of freedom associated with a t-test will be equal to the degrees of freedom associated with the denominator of the associated F-test.\n2-sample t-tests may also an easier approach to first considering differences among groups since with only 2 populations the difference in means may be considered. However, it can be shown (not here) this is simply a rearrangement of our exploration of variances.\nTo demonstrate this, let’s only consider two species. Note\n\ntwo_species_subset &lt;- iris[iris$Species!=\"setosa\",]\nt.test(Sepal.Length ~ Species, two_species_subset, var.equal=T)\n\n\n    Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -5.6292, df = 98, p-value = 1.725e-07\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.8818516 -0.4221484\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nyields the same p-value as\n\nAnova(lm(Sepal.Length ~ Species, two_species_subset), type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 1761.80  1 5253.038 &lt; 2.2e-16 ***\nSpecies       10.63  1   31.688 1.725e-07 ***\nResiduals     32.87 98                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAlso note the t statistic is the square root of the F statistic.\n\n-5.6292^2\n\n[1] -31.68789\n\n\nNote the t.test function can also use columns holding data from each population as arguments as opposed to the formula interface, but we will not use that approach here.\nThe var.equal=T argument, however, is not the default in R, and this assumption is one of the major differences in 2-sample t-tests and F tests. Remember, ANOVAs and t-tests both require estimates for sigma. If we do not assume the variances are equal for each group, then the best way to estimate the variance is to calculate the variance for each group and take a weighted (by sample size mean). This approach is known as the Behren-Fisher or Welsh t-test.\n\nt.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nt = -5.6292, df = 94.025, p-value = 1.866e-07\nalternative hypothesis: true difference in means between group versicolor and group virginica is not equal to 0\n95 percent confidence interval:\n -0.8819731 -0.4220269\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nThe resulting statistics has a distrubtion that can be approximated by a t-distribution, but the associated degrees of freedom can can be non-integer (decimal) and less than (n1+ n2 - 2).\nThis means the basic assumptions for 2-sample t-tests are independent data points, groups show the same variance, and means are normally distributed. Much like the one-sample t-test, the central limit theorem implies assumptions about the mean distribution are commonly met. However, if they are not met, we have a few common options."
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#non-parametric-connections",
    "href": "content/chapters/Compare_means_among_populations.html#non-parametric-connections",
    "title": "Comparing means among groups",
    "section": "Non-parametric connections",
    "text": "Non-parametric connections\nOptions for when assumptions of the t- and F-tests (ANOVAs) are presented below. Note given the history of t-tests being considered apart from ANOVAs, some functions only work with less than 2 populations while others work with three or more. However, the overall approaches are similar.\n\nRanks: Wilcoxon/Mann-Whitney U and Kruskal-Wallis test\nWe can extend the Wilcoxon test to 2-samples. To do so, we rank the data points from smallest to largest. The ranks are then used to calculate a U statistic. The statistic sums the ranks for each group (r), then uses them to calculate\n\\[\nU_1 = n_1n_2+\\frac{n_1(n_1+1)}{2}-r_1\n\\] The U statistics is calculated for each group. The larger U value is then taken and used to compute a p value. We can calculate this using the wilcox.test function,\n\nwilcox.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.869e-07\nalternative hypothesis: true location shift is not equal to 0\n\n\nThis test assumes the two distributions being considered have similar shape (not that the resulting means are normally-distributed). If you remove the default continuity correction (applied as we approximate discrete data with a continuous distribution)\n\nwilcox.test(Sepal.Length ~ Species, two_species_subset, correct=F)\n\n\n    Wilcoxon rank sum test\n\ndata:  Sepal.Length by Species\nW = 526, p-value = 5.765e-07\nalternative hypothesis: true location shift is not equal to 0\n\n\nWe get the same result as the Kruskal-Wallis test\n\nkruskal.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 24.989, df = 1, p-value = 5.765e-07\n\n\nwhich is a rank-based test that can be applied to 3+ populations.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\n\nIf we have more than three populations and this omnibus test reveals a significant p-value, we can follow it up with appropriate post-hoc tests.\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\n\n\nSign/Binary approach\nFor a single sample, we also considered the sign/binary test. We will return to this test in the next chapter, as it does not work for data from independent samples.\n\n\nBootstrapping\nAnother option is to extend the bootstrapping option. Although we could again develop a simulation using the boot function again, here we again use the MKinfer package.\n\nlibrary(MKinfer)\n\nWarning: package 'MKinfer' was built under R version 4.2.3\n\nboot.t.test(Sepal.Length ~ Species, two_species_subset)\n\n\n    Bootstrap Welch Two Sample t-test\n\ndata:  Sepal.Length by Species\nbootstrap p-value &lt; 2.2e-16 \nbootstrap difference of means (SE) = -0.6487257 (0.1144229) \n95 percent bootstrap percentile confidence interval:\n -0.8760 -0.4239\n\nResults without bootstrap:\nt = -5.6292, df = 94.025, p-value = 1.866e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.8819731 -0.4220269\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nnote we can also run this test without assuming variances are different.\n\nboot.t.test(Sepal.Length ~ Species, two_species_subset, var.equal=T)\n\n\n    Bootstrap Two Sample t-test\n\ndata:  Sepal.Length by Species\nbootstrap p-value &lt; 2.2e-16 \nbootstrap difference of means (SE) = -0.652117 (0.1316271) \n95 percent bootstrap percentile confidence interval:\n -0.910 -0.396\n\nResults without bootstrap:\nt = -5.6292, df = 98, p-value = 1.725e-07\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.8818516 -0.4221484\nsample estimates:\nmean in group versicolor  mean in group virginica \n                   5.936                    6.588 \n\n\nBoth these approaches also show the corresponding t-test results, but note you should choose which test you plan to use before seeing the results!\nFor more than 2 groups, the t1waybt function in the WRS2 package can allow comparison.\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\n\nIf needed, the mcppb20 package allows for appropriate post-hoc comparisons.\n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\nbootstrap_post_hoc_df &lt;-data.frame(bootstrap_post_hoc$comp)\nbootstrap_post_hoc_df$adjusted_p &lt;- p.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\nbootstrap_post_hoc_df$Group &lt;- factor(bootstrap_post_hoc_df$Group)\nlibrary(plyr)\nbootstrap_post_hoc_df$Group &lt;- revalue(bootstrap_post_hoc_df$Group,\n                                       setNames(                                      bootstrap_post_hoc$fnames,as.character(1:length(bootstrap_post_hoc$fnames))))\n\nThe following `from` values were not present in `x`: 3\n\nbootstrap_post_hoc_df$Group.1 &lt;- factor(bootstrap_post_hoc_df$Group.1)\n\nbootstrap_post_hoc_df$Group.1 &lt;- revalue(bootstrap_post_hoc_df$Group.1,\n                                       setNames(                                      bootstrap_post_hoc$fnames,as.character(1:length(bootstrap_post_hoc$fnames))))\n\nThe following `from` values were not present in `x`: 1\n\nbootstrap_post_hoc_df\n\n       Group    Group.1     psihat  ci.lower   ci.upper p.value adjusted_p\n1     setosa versicolor -0.9100000 -1.143333 -0.7266667       0          0\n2     setosa  virginica -1.5466667 -1.836667 -1.3066667       0          0\n3 versicolor  virginica -0.6366667 -0.930000 -0.3666667       0          0\n\n\n\n\nPermutation\nA new option when comparing groups (2 or more) is known as the permutation test. We encountered a similar approach when we learned about the Fisher’s test for binomial data. Using this approach, we can move the measurements between measured populations, calculate test statistics, and consider how unusual our observed statistic was (a p value!). We can do this for 2\n\nlibrary(coin)\nindependence_test(Sepal.Length ~ Species, data =  two_species_subset)\n\n\n    Asymptotic General Independence Test\n\ndata:  Sepal.Length by Species (versicolor, virginica)\nZ = -4.9183, p-value = 8.731e-07\nalternative hypothesis: two.sided\n\n\nor 3+ populations\n\nindependence_test(Sepal.Length ~ Species, data =  iris)\n\n\n    Asymptotic General Independence Test\n\ndata:  Sepal.Length by Species (setosa, versicolor, virginica)\nmaxT = 8.7572, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nPost-hoc test options are available in the rcompanion package.\n\nlibrary(rcompanion)\n\nWarning: package 'rcompanion' was built under R version 4.2.3\n\n\n\nAttaching package: 'rcompanion'\n\n\nThe following object is masked from 'package:MKinfer':\n\n    quantileCI\n\npairwisePermutationTest(Sepal.Length ~ Species,\n                             data = iris,\n                             method=\"holm\")\n\n                  Comparison   Stat   p.value  p.adjust\n1    setosa - versicolor = 0 -7.246  4.28e-13 8.560e-13\n2     setosa - virginica = 0 -8.368 5.883e-17 1.765e-16\n3 versicolor - virginica = 0 -4.918 8.731e-07 8.731e-07"
  },
  {
    "objectID": "content/chapters/Compare_means_among_populations.html#next-steps",
    "href": "content/chapters/Compare_means_among_populations.html#next-steps",
    "title": "Comparing means among groups",
    "section": "Next steps",
    "text": "Next steps\nOur following chapters will extend ANOVAs to consider the impact of multiple measured categories. In doing so, we will also explain paired t-tests and sign tests for paired data."
  },
  {
    "objectID": "content/chapters/Estimation.html",
    "href": "content/chapters/Estimation.html",
    "title": "Estimation and uncertainty",
    "section": "",
    "text": "Now that we can describe data distributions, we want to start thinking about how we quantify the uncertainty in our estimates (of \\(\\mu\\), for example). Remember, we typically want to describe a population but need to rely on a sample, and we’ve already talked about sampling error. So now we just want to think about how much error we typically have (or, alternatively, how precise are our estimates).\nAnswering this question is hard. Quantifying sampling error requires you to know the “true” value for a population parameter, but we only have estimates! Statisticians solve this problem by investigating sampling error in populations they fully know because they created them."
  },
  {
    "objectID": "content/chapters/Estimation.html#lets-start-with-an-example",
    "href": "content/chapters/Estimation.html#lets-start-with-an-example",
    "title": "Estimation and uncertainty",
    "section": "Let’s start with an example",
    "text": "Let’s start with an example\nFor example, let’s assume we measure all the males in a population. Furthermore, let’s assume the distribution of heights is normal. Remember, this means the distribution is roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate. In fact, in turns out ~95% of the data lies within two standard deviations (remember those?) of the mean (so we calculate the mean and then the standard deviation. We then subtract the standard deviation from the mean to find a lower bound. We then add the standard deviation from the mean to find an upper bound. These bounds denote where 95% of the data points will be found).\nLet’s see this in action. First, lets make a population with a trait (let’s assume height, measured in cm, that follows a normal distribution. We can set the mean to 70 and the standard deviation to 3.\n\nset.seed(42)\npopulation_size &lt;- 10000\npopulation_norm &lt;- data.frame(id = 1:population_size, \n                         height = rnorm(population_size, 70, 3))\n\nNow’s let graph it.\n\nlibrary(ggplot2)\n\nggplot(population_norm, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow let’s add the mean (69.97 cm) and mark two standard deviations (sd = 3.02 in) above and below it. Remember we noted a benefit of using standard deviations to describe spread was that they were in the same units as the mean? Now we can use that!\n\ncolors &lt;- c(\"mean\" = \"black\", \"2 standard deviations below\" = \"red\", \n            \"2 standard deviations above\" = \"green\")\nggplot(population_norm, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(height), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(height)-\n                     2*sd(height), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(height)+\n                     2*sd(height), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 1200, x = mean(population_norm$height), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 1200, x = mean(population_norm$height)-\n                     2*sd(population_norm$height), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 1200, x = mean(population_norm$height)+\n                     2*sd(population_norm$height), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 1: Our imaginary population!\n\n\n\n\nThis bound captures 95.53% of the data.\nNow let’s sample the population. We’ll start by drawing a sample of 100 from the population. This is true random sampling, so any differences are due to sampling error.\n\nsample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\nggplot(sample_1, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of 100 random males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFor this sample, we have a mean of 69.78 cm and a standard deviation of 3.11 cm."
  },
  {
    "objectID": "content/chapters/Estimation.html#moving-to-a-sample-of-means",
    "href": "content/chapters/Estimation.html#moving-to-a-sample-of-means",
    "title": "Estimation and uncertainty",
    "section": "Moving to a sample of means",
    "text": "Moving to a sample of means\nHere’s the tricky part. We typically only have one sample, but we want to discuss the uncertainty in our estimate. So, let’s explore this by drawing multiple samples (each of 100 individuals) from our population and finding the mean for each sample.\n\nnumber_of_samples &lt;- 1000\nsample_outcomes_1 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes_1$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes_1$sd[i] &lt;- sd(sample_1$height)\n  \n}\n\nThen let’s plot the means.\n\nggplot(sample_outcomes_1, aes(mean)) + \n    geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 100)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_1$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_1$mean)-\n                     2*sd(sample_outcomes_1$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_1$mean)+\n                     2*sd(sample_outcomes_1$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFor our sample of means (this should sound weird!), we have a mean of 69.98 in and a standard deviation of 0.3 cm\nNote this suggests the mean of our means is close to the true population value of \\(\\mu\\). But the spread of our means (their standard deviation) is much less than the spread of the actual population! How much less? Let’s consider a set of smaller samples (n = 20).\n\nsample_outcomes_2 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_2 &lt;- population_norm[sample(nrow(population_norm), 20),]\n  sample_outcomes_2$mean[i] &lt;- mean(sample_2$height)\n  sample_outcomes_2$sd[i] &lt;- sd(sample_2$height)\n  \n}\n\nggplot(sample_outcomes_2, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 20)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_2$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_2$mean)-\n                     2*sd(sample_outcomes_2$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_2$mean)+\n                     2*sd(sample_outcomes_2$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThis new sample of means has a mean of 69.96 in and a standard deviation of 0.66 cm So, the estimate for \\(\\mu\\) is still close to the same, but the standard deviation of our estimates is growing.\nThis is even more clear if we sample only 5 individuals.\n\nsample_outcomes_3 &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_3 &lt;- population_norm[sample(nrow(population_norm), 5),]\n  sample_outcomes_3$mean[i] &lt;- mean(sample_3$height)\n  sample_outcomes_3$sd[i] &lt;- sd(sample_3$height)\n  \n}\n\nggplot(sample_outcomes_3, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 5)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_3$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_3$mean)-\n                     2*sd(sample_outcomes_3$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_3$mean)+\n                     2*sd(sample_outcomes_3$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nwhere we find a mean of 69.97 in and a standard deviation of 1.33 cm.\nIf we facet the graphs (and let them share an x-axis) we can see this even better\n\nsample_outcomes_1$n=100\nsample_outcomes_2$n=20\nsample_outcomes_3$n=5\nsamples_all &lt;- rbind(sample_outcomes_1,sample_outcomes_2, sample_outcomes_3)\n\nggplot(samples_all, aes(mean)) + \n   geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples\",\n       color=\"Measure\") +  facet_wrap(~n, ncol=1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nYou can clearly see larger sample sizes lead to a more “clustered’ group of means (so there is less uncertainty in the measurements!). This is why larger estimates make us more confident in our estimates - the means we get are less likely to be far away! In other words, larger samples yield more precise estimates with lower spread (lower sampling error).\nWe call the standard deviation of our means the standard error. We can calculate this as\n\\[\n[\\sigma_{\\overline{Y}} = \\frac{\\sigma}{\\sqrt{n}}] \\sim [s_{\\overline{Y}} = \\frac{s}{\\sqrt{n}}]\n\\]\nAlso, note distribution of means was normal (which we will define even better in a few lectures!). For now, that means we can get 95% of the sample means within ~2 standard deviations of the mean of means, which is very close to the true mean. Conversely, if we use data from each sample to generate a an interval ~2 standard deviations above and below each sample mean, these intervals will contain the true mean 95% of the time. We call this range a 95% confidence interval. For example, let’s take take 20 samples of 100 individuals from our fake population, then calculate and plot their confidence intervals.\n\nnumber_of_samples &lt;- 20\nsample_outcomes &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA, se = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes$sd[i] &lt;- sd(sample_1$height)\n  sample_outcomes$se &lt;- sd(sample_1$height)/sqrt(100)\n}\nsample_outcomes$sample &lt;- as.factor(1:number_of_samples)\nggplot(sample_outcomes\n       , aes(x=sample, y=mean)) +\n  geom_point() +\n  geom_errorbar(aes(ymin=mean-(2*se), ymax=mean+(2*se)))+\n  geom_hline(aes(yintercept=mean(population_norm$height))) +\n  ylab(\"Mean\")+\n  xlab(\"Sample\")+\n  ggtitle(\"Variation in error bars\")\n\n\n\n\nNotice one of samples (#2) has a range that does not include the true mean of the population!\nA few other notes about confidence intervals\n\nConfidence interval for normally-distributed samples (like those described here!) should be symmetric around the mean. This will change slightly for non-normal data (which we may address with generalized linear models that use a binomial, Poisson, or gamma distribution).\nThe “~2” is based on sample size. The value actually trends towards 1.96 at large sample sizes, but at sample sizes over ten 2 is a good estimate. You may also here this total (the 2 multiplied by the standard error) referred to as the margin of error. We could also have other numbers. For example, we could have a 90% confidence interval.\n\n\n\nWould it be wider or narrower compared to a 95% interval?\n\nIf you are less confident in the interval (90% vs 95%), the interval itself will get smaller (only 90% of samples need to have the true mean!)\n\n\nConfidence bounds also exist. These are slightly different - we’ll explain them in a few chapters.\n(more complicated) Note these calculations assumes we have lots of samples, but we typically only have one. The average probability of the first 95% CI capturing the true sample mean is only around 83%\n\n\n\n\n\n\nNeed to see this another way?\n\nThese two simulations (produced by UBC) will allow you to see this another way!\n\nRelationship between sample size and distribution of sample means for samples from a normally distributed population\nConfidence intervals"
  },
  {
    "objectID": "content/chapters/Estimation.html#what-if-the-population-isnt-normal",
    "href": "content/chapters/Estimation.html#what-if-the-population-isnt-normal",
    "title": "Estimation and uncertainty",
    "section": "What if the population isn’t normal?",
    "text": "What if the population isn’t normal?\nFinally, it turns out the underlying distribution of data doesn’t matter; only that of the trait we are focused on does. For example, the means of the data will be normally distributed as long as you have a large sample size. This is know as the central limit theorem.\nTo prove this, let’s instead consider a uniform distribution:\n\npopulation_unif &lt;- data.frame(id = 1:population_size, \n                         height = runif(population_size, 60, 80))\nggplot(population_unif, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of all males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow, let’s do what we did above. First, draw a sample of 100\n\nsample_unif &lt;- population_unif[sample(nrow(population_unif), 100),]\nggplot(sample_unif, aes(height)) + \n  geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Height of 100 random males in our fake population\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNote the sample is still relatively uniformly distributed. This makes sense. In general, a good sample should resemble the underlying population, so this makes sense.\nNow let’s sample a 100 of these numerous times and plot the means of each sample.\n\nnumber_of_samples &lt;- 1000\nsample_outcomes_unif &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA)\n\nfor (i in 1:number_of_samples){\n  sample_unif &lt;- population_norm[sample(nrow(population_unif), 100),]\n  sample_outcomes_unif$mean[i] &lt;- mean(sample_unif$height)\n  sample_outcomes_unif$sd[i] &lt;- sd(sample_unif$height)\n}\nggplot(sample_outcomes_unif, aes(mean)) + \n    geom_histogram(color=\"black\") +\n  labs(x=\"Height (cm)\", y= \"Frequency\",\n       title = \"Mean heights from our samples (n = 100)\",\n       color=\"Measure\") +\n    geom_vline(aes(xintercept=mean(mean), color=\"mean\"))+\n    geom_vline(aes(xintercept=mean(mean)-\n                     2*sd(mean), color=\"2 standard deviations below\"))+\n  geom_vline(aes(xintercept=mean(mean)+\n                     2*sd(mean), color=\"2 standard deviations above\")) +\n        scale_color_manual(values = colors)+\n   annotate(\"text\", label = \"mean\", y = 150, x = mean(sample_outcomes_unif$mean), color = \"black\") +\n     annotate(\"text\", label = \"2 standard deviations \\n below\", y = 150, x = mean(sample_outcomes_unif$mean)-\n                     2*sd(sample_outcomes_unif$mean), color = \"red\")+\n     annotate(\"text\", label = \"2 standard deviations \\n above\", y = 150, x = mean(sample_outcomes_unif$mean)+\n                     2*sd(sample_outcomes_unif$mean), color = \"green\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNotice we are back to a normal distribution!\n\n\nNeed to see this another way?\n\nAnother UBC visualization will allow you to see this another way!\n\nCentral limit theorem: Sampling from non-normal distributions."
  },
  {
    "objectID": "content/chapters/Estimation.html#visualization-issues",
    "href": "content/chapters/Estimation.html#visualization-issues",
    "title": "Estimation and uncertainty",
    "section": "Visualization issues",
    "text": "Visualization issues\nAs you can see above, 95% confidence intervals are commonly graphed to show the potential spread of mean values. This distinction is important, as one could plot the standard deviation of the raw the data, the standard error of the related means, or the 95% confidence interval. These can be very different. As an example,let’s return to our normal population.\n\nnumber_of_samples &lt;- 1\nsample_outcomes &lt;- data.frame(mean = rep(NA, number_of_samples), sd = NA, se = NA)\n\nfor (i in 1:number_of_samples){\n  sample_1 &lt;- population_norm[sample(nrow(population_norm), 100),]\n  sample_outcomes$mean[i] &lt;- mean(sample_1$height)\n  sample_outcomes$sd[i] &lt;- sd(sample_1$height)\n  sample_outcomes$se &lt;- sd(sample_1$height)/sqrt(100)\n}\nsample_outcomes$sample &lt;- as.factor(1:number_of_samples)\n\nsample_1$sample &lt;- \"Data\"\nsample_1$data &lt;- sample_1$height\nonese &lt;- sample_outcomes\nonese$sample &lt;- \"+- 1 standard error\"\nonese$data &lt;- onese$mean\nonese$bar_length &lt;-  onese$se\ntwosd &lt;- sample_outcomes\ntwosd$sample &lt;- \"+- 2 standard error ~ \\n 95% confidence interval\"\ntwosd$data &lt;- twosd$mean\ntwosd$bar_length &lt;-  onese$se * 2\nonesd &lt;- sample_outcomes\nonesd$sample &lt;- \"+- 1 standard deviation\"\nonesd$data &lt;- onesd$mean\nonesd$bar_length &lt;-  onese$sd\n\nexample_clarity &lt;- merge(sample_1, onese, all.x =T, all.y = T)\nexample_clarity &lt;- merge(example_clarity, twosd, all.x =T, all.y = T)\nexample_clarity &lt;- merge(example_clarity, onesd, all.x =T, all.y = T)\n\nlibrary(plyr)\nexample_clarity$sample &lt;- relevel(as.factor(example_clarity$sample), \"Data\")\n\nggplot(example_clarity\n       , aes(x=sample, y=data)) +\n  geom_point() +\n  geom_errorbar(aes(ymin=mean-bar_length, ymax=mean+bar_length))+\n  labs(y =\"Height (cm)\", x= \"Frequency\",\n       title = \"Variation in error bar display\")\n\n\n\n\nNotice the differences! We will typically use 95% confidence intervals in class, but you should always specify in your captions and note when you read other papers!\nVisualizations of spread are commonly used with bar graphs (despite the earlier issues we noted with bar graphs!). For example, we can return to our iris data and add\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\nIn general, presenting the estimate for a parameter and measures of sampling error (or uncertainty) allow you to state the magnitude of a statistic. This is a different but related approach to the more commonly observed p-values (which we’ll get to!). For example, for a single population we can ask if the confidence interval includes a relevant value (like 0!). For multiple groups,we can consider if the true means are in the same range by looking at overlap in confidence intervals among the groups."
  },
  {
    "objectID": "content/chapters/Estimation.html#next-steps",
    "href": "content/chapters/Estimation.html#next-steps",
    "title": "Estimation and uncertainty",
    "section": "Next steps",
    "text": "Next steps\nIn this chapter we’ve started to talk about probability. In the next we will review some probability basics before we move onto testing hypotheses."
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html",
    "href": "content/chapters/More_ANOVAs.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "In the last chapter we introduced the idea of comparing means among populations (one-way ANOVAs, our first linear models). However, the units that we measure may belong to multiple groups. We will extend our analysis of variance to consider multiple group membership and interactions in this chapter. As a starting point, consider that group membership may be an inherent property of the unit we measure or we may assign it."
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#example-back-to-the-birds",
    "href": "content/chapters/More_ANOVAs.html#example-back-to-the-birds",
    "title": "More ANOVAs",
    "section": "Example: Back to the birds",
    "text": "Example: Back to the birds\nOne of the last chapters practice problems focused bird feathers. While studying feather color in Northern flickers (Colaptes auratus), Wiebe and Bortolotti (2002) noted that ~25% of birds had one or more “odd” tail feathers. They decided to compare the color of these odd and “typical” feathers.\n\n\n\nNorthern Flicker. Mike’s Birds, CC BY-SA 2.0 &lt;https://creativecommons.org/licenses/by-sa/2.0&gt;, via Wikimedia Commons\n\n\nExample and data provided by McDonald (2014).\n\nlibrary(rmarkdown)\npaged_table(feather)"
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#how-do-we-analyze-this-data",
    "href": "content/chapters/More_ANOVAs.html#how-do-we-analyze-this-data",
    "title": "More ANOVAs",
    "section": "How do we analyze this data?",
    "text": "How do we analyze this data?\nWe may first note that we have a continuous measurement (feather color, measured using color hues from a digital camera and another statistical technique that we will not go into here) and a categorical variable (feather type, with levels “typical” and “odd”). This hopefully reminds you of an ANOVA/t-test!\nWe could plot the data\n\nlibrary(ggplot2)\nggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type))+\n  geom_jitter()+\n  labs(y= \"Color index\",\n       x= \"Feather type\",\n       title=\"Comparing odd and typical feathers in Northern flickers\")+\n  guides(color=F)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\nDevelop a set of hypotheses:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{odd feather color}} = \\mu_{\\textrm{typical feather color}}\\\\\nH_A: \\mu_{\\textrm{odd feather color}} \\neq \\mu_{\\textrm{typical feather color}}\\\\\n\\end{split}\n\\]\nand test them using a t-test:\n\nt.test(Color_index ~ Feather_type, data=feather)\n\n\n    Welch Two Sample t-test\n\ndata:  Color_index by Feather_type\nt = -3.56, df = 29.971, p-value = 0.00126\nalternative hypothesis: true difference in means between group Odd and group Typical is not equal to 0\n95 percent confidence interval:\n -0.21579254 -0.05845746\nsample estimates:\n    mean in group Odd mean in group Typical \n            -0.176125             -0.039000 \n\n\nor, using more generalizable functions, a linear model:\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(lm(Color_index ~ Feather_type, data=feather), type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)  0.49632  1  41.816 3.814e-07 ***\nFeather_type 0.15043  1  12.674  0.001259 ** \nResiduals    0.35607 30                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe find a significant p value, but we did not check assumptions. For linear models (remember, $i.i.d. N(,)$, we could use our visual checks\n\nplot(lm(Color_index ~ Feather_type, data=feather))\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhich appears ok, but there is a problem.\nOur data are not independent!"
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#lack-of-independence",
    "href": "content/chapters/More_ANOVAs.html#lack-of-independence",
    "title": "More ANOVAs",
    "section": "Lack of Independence",
    "text": "Lack of Independence\nOdd and typical feathers were measured on a single bird (note the Bird column) in the dataset. We might assume feathers on a given bird are more closely related in color than feathers on different birds. This could be due to diet or other factors making all feathers on a given bird brighter or darker than those on another. Regardless of reason (and “good” p value), we know the measurements are linked in some way. Note we could “connect” individual observations.\n\nggplot(feather, aes(x=Feather_type, y= Color_index, color=Feather_type, group=Bird))+\n  geom_line(position = position_dodge(0.4), color=\"black\") +\n  geom_point(position = position_dodge(0.4)) +  \n  labs(y= \"Color index\",\n       x= \"Feather type\",\n       title=\"Comparing odd and typical feathers in Northern flickers\")+\n  guides(color=F)\n\n\n\n\nThis may also occur if we measure outcomes with-in a single unit (e.g., a study of fertilizer impacts using multiple fields) or over time (e.g., before/after studies). Regardless of the reason, when our experimental design has led to measurements being connected/not independent, we need to consider these connections in order to properly note (and sometimes even observe) impacts of focal variables."
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#blocking-two-way-anovasand-paired-t-tests",
    "href": "content/chapters/More_ANOVAs.html#blocking-two-way-anovasand-paired-t-tests",
    "title": "More ANOVAs",
    "section": "Blocking, two-way ANOVAs,and paired t-tests",
    "text": "Blocking, two-way ANOVAs,and paired t-tests\nIn this case, the connections may be considered artifacts of the data. We didn’t assign birds. We also made a choice to compare odd and typical feathers from the same bird - why? In general, accounting for extra variation in the data will give you a better answer about how a given variable influences outcomes. This may be called blocking. Although the motivation might therefore be to get a “better” p value, it should be driven by experimental design (and thus we started with an example where we didn’t “need” to account for it to achieve significance).\nIn order to consider how color differs by bird and feather type, we need to add both variables to our linear model. For each variable we add, we also add a null (and corresponding alternative) hypothesis. So we retain our focus on feather type:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{odd feather color}} = \\mu_{\\textrm{typical feather color}}\\\\\nH_A: \\mu_{\\textrm{odd feather color}} \\neq \\mu_{\\textrm{typical feather color}}\\\\\n\\end{split}\n\\]\nbut also add a set of hypotheses focused on birds:\n\\[\n\\begin{split}\nH_O: \\mu_{\\textrm{color of bird A}} = \\mu_{\\textrm{color of bird B}}....\\textrm{for all birds}\\\\\nH_A: \\mu_{\\textrm{color of bird A}} \\neq \\mu_{\\textrm{color of bird B}}....\\textrm{for all birds}\\\\\n\\end{split}\n\\]\nWe can analyze this using our linear model approach. This is possible because, as we noted earlier, we can subdivide variance among multiple levels. Under the hood, the linear model approach build a model matrix that considers the impact of feather type and bird on outcomes. Since both variables are categorical, this is often called a two-way ANOVA. First, let’s make the object\n\ntwo_way_anova_example &lt;- lm(Color_index ~ Feather_type + Bird, data=feather)\n\n\n\nYou can see the new model matrix and coefficients if you want\n\nNote the model matrix now includes columns for feather type and bird (lots of dummy variables, and now intercept is Bird A’s odd feather!). The \\(\\beta\\) matrix of coefficients has corresponding estimates.\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(two_way_anova_example)))\n\n\n\n  \n\n\nmatrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n            [,1]\n [1,] -0.3580625\n [2,]  0.1371250\n [3,]  0.0905000\n [4,]  0.0450000\n [5,]  0.1250000\n [6,]  0.2535000\n [7,]  0.2575000\n [8,]  0.1500000\n [9,]  0.2525000\n[10,]  0.2885000\n[11,]  0.2150000\n[12,]  0.2530000\n[13,]  0.1445000\n[14,]  0.1365000\n[15,]  0.2190000\n[16,]  0.2530000\n[17,]  0.2275000\n\n\nSo for our first observation, which is\n\nfeather[1,]\n\n  Bird Feather_type Color_index\n1    A      Typical      -0.255\n\n\nOur estimate is the intercept (since it’s bird A) and the typical feather:\n\nmodel.matrix(two_way_anova_example)[1,] %*% matrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n           [,1]\n[1,] -0.2209375\n\n\nand thus our residual is\n\ntwo_way_anova_example$residuals[1]\n\n         1 \n-0.0340625 \n\n\nwhich is the same as\n\nfeather[1,]$Color_index-model.matrix(two_way_anova_example)[1,] %*% matrix(as.numeric(two_way_anova_example$coefficients), ncol=1)\n\n           [,1]\n[1,] -0.0340625\n\n\n\nThen check the assumptions\n\nplot(two_way_anova_example)\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote, visually speaking, the residuals do appear to be closer to normal now. Since assumptions look ok, we can analyze the outcome\n\nsummary(two_way_anova_example)\n\n\nCall:\nlm(formula = Color_index ~ Feather_type + Bird, data = feather)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.12444 -0.05209  0.00000  0.05209  0.12444 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         -0.35806    0.06955  -5.148 0.000119 ***\nFeather_typeTypical  0.13712    0.03374   4.065 0.001017 ** \nBirdB                0.09050    0.09542   0.948 0.357936    \nBirdC                0.04500    0.09542   0.472 0.643998    \nBirdD                0.12500    0.09542   1.310 0.209903    \nBirdE                0.25350    0.09542   2.657 0.017950 *  \nBirdF                0.25750    0.09542   2.699 0.016505 *  \nBirdG                0.15000    0.09542   1.572 0.136802    \nBirdH                0.25250    0.09542   2.646 0.018330 *  \nBirdI                0.28850    0.09542   3.023 0.008554 ** \nBirdJ                0.21500    0.09542   2.253 0.039643 *  \nBirdK                0.25300    0.09542   2.651 0.018139 *  \nBirdL                0.14450    0.09542   1.514 0.150719    \nBirdM                0.13650    0.09542   1.431 0.173069    \nBirdN                0.21900    0.09542   2.295 0.036567 *  \nBirdO                0.25300    0.09542   2.651 0.018139 *  \nBirdP                0.22750    0.09542   2.384 0.030759 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.09542 on 15 degrees of freedom\nMultiple R-squared:  0.7304,    Adjusted R-squared:  0.4427 \nF-statistic: 2.539 on 16 and 15 DF,  p-value: 0.03923\n\nAnova(two_way_anova_example, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df F value   Pr(&gt;F)    \n(Intercept)  0.24133  1 26.5059 0.000119 ***\nFeather_type 0.15043  1 16.5214 0.001017 ** \nBird         0.21950 15  1.6072 0.184180    \nResiduals    0.13657 15                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNote we see a significant difference in color among birds and feather type. Although we may be tempted to (and could) use post-hoc tests to consider which birds are different than which others, this is typically not done for blocked variables. We did not assign these pairings and it is not the focus of our efforts.\nSince we only had 2 types of feathers, we also don’t need post-hoc tests. A significant p value means they differ from each other, and the estimates provided by the summary command indicate the typical feathers have a higher color index.\n\nt-test connections\nWhen we have only two measurements per group (e.g., odd and typical feathers from each bird), we can use a t-test approach to achieve similar goals. This approach is known as a paired t-test. Instead of focusing on the difference in means (like a 2-sample t-test), the test focuses on the mean difference between paired measurements (which would be 0 under the null hypothesis!). In this way, it is effectively a one-sample test that is pairing the data to reduce variation (blocking). We can do carry out the test:\n\nt.test(Color_index ~ Feather_type, data=feather, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  Color_index by Feather_type\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean difference \n      -0.137125 \n\n\nand get the same results as above (note we don’t even have to consider corrections like the Welch approach since this a one-sample test). Common examples of paired t-tests include before-after and twin studies.\nIn an earlier chapters we considered options for one- and two-sample tests when t-tests assumptions were not met. For two-sample tests, one of these approaches, the sign or binary test, is only valid for paired data. The differences in paired observations are compared to a set value (typically 0). Under the null hypothesis, half should be below the proposed median and half should be above. Differences matching the proposed value are ignored, thus reducing the sample size and making it harder to reject the null hypothesis; this is actually an odd way of accounting for them. The proportion of values below the proposed median is then evaluated using a binomial test. For two sample, the SIGN.test function in the BSDA package requires 2 columns of data and assumes the order of the column represents paired data.\n\nlibrary(BSDA)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'BSDA'\n\n\nThe following objects are masked from 'package:carData':\n\n    Vocab, Wool\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nSIGN.test(feather[feather$Feather_type == \"Odd\", \"Color_index\"], \n          feather[feather$Feather_type == \"Typical\", \"Color_index\"],\n          md = 0)\n\n\n    Dependent-samples Sign-Test\n\ndata:  feather[feather$Feather_type == \"Odd\", \"Color_index\"] and feather[feather$Feather_type == \"Typical\", \"Color_index\"]\nS = 3, p-value = 0.02127\nalternative hypothesis: true median difference is not equal to 0\n95 percent confidence interval:\n -0.24048275 -0.02331055\nsample estimates:\nmedian of x-y \n       -0.114 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level  L.E.pt  U.E.pt\nLower Achieved CI     0.9232 -0.2400 -0.0320\nInterpolated CI       0.9500 -0.2405 -0.0233\nUpper Achieved CI     0.9787 -0.2410 -0.0140\n\n\n\n\nMore than 2 measurements? Back to the linear model\nWe can also block for variation when we take more than 2 measurements per unit. For example, imagine if these birds also had a special, long tail feather.\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather_type = \"Special\", \n                      Color_index= feather[feather$Feather_type == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather_extra &lt;- merge(feather, special, all = T)\nfeather_extra$Feather_type &lt;- factor(feather_extra$Feather_type)\n\nWe could still block for variation using the linear model/ANOVA, but not the t-test, approach. As another review, we create the model\n\nmore_blocks &lt;-lm(Color_index ~ Feather_type + Bird, data=feather_extra)\n\nCheck assumptions\n\nplot(more_blocks)\n\n\n\n\n\n\n\n\n\n\n\n\n\nCheck outcome (this time focusing on Anova output)\n\nAnova(more_blocks, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n              Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)  0.36392  1  59.9538 1.224e-08 ***\nFeather_type 1.67906  2 138.3093 7.208e-16 ***\nBird         0.34649 15   3.8055 0.0008969 ***\nResiduals    0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nWe still see feather type has a significant impact on color, but since we have more than 2 groups we need to follow up this finding with a post-hoc test.\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncompare &lt;- glht(more_blocks, linfct = mcp(Feather_type = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather_type + Bird, data = feather_extra)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nSpecial - Odd == 0      0.44713    0.02755  16.232   &lt;1e-04 ***\nTypical - Odd == 0      0.13713    0.02755   4.978   &lt;1e-04 ***\nTypical - Special == 0 -0.31000    0.02755 -11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)"
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#other-ways-to-be-in-multiple-groups",
    "href": "content/chapters/More_ANOVAs.html#other-ways-to-be-in-multiple-groups",
    "title": "More ANOVAs",
    "section": "Other ways to be in multiple groups",
    "text": "Other ways to be in multiple groups\nIn the bird example, one of our categories (bird) was un-intential. We chose to measure odd and typical feathers, and accounting for variation among birds was an appropriate step given lack of independence in measurements. However, we can also assign units to multiple groups (instead of making multiple measurements within one unit).\nConsider if we ran an experiment focused on the impact of factors A and B on some trait. We can fully cross the factors in an experiment. Doing so can let us consider the main effects of multiple variables and potential interactions among them in what is often called a factorial ANOVA. For starters, let each factor have only 2 levels, and let the levels be the absence or presence of the factor.\n\n\n\n\nFactor A\n\n\n\nFactor B\nAbsent\nPresent\n\n\nAbsent\nControl\nImpact of A only\n\n\nPresent\nImpact of B only\nCombined impact of A+B\n\n\n\n\n\nExperimental design notes\n\nFor a factorial ANOVA, we need to assign each unit randomly to a level of factor A. Then each level of factor B is randomly assigned to subjects at each level of factor A. This is different than randomly assigning treatments of A and B, as that could lead to outcomes where some level of factor B is not represented in some level of factor A.\nWe also need multiple units (3+) assigned to each combination.\n\nWhen both are absent we have a classic control outcome. When one is present and the other absent we see main effects impacts of only one factor. Note we previously analyzed experiments that considered only one factor using ANOVAs or t-tests (linear models), but now we have multiple factors. We should not analyze the main effects of each using 2 one-way ANOVAs. Doing so cuts our data in half, meaning our estimates of variances are less precise and we increase our chance of making a type 1 error. More importantly, we wouldn’t be able to properly consider the combined impacts of A + B. What could these be?\n\nexample_interaction &lt;- data.frame(Treatment = c(rep(\"Control\",5),\n                                                rep(\"Impact of A only\",5),\n                                                rep(\"Impact of B only\",5),\n                                                rep(\"A+B Additive\",5), \n                                                rep(\"A+B Synergistic\", 5),\n                                                rep(\"A+B Antagonistic\", 5)), \n                                  Cause= rep(c(\"Control\",\"Factor A\",\"Factor B\", \"Synergistic\", \"Antagonistic\"), 6),\n                                  Impact = c(5,0,0,0,0,\n                                             5,2,0,0,0,\n                                             5,0,3,0,0,\n                                             5,2,3,0,0,\n                                             0,0,0,20,0,\n                                             0,0,0,0,6))\nexample_interaction$Treatment &lt;- factor(example_interaction$Treatment, levels=c(\"Control\",\"Impact of A only\",\"Impact of B only\", \"A+B Additive\", \"A+B Synergistic\", \"A+B Antagonistic\"))\nexample_interaction$Cause &lt;- factor(example_interaction$Cause, levels=c(\"Control\",\"Factor A\",\"Factor B\", \"Synergistic\", \"Antagonistic\"))\nggplot(example_interaction, aes(x=Treatment, y= Impact, fill= Cause))+\n  geom_col(position = position_stack(reverse = TRUE))+\n  theme(axis.text.x = element_text(angle = -45))\n\n\n\n\nAs shown in the graph (Inspired by (Fong, Bittick, and Fong 2017)), A and B could have additive effects (where they simply stack), synergistic effects (the combined impact is more than the sum of the two), or antagonistic effects (the combined impacts is less than the sum of the two). Synergistic and antagonistic impacts are both examples of interactions. Interactions occur when the impact of one variable depends on the level of another.\n\nExample: Impacts of grazing and fertilization\nWe can extend this example to consider more than 2 levels for one or more factors. For example, Valdez et al. (2023) wanted to consider the impact of top-down (snail grazing) and bottom- up (nutrient availability) on marsh plant (Spartina alterniflora) growth. To do this, they assigned plots to one of 3 grazer treatments and one of 2 nitrogen treatments.\n\n\n\nFig 1 from Valdez et al. 2003. Map and conceptual illustration of experimental design.\n\n\nThis design is different from the bird example. No two measurements for a given trait were taken on the same plot. In this case, we likely care about the main effects, or impacts, of both variables. However, we may also need to consider interactions among the variables. Interactions occur when the impact of one variable depends on the level of another. For example, snail removal might have major impacts on nitrogen-enriched plots while having no impact on ambient plots. Due to this, we now have even more hypotheses:\n\\[\n\\begin{split}\nH_O: \\mu_\\textrm{plant growth, no fertilizer} = \\mu_\\textrm{plant growth, fertilizer}\\\\\nH_O: \\mu_\\textrm{plant growth, snails removed} = \\mu_\\textrm{plant growth, control snails}= \\mu_\\textrm{plant growth, snails added}\\\\\nH_O: \\textrm{impact of snail grazing does not depend on nitrogen level}\\\\\n\\end{split}\n\\]\nFortunately, these are easy to consider in our linear model framework. While not shown here, the model matrix adds columns to note our new interaction terms, and the coefficient matrix estimates them. From an R standpoint, we can include the interaction between two variables using the “:” notation. We’ll focus on below-ground biomass (standardized to m2) for this example (the paper measured 9 response variables!)\n\nvaldez_2023 &lt;- read.csv(\"data/Spartina_alterniflora_traits.csv\", stringsAsFactors = T)\nbgb_model &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023)\n\nFor shorthand, note that if we put main effect * main effect in a model, it automatically adds the interaction term. You can see the model summary is the same.\n\nbgb_model_shorthand &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level * Nitrogen.level, valdez_2023)\nsummary(bgb_model)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level + \n    Snail.Level:Nitrogen.level, data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\nsummary(bgb_model_shorthand)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\n\nYou may note a weird NA here (we’ll come back to it), but remember we should really check model assumptions before looking at output.\n\nplot(bgb_model)\n\n\n\n\n\n\n\n\n\n\n\n\n\nThese look ok. There may be a slight increase in variance with fitted values, but we can work with this. Let’s build an ANOVA table.\n\nAnova(bgb_model, type=\"III\")\n\nError in Anova.III.lm(mod, error, singular.ok = singular.ok, ...): there are aliased coefficients in the model\n\n\nBut we got an error! What happened? Let’s look at the data\n\npaged_table(valdez_2023)\n\n\n\n  \n\n\n\nA summary may help more. Note we can summarize across multiple factors.\n\nlibrary(Rmisc)\n\nLoading required package: plyr\n\npaged_table(summarySE(valdez_2023, measurevar = \"below.biomass.g.meter.sq..m2..\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\")))\n\n\n\n  \n\n\n\nNote the uncaged treatment only has without for the nitrogen impact. It was a control! While we often need these in experiments, they can create analysis problems. This is because we can’t consider how nutrient level depends on snail treatment for the control level! In other words, interactions can not be calculated for some levels.\nThis is also why we saw the NA and warnings in our model summary\n\nsummary(bgb_model)\n\n\nCall:\nlm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level + \n    Snail.Level:Nitrogen.level, data = valdez_2023)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-103.003  -50.933    1.507   28.297  153.937 \n\nCoefficients: (1 not defined because of singularities)\n                                                Estimate Std. Error t value\n(Intercept)                                       542.16      40.72  13.315\nSnail.Levelremoval                                 33.58      57.58   0.583\nSnail.Levelsnail addition                         -88.85      57.58  -1.543\nSnail.Leveluncaged                                 45.09      57.58   0.783\nNitrogen.levelwithout                            -111.87      57.58  -1.943\nSnail.Levelremoval:Nitrogen.levelwithout           43.39      81.44   0.533\nSnail.Levelsnail addition:Nitrogen.levelwithout    60.18      81.44   0.739\nSnail.Leveluncaged:Nitrogen.levelwithout              NA         NA      NA\n                                                Pr(&gt;|t|)    \n(Intercept)                                     2.44e-09 ***\nSnail.Levelremoval                                0.5691    \nSnail.Levelsnail addition                         0.1451    \nSnail.Leveluncaged                                0.4467    \nNitrogen.levelwithout                             0.0724 .  \nSnail.Levelremoval:Nitrogen.levelwithout          0.6025    \nSnail.Levelsnail addition:Nitrogen.levelwithout   0.4721    \nSnail.Leveluncaged:Nitrogen.levelwithout              NA    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 70.53 on 14 degrees of freedom\nMultiple R-squared:  0.498, Adjusted R-squared:  0.2829 \nF-statistic: 2.315 on 6 and 14 DF,  p-value: 0.09183\n\n\nYou could note we have the same issue for our initial bird analysis:\n\ntwo_way_anova_example_int &lt;- lm(Color_index ~ Feather_type * Bird, data=feather)\nAnova(two_way_anova_example_int, type=\"III\")\n\nError in Anova.lm(two_way_anova_example_int, type = \"III\"): residual df = 0\n\n\nOn a positive note, this means R will typically not consider interactions when it shouldn’t, but you need to know why in order to fix it.\n\n\nDealing with controls and missing interactions\nTo fix this (and deal with controls), we need to consider the data. Valdez et al. (2023) used t-tests (why?) to consider differences between cage and cage control plots (note %in% and the fact they did not focus on above-ground biomass (maybe because uncaged plots had little..). %in% allows you to subset data by matching items to list. Remember you can always get help on functions using something like (we need the quotations for operators!)\n\n?'%in%'\n\n\nt.test(below.biomass.g.meter.sq..m2..~Snail.Level, valdez_2023[valdez_2023$Snail.Level %in% c(\"uncaged\",\"control snails\") & valdez_2023$Nitrogen.level == \"without\",])\n\n\n    Welch Two Sample t-test\n\ndata:  below.biomass.g.meter.sq..m2.. by Snail.Level\nt = -0.82961, df = 3.9666, p-value = 0.4538\nalternative hypothesis: true difference in means between group control snails and group uncaged is not equal to 0\n95 percent confidence interval:\n -196.4785  106.3052\nsample estimates:\nmean in group control snails        mean in group uncaged \n                    430.2967                     475.3833 \n\n\nIf interactions are missing for other reasons (e.g., a set of units failed/died/data was lost), we can either ignore interactions or combine factor levels into a single new treatment variable and analyze using one-way ANOVAs.\n\n\nConsidering interactions\nTo consider interactions, we can remove the controls\n\nbgb_model_cont_removed &lt;-lm(below.biomass.g.meter.sq..m2..~Snail.Level + Nitrogen.level + Snail.Level:Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\n\nWe can consider the assumptions\n\nplot(bgb_model_cont_removed)\n\n\n\n\n\n\n\n\n\n\n\n\n\nand now note …\n\nAnova(bgb_model_cont_removed, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: below.biomass.g.meter.sq..m2..\n                           Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)                881823  1 176.4820 1.545e-08 ***\nSnail.Level                 24012  2   2.4028   0.13254    \nNitrogen.level              18771  1   3.7567   0.07648 .  \nSnail.Level:Nitrogen.level   2893  2   0.2895   0.75371    \nResiduals                   59960 12                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n…that the ANOVA table works.\n\n\nIntepreting interactions\n\nWhen not significant\nIf interactions are not significant, they can be handled in 2 ways.\n\nWe can leave the interaction in the model and interpret main effects immediately\nWe can remove the interaction from the model, re-run it, and interpret main effects of the factors.\n\nbgb_model_cont_removed_int_removed &lt;- update(bgb_model_cont_removed, .~.-Snail.Level:Nitrogen.level)\nplot(bgb_model_cont_removed_int_removed)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(bgb_model_cont_removed_int_removed, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: below.biomass.g.meter.sq..m2..\n                Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept)    1239848  1 276.1645 1.303e-10 ***\nSnail.Level      39024  2   4.3461   0.03402 *  \nNitrogen.level   26919  1   5.9959   0.02812 *  \nResiduals        62853 14                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nRegardless, we can interpret main effects (though with possibly different outcomes). The benefit of approach 2 is we “increase” the degrees of freedom associated with the residuals, which ends up reducing the the MST. This is because in 2-way ANOVAs we allocate degrees of freedom to calculating main effects and interactions. This approach was likely used in the original manuscript.\nSimply using the the provided output (approach 1) and not perform another series of tests, however, reduces the chances for a Type 1 error. We will return to this discussion when we get to model selection.\nIf we see significant effects of a factor that has more than 2 levels (like we do when using the approach that drops insignificant interactions), we can consider the general impact of grazing levels using post-hoc tests:\n\nsummary(glht(bgb_model_cont_removed_int_removed, linfct = mcp(Snail.Level = \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = below.biomass.g.meter.sq..m2.. ~ Snail.Level + Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)  \nremoval - control snails == 0           55.27      38.68   1.429   0.3534  \nsnail addition - control snails == 0   -58.76      38.68  -1.519   0.3123  \nsnail addition - removal == 0         -114.03      38.68  -2.948   0.0267 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nWhen significant\nIf the interaction term is significant, it means the main effects can not be interpreted. This is because the impact of a given variable depends on the level of another. When this happens, the data is typically divided into subset and analyzed using one-way ANOVAs.\nFor example, when Valdez et al. (2023) analyzed standing dead mass, they found a significant interaction term:\n\nsdm_model &lt;-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",])\nplot(sdm_model)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n                            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)                1050.19  1 328.463 4.392e-10 ***\nSnail.Level                 300.82  2  47.042 2.095e-06 ***\nNitrogen.level              348.39  1 108.963 2.248e-07 ***\nSnail.Level:Nitrogen.level  200.90  2  31.417 1.700e-05 ***\nResiduals                    38.37 12                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nFollowing this, you could investigate impacts in plots with nitrogen, where you find snail manipulation had a significant impact (and considered post-hoc which ones!)\n\nsdm_model_fertilized &lt;-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\" & valdez_2023$Nitrogen.level == \"Fertilized\",])\nplot(sdm_model_fertilized)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_fertilized, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 1050.19  1 206.027 7.158e-06 ***\nSnail.Level  300.82  2  29.507  0.000786 ***\nResiduals     30.58  6                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(glht(sdm_model_fertilized, linfct = mcp(Snail.Level= \"Tukey\")))\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Standing.Dead..dry..m2. ~ Snail.Level, data = valdez_2023[valdez_2023$Snail.Level != \n    \"uncaged\" & valdez_2023$Nitrogen.level == \"Fertilized\", ])\n\nLinear Hypotheses:\n                                     Estimate Std. Error t value Pr(&gt;|t|)    \nremoval - control snails == 0         -14.150      1.843  -7.676   &lt;0.001 ***\nsnail addition - control snails == 0   -7.567      1.843  -4.105   0.0150 *  \nsnail addition - removal == 0           6.583      1.843   3.571   0.0272 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nand plots without added nutrients, where you find snail addition did not\n\nsdm_model_not_fertilized &lt;-lm(Standing.Dead..dry..m2.~Snail.Level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\" & valdez_2023$Nitrogen.level == \"without\",])\nplot(sdm_model_not_fertilized)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_not_fertilized, type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept) 36.123  1 27.8457 0.001871 **\nSnail.Level 12.416  2  4.7856 0.057211 . \nResiduals    7.783  6                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nOther approaches for dealing with significant interactions include directly interpreting interaction terms (which we can do given our understanding of linear model coefficients), but this is rarely used. They are somewhat messy\n\ncoef(sdm_model)\n\n                                    (Intercept) \n                                      18.710000 \n                             Snail.Levelremoval \n                                     -14.150000 \n                      Snail.Levelsnail addition \n                                      -7.566667 \n                          Nitrogen.levelwithout \n                                     -15.240000 \n       Snail.Levelremoval:Nitrogen.levelwithout \n                                      16.153333 \nSnail.Levelsnail addition:Nitrogen.levelwithout \n                                      10.356667 \n\n\nAnother approach when interactions are significant is to compare all group means (somewhat like a Tukey design for combined treatment levels). The emmeans package offers this approach.\n\nlibrary(emmeans)\n\nWarning: package 'emmeans' was built under R version 4.2.3\n\nemmeans(sdm_model, pairwise ~ Snail.Level*Nitrogen.level)\n\n$emmeans\n Snail.Level    Nitrogen.level emmean   SE df lower.CL upper.CL\n control snails Fertilized      18.71 1.03 12    16.46    20.96\n removal        Fertilized       4.56 1.03 12     2.31     6.81\n snail addition Fertilized      11.14 1.03 12     8.89    13.39\n control snails without          3.47 1.03 12     1.22     5.72\n removal        without          5.47 1.03 12     3.22     7.72\n snail addition without          6.26 1.03 12     4.01     8.51\n\nConfidence level used: 0.95 \n\n$contrasts\n contrast                                              estimate   SE df t.ratio\n control snails Fertilized - removal Fertilized          14.150 1.46 12   9.692\n control snails Fertilized - snail addition Fertilized    7.567 1.46 12   5.183\n control snails Fertilized - control snails without      15.240 1.46 12  10.439\n control snails Fertilized - removal without             13.237 1.46 12   9.066\n control snails Fertilized - snail addition without      12.450 1.46 12   8.528\n removal Fertilized - snail addition Fertilized          -6.583 1.46 12  -4.509\n removal Fertilized - control snails without              1.090 1.46 12   0.747\n removal Fertilized - removal without                    -0.913 1.46 12  -0.626\n removal Fertilized - snail addition without             -1.700 1.46 12  -1.164\n snail addition Fertilized - control snails without       7.673 1.46 12   5.256\n snail addition Fertilized - removal without              5.670 1.46 12   3.884\n snail addition Fertilized - snail addition without       4.883 1.46 12   3.345\n control snails without - removal without                -2.003 1.46 12  -1.372\n control snails without - snail addition without         -2.790 1.46 12  -1.911\n removal without - snail addition without                -0.787 1.46 12  -0.539\n p.value\n  &lt;.0001\n  0.0024\n  &lt;.0001\n  &lt;.0001\n  &lt;.0001\n  0.0072\n  0.9716\n  0.9868\n  0.8450\n  0.0021\n  0.0206\n  0.0512\n  0.7419\n  0.4406\n  0.9932\n\nP value adjustment: tukey method for comparing a family of 6 estimates \n\n\nThis was likely the approach used in the Valdez et al. 2023 paper.\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Snail.Level*Nitrogen.level)$contrasts))\n\n\n\n  \n\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Snail.Level)$contrasts))\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n\n\n  \n\n\npaged_table(data.frame(emmeans(sdm_model, pairwise ~ Nitrogen.level)$contrasts))\n\nNOTE: Results may be misleading due to involvement in interactions\n\n\n\n\n  \n\n\n\nNote the warning; if interactions are significant comparing main effects may be inappropriate (which is why other approaches include subsetting the data)."
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#other-options",
    "href": "content/chapters/More_ANOVAs.html#other-options",
    "title": "More ANOVAs",
    "section": "Other options",
    "text": "Other options\nBootstrapping and permutation tests options may also be used for two-way ANOVAs when assumptions are not met, though there is implementation is more complicated than single-sample designs due to the need to randomize/permute interaction impacts.\nAnother option is to use weighted-least squares regression - this approach specifically helps when residuals are not evenly distributed among groups. For example, we could take the sdm_model (just as an example of use! it’s not needed here!) This approach assume you built the model and then noted an issue with heteroscedasticity. If so, we can calculate a weight for each residual that is based on its variance - below makes a value that increases with low variance.\n\nwt_sdm &lt;- 1 / lm(abs(sdm_model$residuals) ~ sdm_model$fitted.values)$fitted.values^2\n\nWe can then add a new argument to the lm function to use these weights.\n\nsdm_model_wls &lt;-lm(Standing.Dead..dry..m2.~Snail.Level * Nitrogen.level, valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], weights = wt_sdm)\n\nWe can then continue on our normal route:\n\nplot(sdm_model_wls)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(sdm_model_wls, type=\"III\")\n\nAnova Table (Type III tests)\n\nResponse: Standing.Dead..dry..m2.\n                            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)                203.228  1  76.442 1.497e-06 ***\nSnail.Level                157.447  2  29.611 2.288e-05 ***\nNitrogen.level             130.416  1  49.054 1.427e-05 ***\nSnail.Level:Nitrogen.level 143.013  2  26.896 3.681e-05 ***\nResiduals                   31.903 12                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf you compare the two models you notice slight differences - these are minimal here due to lack of differences in variance.\n\nsummary(sdm_model)\n\n\nCall:\nlm(formula = Standing.Dead..dry..m2. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.5800 -0.8350 -0.0317  0.6600  3.7400 \n\nCoefficients:\n                                                Estimate Std. Error t value\n(Intercept)                                       18.710      1.032  18.124\nSnail.Levelremoval                               -14.150      1.460  -9.692\nSnail.Levelsnail addition                         -7.567      1.460  -5.183\nNitrogen.levelwithout                            -15.240      1.460 -10.439\nSnail.Levelremoval:Nitrogen.levelwithout          16.153      2.065   7.824\nSnail.Levelsnail addition:Nitrogen.levelwithout   10.357      2.065   5.016\n                                                Pr(&gt;|t|)    \n(Intercept)                                     4.39e-10 ***\nSnail.Levelremoval                              5.02e-07 ***\nSnail.Levelsnail addition                       0.000228 ***\nNitrogen.levelwithout                           2.25e-07 ***\nSnail.Levelremoval:Nitrogen.levelwithout        4.72e-06 ***\nSnail.Levelsnail addition:Nitrogen.levelwithout 0.000301 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.788 on 12 degrees of freedom\nMultiple R-squared:  0.9284,    Adjusted R-squared:  0.8986 \nF-statistic: 31.14 on 5 and 12 DF,  p-value: 1.792e-06\n\nsummary(sdm_model_wls)\n\n\nCall:\nlm(formula = Standing.Dead..dry..m2. ~ Snail.Level * Nitrogen.level, \n    data = valdez_2023[valdez_2023$Snail.Level != \"uncaged\", \n        ], weights = wt_sdm)\n\nWeighted Residuals:\n     Min       1Q   Median       3Q      Max \n-2.31784 -0.89013 -0.03702  0.92266  2.46121 \n\nCoefficients:\n                                                Estimate Std. Error t value\n(Intercept)                                       18.710      2.140   8.743\nSnail.Levelremoval                               -14.150      2.202  -6.426\nSnail.Levelsnail addition                         -7.567      2.490  -3.039\nNitrogen.levelwithout                            -15.240      2.176  -7.004\nSnail.Levelremoval:Nitrogen.levelwithout          16.153      2.322   6.956\nSnail.Levelsnail addition:Nitrogen.levelwithout   10.357      2.620   3.953\n                                                Pr(&gt;|t|)    \n(Intercept)                                     1.50e-06 ***\nSnail.Levelremoval                              3.27e-05 ***\nSnail.Levelsnail addition                        0.01030 *  \nNitrogen.levelwithout                           1.43e-05 ***\nSnail.Levelremoval:Nitrogen.levelwithout        1.53e-05 ***\nSnail.Levelsnail addition:Nitrogen.levelwithout  0.00192 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.631 on 12 degrees of freedom\nMultiple R-squared:  0.8747,    Adjusted R-squared:  0.8225 \nF-statistic: 16.75 on 5 and 12 DF,  p-value: 4.789e-05\n\n\nWhy not just always do this? Because weighted least squares implicitly assumes we know the weights. We are actually estimating them, so small datasets may lead to bad estimates and outcomes."
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#plotting-outcomes",
    "href": "content/chapters/More_ANOVAs.html#plotting-outcomes",
    "title": "More ANOVAs",
    "section": "Plotting outcomes",
    "text": "Plotting outcomes\nResults from two-way ANOVAs are often plotted similarly to one-way ANOVAs, but with colors or other aesthetics representing the additional group.\n\nsdm_summary &lt;- summarySE(valdez_2023[valdez_2023$Snail.Level != \"uncaged\",], measurevar = \"Standing.Dead..dry..m2.\", groupvars = c(\"Snail.Level\", \"Nitrogen.level\"))\nsdm_summary\n\n     Snail.Level Nitrogen.level N Standing.Dead..dry..m2.        sd        se\n1 control snails     Fertilized 3               18.710000 3.6626220 2.1146158\n2 control snails        without 3                3.470000 1.0013491 0.5781292\n3        removal     Fertilized 3                4.560000 0.4250882 0.2454248\n4        removal        without 3                5.473333 1.4150029 0.8169523\n5 snail addition     Fertilized 3               11.143333 1.3025104 0.7520047\n6 snail addition        without 3                6.260000 0.9417006 0.5436911\n        ci\n1 9.098457\n2 2.487489\n3 1.055978\n4 3.515062\n5 3.235615\n6 2.339314\n\n\n\nsdm_summary$Snail.Level &lt;- relevel(sdm_summary$Snail.Level, \"removal\")\n\nggplot(sdm_summary, aes(x=Snail.Level, \n                           y=Standing.Dead..dry..m2.,\n                           fill=Nitrogen.level)) +\n  geom_col(color=\"black\", position=position_dodge()) +\n  geom_errorbar(aes(ymin=Standing.Dead..dry..m2., ymax=Standing.Dead..dry..m2.+ci), position = position_dodge()) +\n  labs(title=\"Grazing impacts depend on nitrogen levels\",\n       x= \"Grazing level\",\n       y= expression(paste(\"Standing dry mass (\" , g^{-1}, m^{-2}, \")\")))"
  },
  {
    "objectID": "content/chapters/More_ANOVAs.html#next-steps",
    "href": "content/chapters/More_ANOVAs.html#next-steps",
    "title": "More ANOVAs",
    "section": "Next steps",
    "text": "Next steps\nIn the next chapters we will carry our linear model approach to consider the relationship between continuous outcomes and continuous predictor variables."
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html",
    "href": "content/chapters/Relationships_among_numerical_variables.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "In the last chapter we extended linear models to consider impacts of multiple factors. Continuing that tradition, we will now explore how numerical (and specifically continuous) predictor variables can be used to explain variation in numerical outcome variables."
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#back-to-the-iris-data",
    "href": "content/chapters/Relationships_among_numerical_variables.html#back-to-the-iris-data",
    "title": "Relationships among numerical variables",
    "section": "Back to the iris data",
    "text": "Back to the iris data\nWe will motivate this with an example from our favorite iris data. So far we have considered how species impacts measured outcomes. However, we might also want to consider the relationship between traits. For example, we might want to know if sepal and petal length are related. We could plot the data:\n\nlibrary(ggplot2)\nsepal_petal_relationship &lt;- ggplot(iris, aes(x=Sepal.Length, y=Petal.Length)) +\n  geom_point() +\n  labs(title=\"Sepal length increases with petal length\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\nsepal_petal_relationship\n\n\n\n\nOur related hypothesis might be a relationship exists among the variables; alternatively, one does not. To put this our null hypothesis framework, we might write:\n\\[\n\\begin{split}\nH_O: \\textrm{there is not a relationship between sepal and petal length}\\\\\nH_A: \\textrm{there is a relationship between sepal and petal length}\\\\\n\\end{split}\n\\]\nIn other words, we need to gather enough evidence to reject the hypothesis of no relationship. Note we will formalize these hypotheses more in a moment, but how do we test them?\n\nWorking with continuous predictors\nFor some background, consider differences between continuous and categorical predictor variables. Unlike examples of when we transformed continuous outcomes into binomial data, continuous predictors offers information on order and spacing. Compared to un-ordered categorical variables (what we’ve focused on), the numbers mean something! This allows us (with caution) to estimate outcomes from un-sampled regions.\nConsider: We know the mean sepal lengths for three species of irises:\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\n\nLoading required package: plyr\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Sepal.Length\", groupvars =\n                               c(\"Species\"))\n\nggplot(function_output, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_col(aes(fill=Species)) +\n    geom_errorbar(aes(ymin=Sepal.Length-ci, ymax=Sepal.Length+ci)) +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n\n\n\nBut if we find a new species, we actually don’t know what to expect!\nHowever, if we have this graph\n\nsepal_petal_relationship\n\n\n\n\nWe might have a guess of the petal length of a flower that has a sepal length of 2.5 cm even though we didn’t measure anything of that size. In fact, you might be able to visualize the relationship:\n\nsepal_petal_relationship+geom_smooth(method = \"lm\",se = F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWhile we can draw this “line of best fit” by sight, linear models actually give us a way to formally define it (analyze our hypothesis). The line of best fit minimizes the residuals (which means it also offers a prediction any value of sepal length!). This approach, however, also means we are considering linear relationships between our predictor variables (but note our predictor variables themselves could be a transformation of an actual measurement, such as a square root or value cubed!). This is one assumption of linear regression. We can consider non-linear relationships using other techniques (which we will cover later).\nIf we wanted to carry out a sampling experiment to determine a p-value for our hypotheses, we could sample from a population that represents our sepal lengths and one that represents our petal lengths. If the two populations are not connected, then arbitrary pairs could be made - this would indicate no relationship among the variables. For each dataset, we could note the potential relationship (now occuring by chance!) between our variables, and then compare that null distribution to what we actually observed. To make this approach more generalizable, we could standardize our data points - using these to calculate our error terms for full and reduced models would lead us to F distributions.\nOverall, this means we can use a linear model approach to investigate relationships among numerical variables. We can build the model\n\niris_regression &lt;- lm(Petal.Length ~ Sepal.Length, iris)\n\nand see the impacts on our linear model.\nThe relationship between our two variables is noted in the model matrix, which now includes our actual values,\n\nlibrary(rmarkdown)\npaged_table(data.frame(model.matrix(iris_regression)))\n\n\n\n  \n\n\n\nand a coefficient that shows their relationship. The first parameter is the x-intercept, and the second (the relationship) is the slope of the best fit line!\n\nmatrix(as.numeric(iris_regression$coefficients), ncol=1)\n\n          [,1]\n[1,] -7.101443\n[2,]  1.858433\n\n\nOnce the model is made, we can plot it to check assumptions\n\nplot(iris_regression)\n\n\n\n\n\n\n\n\n\n\n\n\n\nFor numerical relationships we typically see more of a cloud of data, but we are still assuming the residuals are normally distributed (with the same variance for all fitted values, i.e. identically distributed) and indepent. Iassumptions are met consider outcomes.\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Petal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  147.95   1  196.45 &lt; 2.2e-16 ***\nSepal.Length 352.87   1  468.55 &lt; 2.2e-16 ***\nResiduals    111.46 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Petal.Length ~ Sepal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.47747 -0.59072 -0.00668  0.60484  2.49512 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -7.10144    0.50666  -14.02   &lt;2e-16 ***\nSepal.Length  1.85843    0.08586   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8678 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\nHere the ANOVA table tells us there is a significant impact of sepal length on petal length, and the summary (and graph) demonstrate that relationship is positive. Note we do not need any post-hoc analysis (why not?)."
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#regression-or-correlation",
    "href": "content/chapters/Relationships_among_numerical_variables.html#regression-or-correlation",
    "title": "Relationships among numerical variables",
    "section": "Regression or correlation",
    "text": "Regression or correlation\nThis approach, with small changes in theory, can be used for two scenarios. We typically consider (but actually rarely use) linear regression. Linear regression technically assumes that an approach was used to determine how one variable impacts another (so we chose which one to vary and how). For this scenario, our sampling experiment technically uses the set values of the predictor variable,and our hypotheses focus on the coefficient value\n\\[\n\\begin{split}\nH_O: \\beta_\\textrm{relationship between sepal and petal length} = 0\\\\\nH_A: \\beta_\\textrm{relationship between sepal and petal length} \\neq 0\\\\\n\\end{split}\n\\]\nNote our coefficient will also change based on measurement units, but this should not impact the resulting p-value.\nThe other approach, correlation, is more simply measuring association between the variables. It’s not specifying which, if either, is the driver - both variables could be responding to an un-measured variable. For example, since we simply observed flower traits, we could easily reverse everything above (plot shown here).\n\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point() +\n  labs(title=\"Sepal length increases with petal length\",\n       y= \"Sepal length (cm)\",\n       x= \"Petal Length (cm)\")\n\n\n\n\nNote that doing so would change the coefficients in our linear model,but not the direction of the relationship. For this reason, correlation often focuses on a unitless correlation parameter, r, instead of a coefficient from our \\(\\beta\\) matrix.\n\\[\n\\begin{split}\nH_O: r_\\textrm{relationship between sepal and petal length} = 0\\\\\nH_A: r_\\textrm{relationship between sepal and petal length} \\neq 0\\\\\n\\end{split}\n\\]\nr can vary from -1 (values are perfectly negatively related) to 1 (values are perfectly positively related), where 0 indicates no associatoin. This should sound familiar (hold this thought). For a related sampling experiment, populations for both traits are simulated and then paired (what we described above!).\nThe correlation coefficient can be calculated in R using the cor.test function; note the formula interface is different to reflect association.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\n\nNote that the output also gives us a confidence interval and estimate for r in addition to a p-value. If we square the provided r value, we get the R2 output we have previously described in our linear model summary.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)$estimate^2\n\n      cor \n0.7599546 \n\nsummary(iris_regression)$r.squared\n\n[1] 0.7599546\n\n\n\nOther options\nIf our assumptions are not met, we have a few options. You may have noticed the cor.test function provided a Pearson’s product-moment correlation. This is one approach that uses the raw data. Another approach, the Spearman rank correlation, uses (surprise) ranked data. This relaxes the assumption of normality and only assumes monotonic relationships (one variable increases or decreases with the other). We can use it by updating the arguments in the cor.test function.\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris, method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\nBootstrapping and permutation options also exist. Some of these use the same functions we’ve encountered before. For example, we can do permutation tests using the coin package.\n\nlibrary(coin)\n\nLoading required package: survival\n\nindependence_test(Petal.Length ~ Sepal.Length, iris)\n\n\n    Asymptotic General Independence Test\n\ndata:  Petal.Length by Sepal.Length\nZ = 10.641, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nBootstrapping may be done using the boot or other packages. For example, the boot function in the car package gives an easy wrapper for boot.\n\nlibrary(car)\nbootstrap_iris &lt;- Boot(iris_regression)\n\nLoading required namespace: boot\n\nsummary(bootstrap_iris)\n\n\nNumber of bootstrap replications R = 999 \n             original   bootBias   bootSE bootMed\n(Intercept)   -7.1014 -0.0114945 0.421148 -7.1289\nSepal.Length   1.8584  0.0023941 0.068358  1.8625\n\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate     2.5 %    97.5 %\n(Intercept)  -7.101443 -7.827446 -6.160272\nSepal.Length  1.858433  1.714627  1.981503"
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#a-little-more-on-assumptions",
    "href": "content/chapters/Relationships_among_numerical_variables.html#a-little-more-on-assumptions",
    "title": "Relationships among numerical variables",
    "section": "A little more on assumptions",
    "text": "A little more on assumptions\nAlthough our linear models all have the same assumptions, numerical predictors add a few new wrinkles. For numerical predictors, outliers may be more of an issue. Outliers may be used a general term to focus on a data point that is different from the rest of the dataset, but only certain types of outliers matter.\nFor example, let’s pretend we realized our iris dataset was missing 3 rows and add them back in.\n\niris_new &lt;- iris\niris_new$Source &lt;- \"original\"\niris_new$label &lt;- NULL\n#make outlier\niris_outlier &lt;- data.frame(Petal.Length = c(2.5,12, 12.1),\n                           Sepal.Length = c(5.4,8.9, 3), \n                           Source = \"new\",\n                           label = c(\"A\",\"B\", \"C\"))\niris_merged &lt;- merge(iris_new, iris_outlier, all = T)\niris_merged &lt;- iris_merged[order(iris_merged$Source, decreasing = T),]\nrownames(iris_merged) &lt;- 1:nrow(iris_merged) \n\niris_merged$row_number &lt;- 1:nrow(iris_merged)\n\nggplot(iris_merged, aes(y=Petal.Length, x=Sepal.Length, color=Source)) +\n  geom_point() +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Petal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\nOur 3 “new” points (rows 151-153) are all unique ins some way. 152 is from a relatively unsampled region of the graph that is within the range of existing data. 151 and 153 are also from un-sampled regions, but these are outside of the original range. More importantly, note if we fit the data without these points\n\nggplot(iris_merged, aes(y=Petal.Length, x=Sepal.Length, color=Source)) +\n  geom_point() +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Petal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       subtitle = \"Best fit based on original data only!\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\") +\n  geom_smooth(data=iris_new[iris_new$Source == \"original\",], method = \"lm\", fullrange=T, se=F)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nWe see that only row 151 appears to be different than what we would expect given the rest of the data. Now, note if we fit a model all these points and check assumptions\n\niris_regression_new &lt;- lm(Petal.Length ~ Sepal.Length, iris_merged)\nplot(iris_regression_new)\n\n\n\n\n\n\n\n\n\n\n\n\n\nseveral plots label row 151. In general, R provides the row number of the most “unusual” rows in each graph. This may mean a fairly normal row that just so happens to be the “most” extreme in a dataset is labelled. However, here we see row 151 falling outside the dotted lines that are labelled Cook’s distance in the 4th graph. Cook’s distance is one way of quantifying leverage, or how much a single point shifts the best fit line. The measure quantifies change in the regression coefficients if each data point is removed individually. Here we see row 151 is a high leverage point, while 153 is not even though the sepal length itself may be an outlier.\nAlthough row 153 is not identified as a high leverage point, it is impacting the line (as are all other points). Our best fit line will always go though the point \\((\\bar{x}, \\bar{y})\\), so outliers in the “x” variable will impact the line. This also explains why the confidence region (which we won’t calculate here), gets “smaller” in the middle of the data range.\n\nggplot(iris_merged, aes(y=Petal.Length, x=Sepal.Length)) +\n  geom_point(aes(color=Source)) +\n  geom_text(iris_merged[iris_merged$Source != \"original\",],mapping=aes(label=row_number,y=Petal.Length+.2), color=\"black\") +\n  labs(title=\"Iris data including our missing 3 rows!\",\n       subtitle = \"Grey area is confidence region, with mean point shown in purple!\",\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\") +\n  geom_smooth( method = \"lm\", fullrange=T, se=T)+\n  geom_point(aes(x=mean(iris_merged$Sepal.Length), y=mean(iris_merged$Petal.Length)), color=\"purple\")\n\nWarning: Use of `iris_merged$Sepal.Length` is discouraged.\nℹ Use `Sepal.Length` instead.\n\n\nWarning: Use of `iris_merged$Petal.Length` is discouraged.\nℹ Use `Petal.Length` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThis all the further you get from the mean, the wider your confidence interval will be for an estimate. Even more importantly, estimating points outside your data range is likely a bad idea."
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#plotting-outcomes",
    "href": "content/chapters/Relationships_among_numerical_variables.html#plotting-outcomes",
    "title": "Relationships among numerical variables",
    "section": "Plotting outcomes",
    "text": "Plotting outcomes\nAs shown above, numerical data is often plotted via paired points. You can also add regression lines with or without confidence regions."
  },
  {
    "objectID": "content/chapters/Relationships_among_numerical_variables.html#next-steps",
    "href": "content/chapters/Relationships_among_numerical_variables.html#next-steps",
    "title": "Relationships among numerical variables",
    "section": "Next steps",
    "text": "Next steps\nIn the next chapters we will carry our linear model approach to consider the relationship between continuous outcomes and continuous predictor variables."
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html",
    "title": "One sample tests for continuous data",
    "section": "",
    "text": "In this chapter will build on our introduction to significance testing by considering tests for continuous data collected on one trait from a single population. This will also allow/require us to more fully define normal distributions, which we have already started to discuss."
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#example",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#example",
    "title": "One sample tests for continuous data",
    "section": "Example",
    "text": "Example\nLet’s return to our iris data and focus on sepal lengths of I. viriginica.\n\nset.seed(42)\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWhat if we wanted to test if the height was equal to a certain value like 7 cm?\nWe can’t, and it’s not.\nHeight is a random variable. It differs among individuals (see above), so it isn’t equal to any specific value. This may seem obvious, but it’s an important step in understanding hypothesis testing. Many students also struggle with this, but most are with the fact we learned about hypothesis testing focusing on proportions (remember the last chapter?). When we focused on binomial data, it was obvious a single draw could not be 2 things - it was a success or failure, and we focused on the relative occurrence of those.\nSimilarly, for continuous numeric data (remember: data that can on any value in a given range), we need to focus on describing the distribution of the data. If we do that, we might want (and be able to test) if, for example, the mean height of I. virginica is equal to 7 cm. In fact, we typically focus on the mean of the distribution (one of measures of central tendency)\nTo do this, we need to do what we did with binomial data: develop a null hypotheses, use it to construct a null distribution, and compare our data to it see how unusual it is (and get a p-value).\n\n\nWhat is our null hypothesis for this example?\n\nFor this example, we are focused on a two-tailed test (we are asking if the mean is equal to a certain value), so we have\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\n\nNow that we have a null hypothesis, we need to test it. We can do this by simulation. Let’s make a distribution where the \\(\\mu_{sepal \\ length} =7 \\  cm\\), then draw samples from it and see how rare it is to get what we actually observed in the data…which was\n\nmean(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\n\n[1] 6.588\n\n\nSeems easy enough, but what distribution do we draw from? For our binomial data we knew exactly what to parameterize - that’s because the entire distribution that fits the null hypothesis is described by the parameter p that is set by the null hypothesis (go back to the last chapter and note we can find the spread using this one variable as well!).\nIf you remember the central limit theorem, you might realize the distribution of the data does not matter in some ways. No matter what it looks like, the means of the data will tend towards normality. However, we still need to describe the data itself it to simulate our draws. We’ll discuss an alternative where you sample from the data itself at the end of this chapter.\nIt turns out the shape of the data itself appears fairly normal. So far we’ve said normal distributions\n\nare roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate\n\n95% of the sample is within \\~2 standard deviations of the mean (and for our mean of means, 95% of the data is within 2 standard errors)\nLook at a density function fit to the data:\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nIt does appear to be fairly symmetric and peaked in the middle. It turns out normal distributions (finally defined below!) are very common in nature.\nJust like the binomial data, a normal distribution can be described using a formula. The formula has 2 parameters that define the shape of the distribution. \\(\\mu\\) defines the center of the distribution, and \\(\\sigma^2\\) describes its spread. The formula for the probabilty density function is\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\ne^{\\frac{-(x-\\mu)^2}{2\\sigma^2}}\n\\]\nThis looks complicated, but remember: this is just an equation for describing the likelihood of outcomes in a probability space! The first part \\(\\sqrt{2\\pi\\sigma^2}\\) arises from trying to work with a curve. To understand the rest, lets take the ln of both sides\n\\[\n\\begin{split}\n\\ln(f(x)) = \\ln(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}) - \\frac{1}{2\\sigma^2}*(x-\\mu)^2 \\\\\n\\ln(f(x)) = -\\ln(\\sqrt{2\\pi\\sigma^2}) - \\frac{1}{2\\sigma^2}*(x-\\mu)^2\n\\end{split}\n\\]\nThis may not look like it helps much, but we now have the formula for a straight line, \\(y=mx+b\\), where\n\\[\n\\begin{split}\ny= \\ln(f(x)) \\\\\nb = - \\frac{1}{2\\sigma^2}\\\\\nm = -\\ln(\\sqrt{2\\pi\\sigma^2})\\\\\nx =  (x-\\mu)^2\n\\end{split}\n\\]\nIn other words, our independent variable is the squared distance from the mean (so all positive)! Note both the y-intercept (the amplitude) and slope (shape) depends on how spread out the data is (\\(\\sigma^2\\)). Note in general when ln(y) decreases linearly with x, y decreases at a constant proportional rate with x. So we can say a normal random variate is any random variable in which the probability of an observation declines in proportion to its squared deviation from the mean (µ).\nLet’s fit a normal distribution to our data:\n\ncolors &lt;- c(\"PDF from data\" = \"black\", \"normal curve\" = \"red\")\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density(aes(color=\"PDF from data\"))+\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\",\n       color=\"Source\" ) +\nstat_function(fun = dnorm, args = list(mean = mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"]), sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"])), aes(color=\"normal curve\"))+\n      scale_color_manual(values = colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNote it fits fairly well, so we’ll use it for our sampling experiment. To do so, we’ll take 50 draws (since we had a sample size of 50) from a normal distribution, find means for each draw, then consider their distribution.\n\nnumber_of_draws &lt;- 50\nnumber_of_simulations &lt;- 1000\n\nsampling_experiment&lt;- data.frame(\"observed_mean\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_mean[i] = mean(rnorm(50, 7, sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"])))\n}\n\nLet’s check out the first few outcomes\n\nhead(sampling_experiment)\n\n  observed_mean\n1      6.977317\n2      7.064034\n3      6.903823\n4      6.984919\n5      7.005049\n6      6.981765\n\n\nand plot them\n\nggplot(sampling_experiment,\n              aes(x=observed_mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed means from 1000 random draws\",\n       x= \"Mean\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow let’s see how that compares to what we actually saw.\n\nsampling_experiment$compare =   ifelse(abs(sampling_experiment$observed_mean-7) &gt;= abs(mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"])-7), 'as or more extreme', 'not as or more extreme')\n\nsampling_experiment$compare &lt;- factor(sampling_experiment$compare)\nlevels(sampling_experiment$compare) &lt;- c(levels(sampling_experiment$compare), \"as or more extreme\")\n\nggplot(sampling_experiment,\n              aes(x=observed_mean, fill=compare)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed means from 1000 random draws\",\n       x= \"Mean\",\n       y= \"Frequency\", \n       fill = \"Sampled mean is ...\") +\n    scale_fill_discrete(drop = FALSE)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nSo in our example simulation, no observed means were as far from the value from the null hypothesis as our sample mean was. This would leave to a p-value of 0 - unusual in some regards, but possible here."
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#another-way-to-compare",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#another-way-to-compare",
    "title": "One sample tests for continuous data",
    "section": "Another way to compare",
    "text": "Another way to compare\nJust like we saw for binomial data, we can always carry out a sampling experiment to find a p-value. However, that’s mainly because we have computers. Even with computers, it would be cumbersome to set up a new sampling experiment for every dataset (which we would need to do for any change in sample size, mean, or standard deviation).\nInstead it would be nice to find a way to replicate the distribution we see above for similar experiments using an equation (just like we did for the binomial data!). One step in doing this relates to how we examine our predictions given our hypotheses. It turns out, we can map our hypotheses to models that explain the variation we see in the data. Our hypotheses (remember\n\\[\n\\begin{split}\nH_O: \\mu_{sepal \\ length} = 7 \\ cm \\\\\nH_A: \\mu_{sepal \\ length} \\neq 7 \\ cm\n\\end{split}\n\\]\nfocus on the mean. They are also stating a prediction for every outcome! Under the null hypothesis, if we were asked to guess the length of a sepal from I. virginica, we would guess 7 cm. Under the alternative hypothesis, we would guess it’s something different than 7. Using our sample, we might instead guess it’s equal to 7 + \\(\\delta\\), where \\(\\delta\\) is estimated from our sample and 7+ \\(\\delta\\) is the mean of our sample.\nFor each hypothesis, we could calculate a measure of related mode fit called the sum squared error from our model, or SSE, where\n\\[\nSSE=sum \\ squared \\ error = \\sum_{i=1}^{n}(Y_i-\\hat{Y_i})^2\n\\]\nHere, \\(Y_i\\) are the data points, and \\(\\hat{Y_i}\\) is our predicted value.\nThis is basically saying we compare the predicted to observed value for each data point for each model (the square exists so things don’t cancel out!). Our null hypothesis corresponds to a simpler view of the world (a reduced or null model), where \\(\\hat{Y_i}\\) is equal to a given value (in our case, 7 cm), whereas under the alternative hypothesis (which corresponds to an alternative or full model), \\(\\hat{Y_i}\\) is equal to a different value (such as 7 + \\(\\delta\\)). The value for \\(\\delta\\) is estimated from our sample and makes the full model larger than the reduced in regard to the number of parameters included in the model.\nWe can then compare the SSE of the 2 models by finding their difference. This is our signal from the data. If we take multiple samples from a known population that is defined by the null hypothesis, we can carry out a very similar sampling to what we did originally.\n\nfor(i in 1:number_of_simulations){\na &lt;- rnorm(50, 7, sd = sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))\nsampling_experiment$observed_mean[i] &lt;- mean(a)\n\nsampling_experiment$SSE_null[i] &lt;-  sum((a-7)^2)\n\nsampling_experiment$SSE_full[i] &lt;- sum((a-mean(a))^2)\n}\n\nsampling_experiment$SSE_difference &lt;- sampling_experiment$SSE_null - sampling_experiment$SSE_full\n\nggplot(sampling_experiment,\n              aes(x=SSE_difference)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed difference in model fit from 1000 draws\",\n       x= \"Mean\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\ndifference_SSE_observed &lt;- sum((iris[iris$Species == \"virginica\",\"Sepal.Length\"]-7)^2)-sum((iris[iris$Species == \"virginica\",\"Sepal.Length\"]-mean(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))^2)\n\nggplot(sampling_experiment,\n              aes(x=SSE_difference)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Observed difference in model fit from 1000 draws\",\n       x= \"Mean\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=difference_SSE_observed))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNote we never saw as large a difference in the signal our sampling experiment as we did in the data!\n\nnrow(sampling_experiment[sampling_experiment$SSE_difference &gt;=  difference_SSE_observed,])\n\n[1] 0\n\n\nNote this distribution is skewed for a few reasons. Given the square term, it must positive. We also unlikely (given sampling error) that signal will be exactly zero. In fact,since we estimate \\(\\delta\\) from the data itself, the alternative model is almost always a better fit (remember our bias in variance estimates?).\nThis approach accounts for the noise that we see in our data (variation we expect to see in signal values even if the null hypothesis is true) through sampling. However, if we could estimate the noise, we could also divide our signal by it. Accounting for signal and noise let’s us take very different questions in terms of data and use a standardized approach to analyze them. This is because a signal to noise ratio typically follows some distribution."
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#z-test-a-distribution-based-approach",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#z-test-a-distribution-based-approach",
    "title": "One sample tests for continuous data",
    "section": "Z-test: a distribution based approach",
    "text": "Z-test: a distribution based approach\nIn our case, the signal to noise ratio is approximated by the normal distribution! This is an approximate solution to the signal to noise ratio because our means approach a normal distribution as sample size increases - so for non-infinity sample sizes, they may not be perfectly normal!\nWe can show that our signal is simply the mean from our data minus the mean under the null hypothesis, and including \\(\\sigma\\) in the denominator accounts for noise. We can make this more generalizable if we z-transform the data using the formula\n\\[\nz=\\frac{Y - \\mu}{\\sigma}\n\\]\nAfter this transformation, the data is centered at 0 (think about it - if you subtract the mean from all data points…) and has a standard deviation of 1 (because you divided by the standard deviation!). This also makes the mean of transformed data equal to \\(\\delta\\) and the mean under the null hypothesis equal to zero. This also means ~68% of the data points lie between -1 and 1, while ~95% lie between -2 and 2 (since the standard deviation is 1!).\n\n\nLoading required package: viridisLite\n\n\nWarning: package 'viridisLite' was built under R version 4.2.3\n\n\n\n\n\nFigure 1: ~65% of the data lies with 1 standard deviation of the mean, ~95% lies within 2 standard deviations, and ~99% lies within 3 standard deviations of the mean\n\n\n\n\nWe call this specific form of the normal distribution (N(0,1), showing the mean and standard deviation parameters) the Z distribution. Extending on this with some algebra, we can get a Z-score from any data using the equation\n\\[\nz=\\frac{\\bar{x} - \\mu}{\\sigma}\n\\]\nThis transforms a given data point into a z-score on the z, or standard normal, distribution. We can then use the Z distribution to consider how unusual our z-scores are (i.e., get a p-value!). We call the approach that uses this distribution the z-test, and it can be carried out using the z.test function in the BDSA package.\n\nlibrary(BSDA)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'BSDA'\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nz.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7, \n             sigma.x= sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))\n\n\n    One-sample z-Test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nz = -4.5815, p-value = 4.617e-06\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.411746 6.764254\nsample estimates:\nmean of x \n    6.588 \n\n\nUsing this approach we get a p-value of .000005 - not 0, but very close!\n\nA little history\nAlthough software now provides us exact (approximate) p-values, historically this was far more difficult. For this reason, people took advantage of a transformation so they could use a standardized table like this one.\n\n\n\nExample of z-table. Jsmura, Creative Commons Attribution-Share Alike 4.0 International licence\n\n\nThese tables showed how Z-scores related to p-values. Note these often showed the area to the left of the value, so two-tailed tests required one to multiple the given p-value by 2 (or, if focused on the upper tail, multiply (1-given p-value) by 2 since the distribution is symmetric. Similarly, some tables only had values &lt;0; for those you could find the score whose absolute value corresponed to the observed z-score and multiply the noted p-value by 2 for two-tailed tests .\nFor our example, we got a z score of -4.8515. The table doesn’t even go that low!"
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#does-the-distribution-of-the-data-matter",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#does-the-distribution-of-the-data-matter",
    "title": "One sample tests for continuous data",
    "section": "Does the distribution of the data matter?",
    "text": "Does the distribution of the data matter?\nRemember we are focusing on the distribution of the means (both our sampling experiment and SSE calculations include the means of the sample and data under the null hyothesis!). Given that and the central limit theorem, does the distribution of the data matter? Yes, but only in regards to the relationship between sample size and normality of the sample means. If the underlying data is normal, then the sampled means are distributed normally for almost any sample size, although sample size impacts the spread of the sample means.\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 2: Means drawn from a normal distribution are normal regardless of sample size\n\n\n\n\nFor other distributions, larger sample sizes are required to approximate normality. For example, consider a highly-peaked (double-exponential) distribution\n\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nor as skewed \\(\\chi^2\\) distribution (here with a df =4, to be explained later!):\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nEven for these very non-normal distributions, the means approach a normal distribution at fairly low sample sizes. This is even true for binomial data, especially when p is not very close to 0 or 1. Consider\n\n\nNo id variables; using all as measure variables\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nThis is why it used to be more common to use a normal approximation to the binomial distribution - even though the binomial distribution is easy to compute,the z is even easier! For example, Sandidge (Sandidge 2003) noted that brown recluse spiders chose dead prey items (as opposed to live - 2 categories!) when offered choices. This data could be assessed using a binomial test\n\n binom.test(119,(59+41+41), p=.5)\n\n\n    Exact binomial test\n\ndata:  119 and (59 + 41 + 41)\nnumber of successes = 119, number of trials = 141, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.7733542 0.8995595\nsample estimates:\nprobability of success \n             0.8439716 \n\n\nor a z-test approach by finding a z-sore\n\n p=.5\n n=41+41+59\n z_score &lt;- (119-p*n)/sqrt(n*p*(1-p))\n pnorm(z_score, lower.tail = F) *2\n\n[1] 3.11282e-16\n\n\nor a \\(\\chi^2\\) test, which is similar to a z test but focuses on a sum of independent squared Z variates. The \\(\\chi^2\\) distribution is defined by a degrees of freedom, or df, parameter, which in this case isequal to the number of categories -1 (or 2-1=1 in this case). We will return to df multiple times! Note the p-values obtained from the Z and \\(\\chi^2\\) tests are the same!\n\nchisq.test(c(119,n-119))\n\n\n    Chi-squared test for given probabilities\n\ndata:  c(119, n - 119)\nX-squared = 66.73, df = 1, p-value = 3.113e-16\n\n\nThis may seem esoteric, but understanding these issues may help you interpret older papers while also choosing to employ more modern statistical methods.\n\nQQ norm plots - commonly used, but not needed, at this point!\nIn addition to considering the sample size and underlying distribution, quantile-quantile (Q-Q) plots are sometimes used to assess normality. These plots plot quantiles in one data set against quantiles from another to determine if they come from similar distribution. Remember, quantiles just order data; percentiles are example where you have 100 cut points. Q-Q norm plots consider if a given dataset are similar to a normal distribution. If so, then the dots should match the straight line produced by the qqline function.\n\nqqnorm(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\nqqline(iris[iris$Species == \"virginica\",\"Sepal.Length\"])\n\n\n\n\nWhile we introduce Q-Q plots here, and they are often used to assess normality, remember our tests (so far) are relying on the means of the data being normally-distributed and not the data itself!"
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-know-the-variance",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-know-the-variance",
    "title": "One sample tests for continuous data",
    "section": "What if we don’t know the variance?",
    "text": "What if we don’t know the variance?\nAssuming everything above makes sense, we are left with one issue: the variance of the underlying population is rarely known!\nIn the above examples, we actually used our estimate of variance from the sample to run our simulation experiment and z-test! While this works ok for large sample sizes (yay for central limit theorem!) and is what statisticians relied upon historically, it doesn’t work for well for smaller sample sizes (unless we somehow know the population variance). Our estimates for the population variance are less precise and potentially biased at small sample sizes.\nTo address this issue, statisticians developed the t-distribution. Unlike the normal distribution, its shape depends on the sample size. This parameter is coded as degrees of freedom, commonly denoted as df, and is equal to n - 1 (we’ll come back to df later!). The major breakthrough, however, was that df was the only sample-specific parameter. The same distribution works regardless of the estimated population variance, as a t statistic/score is created that functions like a z score.\n\\[\nt=\\frac{\\bar{x} - \\mu}{\\frac{s}{\\sqrt{n}}}\n\\]\nIt can be shown (though not here!) that the t-distribution is actually a specific form of the F distribution (which we’ll see in ANOVAs). An F-distribution is the ration of two \\(\\chi^2\\) distributions, which (as noted above) are sums of squared Z distributions. The t distribution is the special case where you can take the square of an F distribution where the numerator (top) \\(\\chi^2\\) distribution has 1 degree of freedom and the denomintor (bottom) has n-1 degrees of freedom. In general, variance follows a \\(\\chi^2\\) distribution with n-1 degrees of freedom.\nBecause it directly uses the estimate of the population variance, smaller sample sizes show more spread (and thus make null hypotheses more difficult to reject!). For example, note how small sample sizes (remember, df=3 means n=4!) are notably different from the normal distribution, while larger sample sizes become very hard to distinguish!\n\n\n\n\n\nNote this means the t-distribution is actually a class of distributions.\nIn older text books, you would have a t-table that showed t scores corresponding to commonly used values of \\(\\alpha\\) for multiple degrees of freedom. These published t scores are sometimes called critical values. Users would have compared their calculated t-score (or its absolute value in the case of negative values) to the appropriate critical values (often \\(\\alpha/2\\) for 2-sided tests) to determine if a finding was significant. We can actually produce a t table in R.\n\ndf &lt;- 1:100\ncut_offs &lt;- c(\".1\", \".05\", \".025\", \".01\")\nt_table &lt;- setNames(data.frame(matrix(ncol = length(cut_offs)+1, nrow = length(df))), c(\"df\",cut_offs))\nt_table$df &lt;- df\nfor (i in 1:length(df)){\n  for (j in 2:ncol(t_table))\n  t_table[i,j] &lt;- round(abs(qt(as.numeric(colnames(t_table)[j]), df[i])),3)\n}\nlibrary(rmarkdown)\npaged_table(t_table)\n\n\n\n\n\n\nFigure 3: Critical values\n\n\n\nTo calculate the test statistic in R, we can instead (thankfully!) use the t.test function.\n\nt.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7, \n             sigma.x= sd(iris[iris$Species == \"virginica\",\"Sepal.Length\"]))\n\n\n    One Sample t-test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nt = -4.5815, df = 49, p-value = 3.195e-05\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.407285 6.768715\nsample estimates:\nmean of x \n    6.588 \n\n\nNote the t-test also provides confidence intervals. Note these consider the spread of the data given the t-distribution so they are always wider than those predicted using a normal distribution, though the difference is small at large sample sizes.\nThis explains why I have noted ~95% of the data lies within 2 standard errors of the mean! For truly normal data, it’s actually within 1.96 standard errors. For data where we estimate the population variance, it depend on the sample size, but even at n=21 (and thus df = 20!) the number is 2.09. Note\n\nt_critical &lt;- setNames(data.frame(matrix(ncol = 2, nrow = length(sample_size))), c(\"n\", \"95% of the data is within this many standard deviations of the mean\"))\nfor (i in 1:length(sample_size)){\nt_critical$n[i] &lt;- sample_size[i]\nt_critical[i,2] &lt;-qt(.025,as.numeric(sample_size[i]))\n}"
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-trust-the-normal-approximation",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#what-if-we-dont-trust-the-normal-approximation",
    "title": "One sample tests for continuous data",
    "section": "What if we don’t trust the normal approximation?",
    "text": "What if we don’t trust the normal approximation?\nDespite the central limit theorem (or because of it), we may not think our sample size is sufficient given the distribution the data to assume that \\(\\hat{Y}\\) really follows a normal distribution. In that case we a few options.\n\nWilcoxon test (aka, signed binary-transform, Fisher’s sign test)\nIf the distribution of the data is symmetric, a Wilcoxon test may be appropriate. Note it is rare to have data that are symmetrically distributed but that for which you don’t think th means will be normally distributed). We introduce the test here as it will come back up (and be more useful) in later chapters.\nThis test employs a strategy we will see again and again: it ranks the data, in this case based on the distance from the mean under the null hypothesis. A sign is also assigned to each rank, with those originating from data points that were lower than the proposed mean becoming negative. In theory, the sum of the signed ranks should be ~0 if HO is true. We can carry out this test in R using the wilcox.test function.\n\nwilcox.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nV = 241.5, p-value = 0.0001312\nalternative hypothesis: true location is not equal to 7\n\n\n\n\nSign test (aka the median test)\nIf the data are not symmetrically distributed, the sign test actually just counts those below the proposed value (which is the median here instead of the mean, since we are concerned about normality). In theory, approximately half the values should be under the proposed mean if HO is true. The proportion below is compared to .5 using a binomial test.\n\nSIGN.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], md = 7)\n\n\n    One-sample Sign-Test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\ns = 12, p-value = 0.0003059\nalternative hypothesis: true median is not equal to 7\n95 percent confidence interval:\n 6.3 6.7\nsample estimates:\nmedian of x \n        6.5 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt U.E.pt\nLower Achieved CI     0.9351    6.3    6.7\nInterpolated CI       0.9500    6.3    6.7\nUpper Achieved CI     0.9672    6.3    6.7\n\n\n\n\nBootstrapping\nThe final option we will review is a little different. For all our other hypothesis tests we’ve been resampling from a distribution that fits the parameters from the null hypothesis. However, its turns out we can resample from the actual data we collected to approximate the distribution of the sample (or the signal in most cases). You can then use that distribution to develop confidence intervals or hypothesis testing. The only requirement here is we have a large enough sample size to actually appropriately sample from (and that we have the means to do it!). This approach was developed in the 1990s given the increase in computing power and availability.\nWe can demonstrate this with an imaginary population (and also demonstrate the central limit theorem). Let’s make a population whose trait value of focus falls between 60 and 80 in a uniform manner.\n\npopulation_unif &lt;- data.frame(id = 1:10000, \n                              value = runif(10000, 60, 80))\nggplot(population_unif, aes(x=value)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow’s let’s take samples of 50 from it a lot of times (1000 here) and plot the means of these samples.\n\nsampling_experiment&lt;- data.frame(\"observed_mean\" = rep(NA, number_of_simulations))\nfor(i in 1:number_of_simulations){\nsampling_experiment$observed_mean[i] &lt;- mean(sample(population_unif$value,50, replace = F))\n}\nggplot(sampling_experiment, aes(x=observed_mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Means from imaginary samples of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow let’s instead think of what might happen - we get a single sample of 50.\n\nactual_sample &lt;- data.frame(sample = sample(population_unif$value,50, replace = F))\nggplot(actual_sample, aes(x=sample)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Actual sample of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nNow (here’s the odd part): Let’s sample from that sample with replacement to get “new” samples, then get those means, again, 1000 times.\n\nbootstrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\nexample_bootstrap &lt;-sample(actual_sample$sample, length(actual_sample$sample), replace = T)\nbootstrap_outcomes$mean[i] &lt;- mean(example_bootstrap)\nbootstrap_outcomes$sd[i] &lt;- sd(example_bootstrap)\n}\n\nWhen we plot them we see it looks very much like the distribution of means we obtained by re-sampling!\n\nggplot(bootstrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Bootstrapped means of size 50 from our imaginary population\",\n       x= \"Trait value\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOverall, this means we can use our sample to recreate our underlying distribution and explore its properties!\nLet’s demonstrate this approach with our iris data. First, we can make “new” datasets from our original data by sampling (with replacement) samples of the same size from our original dataset.\n\nbootstrap_data&lt;- iris[iris$Species == \"virginica\",\"Sepal.Length\"]\nbootstrap_outcomes &lt;- data.frame(mean = rep(NA, number_of_simulations), sd = NA)\nfor (i in 1:number_of_simulations){\niris_bootstrap &lt;-sample(bootstrap_data, length(bootstrap_data), replace = T)\nbootstrap_outcomes$mean[i] &lt;- mean(iris_bootstrap)\nbootstrap_outcomes$sd[i] &lt;- sd(iris_bootstrap)\n}\nggplot(bootstrap_outcomes, aes(x=mean)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means of sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Mean sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nWe again (thanks to the central limit theorem) see the means follow a normal distribution.\nWe can also carry this out using the boot function (in the boot package), though the functions may look a little odd.\n\nlibrary(boot)\n\n\nAttaching package: 'boot'\n\n\nThe following objects are masked from 'package:VGAM':\n\n    logit, simplex\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\nresults &lt;- boot(data=bootstrap_data, statistic = function(x, inds) mean(x[inds]),\n   R=number_of_simulations)\nggplot(data.frame(results$t), aes(x=results.t)) +\n  geom_histogram(color=\"black\") +\n  labs(title=expression(paste(\"Bootstrapped means of sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Mean sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nand then find the 95% confidence interval. Like binomial data, there are a few ways to do this. One is to use the percentile, or quantile, method. This is intuitive. We rank the bootstrapped values from smallest to largest and then find points that cut off the bottom and top 2.5%.\n\nquantile( results$t, probs=c(.025, .975) ) \n\n  2.5%  97.5% \n6.4219 6.7781 \n\n\nThough simple, these findings may also be biased. More advanced intervals are provided the boot.ci function.\n\nboot.ci(results)\n\nWarning in boot.ci(results): bootstrap variances needed for studentized\nintervals\n\n\nBOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS\nBased on 1000 bootstrap replicates\n\nCALL : \nboot.ci(boot.out = results)\n\nIntervals : \nLevel      Normal              Basic         \n95%   ( 6.410,  6.761 )   ( 6.394,  6.758 )  \n\nLevel     Percentile            BCa          \n95%   ( 6.418,  6.782 )   ( 6.416,  6.778 )  \nCalculations and Intervals on Original Scale\n\n\nThe boot.t.test function in the MKinfer package offers another way to calculate bootstrap statistics for single-sample continuous data. It returns the percentile confidence intervals and also offers a p value.\n\nlibrary(MKinfer)\n\nWarning: package 'MKinfer' was built under R version 4.2.3\n\nboot.t.test(iris[iris$Species == \"virginica\",\"Sepal.Length\"], mu = 7)\n\n\n    Bootstrap One Sample t-test\n\ndata:  iris[iris$Species == \"virginica\", \"Sepal.Length\"]\nbootstrap p-value &lt; 2.2e-16 \nbootstrap mean of x (SE) = 6.589584 (0.08854959) \n95 percent bootstrap percentile confidence interval:\n 6.418 6.764\n\nResults without bootstrap:\nt = -4.5815, df = 49, p-value = 3.195e-05\nalternative hypothesis: true mean is not equal to 7\n95 percent confidence interval:\n 6.407285 6.768715\nsample estimates:\nmean of x \n    6.588"
  },
  {
    "objectID": "content/chapters/Tests_for_continuous_data_from_one_sample.html#next-steps",
    "href": "content/chapters/Tests_for_continuous_data_from_one_sample.html#next-steps",
    "title": "One sample tests for continuous data",
    "section": "Next steps",
    "text": "Next steps\nNow that we’ve covered dealing with categorical and continuous data, we will move to comparing populations to each other."
  },
  {
    "objectID": "content/end_matter/additional_resources.html",
    "href": "content/end_matter/additional_resources.html",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!"
  },
  {
    "objectID": "content/end_matter/additional_resources.html#class-related-materials",
    "href": "content/end_matter/additional_resources.html#class-related-materials",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!"
  },
  {
    "objectID": "content/end_matter/additional_resources.html#other-resources",
    "href": "content/end_matter/additional_resources.html#other-resources",
    "title": "Additional resources",
    "section": "Other resources",
    "text": "Other resources\nAs noted in the introduction, there are many, many resources that may assist you in your quest to learn statistics and R. Relevant ones are noted throughout the book and listed here.\n\nGeneral R\nPhillips (n.d.)\n\n\nGit help\nHester (n.d.)"
  },
  {
    "objectID": "content/practice_problems/1_Getting_used_to_R.html",
    "href": "content/practice_problems/1_Getting_used_to_R.html",
    "title": "Getting used to R",
    "section": "",
    "text": "Overview\nThe focus of this overview is to get you used to tools we will be using in class. Before completing it you should have a basic understanding of using R. We will do an introduction in class (download help file). You should also be comfortable using Rstudio and github (see help file).\n\nRmd basics\nRmd files differ from R files in that they combine regular text with code chunks. This is a code chunk\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nCode chunks combine code with output. When combined with regular text/prose, this makes it easier to produce a range of documents. You set the output in the YAML header (the stuff between the 3 dashes you see at top of this document).\nAfter you write the file, you Knit it to turn the Rmd file into the selected output. Try it now. Note the first time you do this in a project you may be prompted to install a number of packages! If you are using a webservice you may also need to allow pop-ups in your browser. Don’t be surprised if a new window pops up (it should).\n\n\n\nThe knit button turns your .rmd file into other products\n\n\nThe Knit button saves the .Rmd file and renders a new version whose output depends on what you selected in the header. Here we have html_document, so if everything works a preview of a webpage like document should appear. The file also produces a github friendly .md file. This means you should only edit the Rmd file (leave the md and output files alone! They are automatically produced any changes you make there will be overwritten by your next knit).\nWhen you Knit a file, it runs in a totally new R instance. this means anything you only added in your instance (like working in the console) won’t be available. In other words, its the best way to see what a “new” user gets when they use your code.\nhowever, you don’t have to knit the file every time. if you just want to see output, note you can press the green button next to an R chunk.\n\n\n\nThe green arrows just runs the chunk in the console and shows the output\n\n\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nNow we’ll start changing the file to show you how rmarkdown works. First, amend the file by replacing the NAME and DATE spots in the header (top of the file between the — markers) with your name and the real date. Then Knit the file again. You should see your name in the new preview.\nRstudio has a Markdown Quick Reference guide (look under the help tab), but some general notes.\n\nPound/Hashtag signs denote headers\nyou can surround something double asterisks for bold or single asterisks for italics\nlists are denoted by numbers or asterisks at beginning of line (followed by space!)\n\nand can be indented for sublevels\n\nR code can be done inline, but is generally placed in stand-alone chunks\n\nthese will, by default, show the code and output\n\nlots of other options exist!\n\nThe main idea is Rmd files allow you to combine code, text, graphs, etc into multiple outputs that you can share (including with coding illiterate colleagues who just want output).\nTo practice working with Rmd files and R, work through the questions below. You can also get more help with this video\n\n\n\nPractice in R\n\n1\nLet x be defined by\n\nx &lt;- 5:15\n\nTry executing this chunk (in R studio, not the webview) by clicking the Run button within the chunk or by placing your cursor inside it and pressing Ctrl+Shift+Enter.\nThis will run the code in the Console. You may need to switch to Console (from Rmarkdown) in the lower right window area to see this. The executed code is also displayed in your processed file (hit Knit again to see this!).\nNote running this chunk has added an object named x to the Environment tab area (top right area of screen). But nothing was “returned” in the console. You prove this by typing x in the console. What does it return?\nDetermine what the “:” does! Complete the following sentence:\nThe : means FILL THIS IN.\n\n\n2\nNow try to guess the output of these commands\n\nlength(x)\nmax(x)\nx[x &lt; 10]\nx^2\nx[ x &lt; 12 & x &gt; 7]\n\nINSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Add a new chunk by clicking the Insert Chunk button on the toolbar or by pressing Ctrl+Alt+I. Then state what each of these does.\n\n\n3\nIs -1:2 the same as (-1):2 or -(1:2)? INSERT AN R CHUNK HERE AND RUN EACH OF THESE COMMANDS. Then state what each of these does.\n\n\n\nData input, plotting, and tests\nYou can read in a dataset from the internet following this protocol.\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nRun this chunk and note it has added an object named sleep to the environment.\nInfo on the dataset is viewable @ http://www.statsci.org/data/general/sleep.html.\n\n4\nHow many rows does the sleep data set have (hint: ?dim)? What kind of data is stored in each variable?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n5\nChange the column named BodyWt to Body_weight”* in the sleep dataset.\nADD ANY R CHUNKS YOU USED TO COMPLETE THE TASK.\n\n\n6\nProduce a plot of how TotalSleep differs between primates and other species. What is this plot showing?\nNote, as of early 2020 R no longer reads in strings as factors! This means the Primate column, which is full of “Yes”s and “No”s, reads in as words and R doesn’t know how to plot them. There are many ways to handle this. You can modify the read.csv command (add stringsAsFactors = T option), eg\n\nsleep &lt;- read.csv(\"http://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n\nIf you do this, you’ll need to rechange anything you previously updated to the object (like renaming the BodyWt column).\nYou can also modify a single column for the actual object\n\nsleep$Primate &lt;- factor (sleep$Primate)\n\nor for a single command, eg (plot not actually shown!)\n\nplot(BodyWt ~ factor(Primate), data = sleep)\n\nNOTE YOU CAN ADD A PLOT TO THE DOCUMENT TOO! AMEND THE BELOW AS NEEDED.\n\nplot(cars)\n\n\n\n\n\n\n7\nThe sleep dataset begs to have a linear model fit for it. Let’s consider. First plot how TotalSleep is explained by BrainWt. Are there any issues with the data? Exclude any outlier and fit a linear model to obtain the p-value for the model (hint: summary()). What does this imply?\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n\nEXTRA QUESTIONS\nnot required\n Dow Puffin Matthew Zalewski / CC BY (https://creativecommons.org/licenses/by/3.0)\n\n8\nSometimes data doesn’t have headers (column names),so you have to add them. Download a dataset on alcids (birds like puffins and auklets) from https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/alcids55.csv.\nYou’ll need to modify the read.csv function by specifying header = False, then use the names function to name the columns [“year”, “a1_abund”, “NAO”, “a2_abund”, “a3_abund”, “a4_abund”, “a5_abund”, “a6_abund”]. Try it and check your input using the head command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER.\n\n\n9\nHere’s a sample dataset:\n\n\n\nDate\ngreenness\nRichness\nhabitat\n\n\n\n\n12-25-2009\n13766\n46\nforest\n\n\n01-01-2010\n50513\n60\nforest\n\n\n01-15-2010\n25084\n60\ngrassland\n\n\n\nEnter it into R (manually or via a .csv). (Hint: you have a piece of this in the code already). Check your input using the head() command.\nENTER ANSWERS HERE. ADD ANY R CHUNKS YOU USED TO FIND THE ANSWER."
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#overview",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#overview",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Hypothesis testing starting with binomial tests lecture."
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#hypothesis-testing-and-the-binomial-distribution",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#hypothesis-testing-and-the-binomial-distribution",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Hypothesis Testing and the Binomial Distribution",
    "text": "Hypothesis Testing and the Binomial Distribution\n\nExample\nUsing the bat paper from class (Geipel et al. 2021), let’s consider how to analyze data showing all 10 bats chose the walking over the motionless model.\n\nbinom.test(10,10)\n\n\n    Exact binomial test\n\ndata:  10 and 10\nnumber of successes = 10, number of trials = 10, p-value = 0.001953\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6915029 1.0000000\nsample estimates:\nprobability of success \n                     1 \n\n\nWe use the binom.test function. We only need arguments for # of succeses and # of trials. By default it runs a 2-sided test against a null hypothesis value of p = .5. You can see how to update thee options by looking at the help file.\n\n?binom.test\n\nNote the confidence interval is assymetric since its estimated to be 1! We can see other options using the binom.confint function from the binom package.\n\nlibrary(binom)\nbinom.confint(10,10)\n\n          method  x  n      mean     lower    upper\n1  agresti-coull 10 10 1.0000000 0.6791127 1.043355\n2     asymptotic 10 10 1.0000000 1.0000000 1.000000\n3          bayes 10 10 0.9545455 0.8292269 1.000000\n4        cloglog 10 10 1.0000000 0.6915029 1.000000\n5          exact 10 10 1.0000000 0.6915029 1.000000\n6          logit 10 10 1.0000000 0.6915029 1.000000\n7         probit 10 10 1.0000000 0.6915029 1.000000\n8        profile 10 10 1.0000000 0.7303058 1.000000\n9            lrt 10 10 1.0000000 0.8252466 1.000000\n10     prop.test 10 10 1.0000000 0.6554628 1.000000\n11        wilson 10 10 1.0000000 0.7224672 1.000000\n\n\nAll of these correct for the fact that most intervals use a normal approximation, which as you remember from our earlier discussions is not good when sample sizes are small and/or the p parameter is extreme (close to 0 or 1)."
  },
  {
    "objectID": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#practice",
    "href": "content/practice_problems/3_Introduction_to_hypothesis_testing_via_binomial_test.html#practice",
    "title": "3. Introduction to hypothesis testing via binomial tests",
    "section": "Practice!",
    "text": "Practice!\nMake sure you are comfortable with null and alternative hypotheses for all examples.\n\n1\nAre people eared (do they prefer one ear or another)? Of 25 people observed while in conversation in a nightclub, 19 turned their right ear to the speaker and 6 turn their left ear to the speaker. How strong is the evidence for eared-ness given this data (adapted from Analysis of Biological Data)? * state a null and alternative hypothesis * calculate a test statistic (signal) for this data * Make you understand how to construct a null distribution + using sampling/simulation (code or written explanation) + by using an appropriate distribution (code or written explanation) * Calculate and compare p-values obtained using + simulation (calculation won’t be required on test, but make sure you understand!) (code or written explanation) + equations for binomial distribution (code or written explanation) + R functions (required)(code) * Calculate a 95% confidence interval for the proportion of people who are right-eared * How do your 95% confidence interval and hypothesis test compare?\n\n\n2\nA professor lets his dog take every multiple-choice test to see how it compares to his students (I know someone who did this). Unfortunately, the professor believes undergraduates in the class tricked him by helping the dog do better on a test. It’s a 100 question test, and every questions has 4 answer choices. For the last test, the dog picked 33 questions correctly. How likely is this to happen, and is there evidence the students helped the dog?\nMAKE SURE TO THINK ABOUT YOUR TEST OPTIONS"
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html",
    "href": "content/practice_problems/5_Contingency_analysis.html",
    "title": "Compare proportions among groups",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#overview",
    "href": "content/practice_problems/5_Contingency_analysis.html#overview",
    "title": "Compare proportions among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture."
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#examples",
    "href": "content/practice_problems/5_Contingency_analysis.html#examples",
    "title": "Compare proportions among groups",
    "section": "Examples",
    "text": "Examples\nIssue is we often get data in spreadsheet format (expanded/long or wide/summarized, each shown below), but we need to get a vector or matrix for chisq.test and related functions.\n\nThe data\nFollowing the Everest example from class. Assume data is in a dataframe where each row is a group data point.\n\neverest &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\"),\n                      Oxygen = c(\"Used\", \"Used\", \"Not used\", \"Not used\"),\n                      Number = c(1045, 32, 88, 8))\n\nAssume data is in a dataframe where each row is an individual data point.\n\nlibrary(mirt)\n\nWarning: package 'mirt' was built under R version 4.2.3\n\n\nLoading required package: stats4\n\n\nLoading required package: lattice\n\neverest_expand &lt;- expand.table(everest)\n\n\n\ntests\nFirst, let’s ask if the same amount of people used or did not use oxygen. WE can use the table command to summarize. Note the chisq.test, by default, assumes each group is equally likely!\n\ntable(everest_expand$Oxygen)\n\n\nNot used     Used \n      96     1077 \n\nchisq.test(table(everest_expand$Oxygen)) \n\n\n    Chi-squared test for given probabilities\n\ndata:  table(everest_expand$Oxygen)\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nDong this with summarized data is actually harder\n\naggregate(Number~Oxygen, everest, sum)$Number\n\n[1]   96 1077\n\nchisq.test(aggregate(Number~Oxygen, everest, sum)$Number) \n\n\n    Chi-squared test for given probabilities\n\ndata:  aggregate(Number ~ Oxygen, everest, sum)$Number\nX-squared = 820.43, df = 1, p-value &lt; 2.2e-16\n\n\nBut this is better!\n\nbinom.test(table(everest_expand$Oxygen))\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value &lt; 2.2e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we wanted to compare to past years where 10% of climbers did not use oxygen? Note table function splits into alphabetical order.\n\nbinom.test(table(everest_expand$Oxygen), p=.1)\n\n\n    Exact binomial test\n\ndata:  table(everest_expand$Oxygen)\nnumber of successes = 96, number of trials = 1173, p-value = 0.04075\nalternative hypothesis: true probability of success is not equal to 0.1\n95 percent confidence interval:\n 0.06679216 0.09902483\nsample estimates:\nprobability of success \n            0.08184143 \n\n\nWhat if we want to determine if using oxygen impacts surival?\n\nchisq.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\nWarning in chisq.test(table(everest_expand$Oxygen, everest_expand$Survived)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nIssue (which we’ll address), but note same as\n\nchisq.test(table(everest_expand$Survived, everest_expand$Oxygen))\n\nWarning in chisq.test(table(everest_expand$Survived, everest_expand$Oxygen)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  table(everest_expand$Survived, everest_expand$Oxygen)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 88, 32, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\nchisq.test(x = matrix(c(1045, 32, 88,  8), 2, 2, byrow = T))\n\nWarning in chisq.test(x = matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)):\nChi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  matrix(c(1045, 32, 88, 8), 2, 2, byrow = T)\nX-squared = 6.1524, df = 1, p-value = 0.01312\n\n\nKey is first argument must be all the info. This is different from (incorrect) approach like\n\nchisq.test(everest$Survived,everest$Oxygen)\n\nWarning in chisq.test(everest$Survived, everest$Oxygen): Chi-squared\napproximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  everest$Survived and everest$Oxygen\nX-squared = 0, df = 1, p-value = 1\n\n\nThis is comparing split among Survived and not to split (expected) using Oxygen!\nSo order has minimal input with 2 groups. Other test options necessitated by the warning\n\nfisher.test(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\np-value = 0.01284\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n 1.144791 6.826869\nsample estimates:\nodds ratio \n  2.964765 \n\nlibrary(DescTools)\nGTest(table(everest_expand$Oxygen, everest_expand$Survived))\n\n\n    Log likelihood ratio (G-test) test of independence without correction\n\ndata:  table(everest_expand$Oxygen, everest_expand$Survived)\nG = 5.7466, X-squared df = 1, p-value = 0.01652\n\n\nWhat if we added another group? Like Enriched, Regular, None for oxygen.\n\neverest_enriched &lt;- data.frame(Survived = c(\"Y\",\"N\",\"Y\", \"N\", \"Y\", \"N\"),\n                      Oxygen = c(\"Regular\", \"Regular\", \"None\", \"None\", rep(\"Enriched\", 2)),\n                      Number = c(1045, 32, 88, 8, 15, 2))\neverest_enriched_expand &lt;- expand.table(everest_enriched)\n\nNow we compare\n\ntable(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\n\n   \n    Enriched None Regular\n  N        2    8      32\n  Y       15   88    1045\n\nchisq.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(table(everest_enriched_expand$Survived,\neverest_enriched_expand$Oxygen)): Chi-squared approximation may be incorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\nX-squared = 10.879, df = 2, p-value = 0.004343\n\n\nFisher again due to size\n\nfisher.test(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen)\np-value = 0.00586\nalternative hypothesis: two.sided\n\n\nNow we follow-up, and rows/columns matter. Note default is row and fdr method. I order results for ease of view\n\nlibrary(rcompanion)\n\nWarning: package 'rcompanion' was built under R version 4.2.3\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen))\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n  Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq p.adj.Chisq\n1      N : Y  0.00586      0.00586  0.0189      0.0189 0.00434     0.00434\n\n\nNot quite what we wanted. How about\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1430  0.1080      0.1620  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.2560\n1      1.0000\n\n\nand you can change methods\n\neverest_expand_correct_fdr &lt;- pairwiseNominalIndependence(table(everest_enriched_expand$Survived, everest_enriched_expand$Oxygen),\n                                                          compare = \"col\",\n                                                          method = \"holm\")\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\nWarning in chisq.test(Dataz, ...): Chi-squared approximation may be incorrect\n\neverest_expand_correct_fdr[order(everest_expand_correct_fdr$p.adj.Fisher),]\n\n          Comparison p.Fisher p.adj.Fisher p.Gtest p.adj.Gtest p.Chisq\n3     None : Regular   0.0128       0.0384  0.0165      0.0495  0.0131\n2 Enriched : Regular   0.0953       0.1910  0.1080      0.2160  0.1710\n1    Enriched : None   0.6450       0.6450  0.6580      0.6580  1.0000\n  p.adj.Chisq\n3      0.0393\n2      0.3420\n1      1.0000\n\n\nTo put in manually, we need a few extra things\n\neverest_table &lt;- as.table(matrix(c(2,8,32,15,88,1045), nrow = 2, byrow = T))\nrownames(everest_table) = c(\"N\", \"Y\")\ncolnames(everest_table) = c(\"Enriched\", \"None\", \"Regular\")\neverest_table\n\n  Enriched None Regular\nN        2    8      32\nY       15   88    1045"
  },
  {
    "objectID": "content/practice_problems/5_Contingency_analysis.html#lets-practice",
    "href": "content/practice_problems/5_Contingency_analysis.html#lets-practice",
    "title": "Compare proportions among groups",
    "section": "Let’s practice",
    "text": "Let’s practice\n\nHeart attacks\n\n1\nLet’s look at some heart attack data. Read in the data using\n\nheart_attacks &lt;- read.table(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/heartatk4R.txt\",header=T, stringsAsFactors = T)\n\nEvery entry is a person that has suffered a heart attack. More information on the dataset can be found at\nhttp://statland.org/Software_Help/DataDesk/datafile.htm\nWe want to again test if heart attacks occur equally across genders.\n\nWhat if we know that males actually make up 50.8% of the population?\n\n\n\n2\nStill using the heart attack data, is survival independent of gender?\n\n\n3\nFor people that have a heart attack before they turn 30, is survival independent of gender?\n\n\n\nDolphins\n\n4\nData on dolphin behavior was collected off the coast of Iceland. Data is @\nhttp://www.statsci.org/data/general/dolpacti.txt\nSince this is a .txt file, not a .csv, you’ll need to use something like\n\ndolphin &lt;- read.table(\"http://www.statsci.org/data/general/dolpacti.txt\", sep=\"\", header = T, stringsAsFactors = T)\n\nMore info on data @\nhttp://www.statsci.org/data/general/dolpacti.html\nIs travelling independent of time of day? You’ll need to consider traveling vs not traveling due to different number of groups observed in each period. Carry out post-hoc tests if needed.\n\n\n\nSmoking\n\n5\nUse data on smoking and exercise from\nhttp://www.r-tutor.com/elementary-statistics/goodness-fit/chi-squared-test-independence\nto determine if smoking is independent of exercise. You’ll need to input data manually. Carry out post-hoc tests if needed."
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html",
    "href": "content/practice_problems/7_More_ANOVAs.html",
    "title": "More ANOVAs",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#overview",
    "href": "content/practice_problems/7_More_ANOVAs.html#overview",
    "title": "More ANOVAs",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the More ANOVAs lecuture."
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#examples",
    "href": "content/practice_problems/7_More_ANOVAs.html#examples",
    "title": "More ANOVAs",
    "section": "Examples",
    "text": "Examples\n\nIf interaction is significant\nFollowing the memory example from class, read in and check data\n\nmemory &lt;- read.table(\"http://www.statsci.org/data/general/eysenck.txt\", header = T,\n                     stringsAsFactors = T)\nstr(memory)\n\n'data.frame':   100 obs. of  3 variables:\n $ Age    : Factor w/ 2 levels \"Older\",\"Younger\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Process: Factor w/ 5 levels \"Adjective\",\"Counting\",..: 2 2 2 2 2 2 2 2 2 2 ...\n $ Words  : num  8 6 4 6 7 6 5 7 9 7 ...\n\n\nLet’s put younger level first\n\nlibrary(plyr)\nmemory$Age &lt;- relevel(memory$Age, \"Younger\")\n\nand graph\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nfunction_output &lt;- summarySE(memory, measurevar=\"Words\", groupvars =\n                               c(\"Age\", \"Process\"), na.rm = T)\nlibrary(ggplot2)\nggplot(function_output, aes(x=Age, y=Words,color=Process, \n                                   shape = Process)) +\n  geom_line(aes(group=Process, linetype = Process), size=2) +\n    geom_point(size = 5) +\n  ylab(\"Words remembered\")+ \n  xlab(\"Age\") + \n  ggtitle(\"Process type interacts with age to impact memory\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nThere appears to be some interactions. Let’ build a model\n\nmemory_interactions &lt;- lm(Words ~ Age * Process, memory)\n\nand check assumptions.\n\npar(mfrow=c(2,2))\nplot(memory_interactions)\n\n\n\n\nThese appear to be met, so look at output\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(memory_interactions, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 272.9281 &lt; 2.2e-16 ***\nAge           72.2  1   8.9963 0.0034984 ** \nProcess     1353.7  4  42.1690 &lt; 2.2e-16 ***\nAge:Process  190.3  4   5.9279 0.0002793 ***\nResiduals    722.3 90                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSince interaction is significant, analyze subsets. For example,\n\nmemory_interactions_young &lt;- lm(Words ~ Process, memory[memory$Age == \"Younger\",])\nplot(memory_interactions_young)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(memory_interactions_young, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Words\n            Sum Sq Df F value    Pr(&gt;F)    \n(Intercept) 2190.4  1 343.442 &lt; 2.2e-16 ***\nProcess     1353.7  4  53.064 &lt; 2.2e-16 ***\nResiduals    287.0 45                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThere is a significant difference in words recalled based on process, but why? Investigate with post-hoc tests.\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncomp_young &lt;- glht(memory_interactions_young, linfct = mcp(Process = \"Tukey\"))\nsummary(comp_young)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Words ~ Process, data = memory[memory$Age == \"Younger\", \n    ])\n\nLinear Hypotheses:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \nCounting - Adjective == 0      -8.300      1.129  -7.349   &lt;1e-04 ***\nImagery - Adjective == 0        2.800      1.129   2.479   0.1136    \nIntentional - Adjective == 0    4.500      1.129   3.984   0.0022 ** \nRhyming - Adjective == 0       -7.200      1.129  -6.375   &lt;1e-04 ***\nImagery - Counting == 0        11.100      1.129   9.828   &lt;1e-04 ***\nIntentional - Counting == 0    12.800      1.129  11.333   &lt;1e-04 ***\nRhyming - Counting == 0         1.100      1.129   0.974   0.8655    \nIntentional - Imagery == 0      1.700      1.129   1.505   0.5646    \nRhyming - Imagery == 0        -10.000      1.129  -8.854   &lt;1e-04 ***\nRhyming - Intentional == 0    -11.700      1.129 -10.359   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n\nBlocking example\nFollowing feather color example from class:\n\n# more than 2? ####\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nstr(feather)\n\n'data.frame':   32 obs. of  3 variables:\n $ Bird       : Factor w/ 16 levels \"A\",\"B\",\"C\",\"D\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ Feather    : Factor w/ 2 levels \"Odd\",\"Typical\": 2 2 2 2 2 2 2 2 2 2 ...\n $ Color_index: num  -0.255 -0.213 -0.19 -0.185 -0.045 -0.025 -0.015 0.003 0.015 0.02 ...\n\nset.seed(25)\nspecial &lt;- data.frame(Bird = LETTERS[1:16], Feather = \"Special\", \n                      Color_index= feather[feather$Feather == \"Typical\", \"Color_index\"] +\n                        .3 +runif(16,1,1)*.01)\nfeather &lt;- merge(feather, special, all = T)\n\n\nAnova(lm(Color_index ~ Feather + Bird, data=feather), type= \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Color_index\n             Sum Sq Df  F value    Pr(&gt;F)    \n(Intercept) 0.36392  1  59.9538 1.224e-08 ***\nFeather     1.67906  2 138.3093 7.208e-16 ***\nBird        0.34649 15   3.8055 0.0008969 ***\nResiduals   0.18210 30                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlibrary(multcomp)\ncompare &lt;- glht(lm(Color_index ~ Feather + Bird, data=feather), linfct = mcp(\"Feather\" = \"Tukey\"))\nsummary(compare)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Color_index ~ Feather + Bird, data = feather)\n\nLinear Hypotheses:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \nTypical - Odd == 0      0.13713    0.02755   4.978   &lt;1e-04 ***\nSpecial - Odd == 0      0.44712    0.02755  16.232   &lt;1e-04 ***\nSpecial - Typical == 0  0.31000    0.02755  11.254   &lt;1e-04 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\n\n#note comparison doesn't work\nAnova(lm(Color_index ~ Feather * Bird, data=feather), type= \"III\")\n\nError in Anova.lm(lm(Color_index ~ Feather * Bird, data = feather), type = \"III\"): residual df = 0"
  },
  {
    "objectID": "content/practice_problems/7_More_ANOVAs.html#practice",
    "href": "content/practice_problems/7_More_ANOVAs.html#practice",
    "title": "More ANOVAs",
    "section": "Practice",
    "text": "Practice\n\n1\nA survey was conducted to see if athletes and non-athletes deal with anger in the same way. Data is @\nangry &lt;- read.csv(“https://docs.google.com/spreadsheets/d/e/2PACX-1vSaawG37o1ZUEs1B4keIJpZAY2c5tuljf29dWnzqQ0tHNCzfbz85AlWobYzBQ3nPPXJBLP-FWe4BNZB/pub?gid=1784556512&single=true&output=csv”, stringsAsFactors = T)\nand more information is at\nhttp://onlinestatbook.com/case_studies/angry_moods.html.\nFocus on the following variables:\nSports 1 = athletes, 2 = non-athletes Gender 1 = males, 2 = females Expression (AE) index of general anger expression: (Anger-Out) + (Anger-In) - (Control-Out) - (Control-In) + 48\nIs there any evidence that gender or athlete status impact how anger is expressed?\n\n\n2\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at http://www.statsci.org/data/oz/ms212.txt With more info at http://www.statsci.org/data/oz/ms212.html. Is there evidence that frequency of exercise (Exercise column) and gender impact change in pulse rate for students who ran (Ran column = 1)?\n\n\n3\nData from Valdez et al 2023 is available @ https://docs.google.com/spreadsheets/d/e/2PACX-1vT2gaLu6pyRMlcbzarn3ej4bFmT_iHvrlNWJYSdrsLdUWIjcJi7rU11-ipvYpGnqD9qLDnbhNd2sDUW/pub?gid=1707080634&single=true&output=csv.\nImport it into to R and\n\ndetermine how the snail grazing and nitrogen levels impact number of flowering shoots ( Shoot.density..m2)\nconstruct a plot to showcase your analysis\n\n\n\n4\nFind an example of a factorial ANOVA from a paper that is related to your work. Make sure you understand the connections between the methods, results, and graphs. Briefly answer the following questions\n\nWhat was the dependent variable?\nWhat were the independent variables?\nWas the interaction significant?\n\nIf so, how did they interpret findings\nIf not, were the main effects significant?"
  },
  {
    "objectID": "content/primer_material/tools_overview.html",
    "href": "content/primer_material/tools_overview.html",
    "title": "Downloading tools and using github",
    "section": "",
    "text": "In class we will use R, Rstudio (now Posit), and git (via github). Below are notes to help you download these and get started.\n\nRequired tools\n\nGet access to R!. You can make an account at Rstudio cloud (https://rstudio.cloud/), now Posit!. You can also install R (https://cran.r-project.org/) and Rstudio (https://www.rstudio.com/) on your machine, but I strongly recommend starting with Rstudio cloud.\nRstudio cloud is free for up to 25 hours/month, you don’t have to maintain it, and it gives gives a standard install (same on all machines, so your intro/ our training may be smother). You can also do both. If you need help, videos are at :\n\nDownloading R\nDownloading Rstudio\nMaking a Rstudio cloud account\n\nJoin the github classroom we’ll be using for our sessions\n\nCheck blackboard for your class!\nWhen you visit the page it will ask you to connect or create a github repository. You can use any name (be anonymous or not) that you want. This is a free process.\n\n\n\n\nGetting started on an assignment\nIt may be easier to open these instructions in a browser so you can follow along there while working in Rstudio!\nAt this point I’m assuming you received an invitation to view an assignment on github classroom and accepted it.After you join the github classroom, you’ll make a clone of the repository onto your machine. First, find your copy of the repository. You can follow the github classroom link again, or log into github and then visit https://github.com/settings/repositories. Find the repository called data_science_intro_YOURGITHUBUSERNAME, and click on it. Then follow along below - find instructions for Rstudio cloud or Rstudio desktop depending on your setup.\n\nIf you are using Rstudio cloud…\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio cloud\nLog into your Rstudio cloud account. You’ll see something like this:\n\n\n\nRstudio cloud home screen\n\n\nTo copy a repository, select New Project, New Project from Github repo. Next you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!)\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the field asking for the URL of your github repository.\nNote you may need to enter your github username and password to create the repository.\nThe next screen will bring you to a “normal” RStudio screen. Continue to the Now we can actually work in R section to get started\n\n\nIf you are using RStudio on your desktop (or via a server…anywhere that\nlooks like an RStudio screen)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio desktop\nTo start working on an assignment, open RStudio.\n\n\n\nSelect File &gt; New Project in Rstudio\n\n\nSelect file, new project, Version control. On the next screen select git. If this isn’t available, you may need to install git (free) on your system. You can download it at https://git-scm.com/download/.\nNext you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!).\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the Rstudio Repository URL space. You can select/edit what you want the repository to be called and where its stored (its just a folder on your computer). For example, I have a Repositories folder in my main hard drive where I save all of these. Then select Create project. Whatever you choose, the project will be saved in new folder in that location using the name you chose. Note you may need to enter your github username and password to create the repository.\nYou also may get an error/warning about personal access token! this happens at different points on different machines (thus why Rstudio cloud is nice). If you see this now, see below for help.\nIf everything work, the next screen will bring you to a “normal” RStudio screen.\nContinue to the Now we can actually work in R section to get started\n\n\nNow we can actually work in R and markdown\nNow you can start working on the files in the repository in Rstudio. To view the files, make sure you are in the right repository. You should see whatever you named the project in the upper right hand corner of Rstudio. If you don’t go to File &gt; Open Project and navigate to where you placed the repository.\nOnce you are in the right project, open the file you want to work on. From inside the project space, go to File, Open File and find it, or look in the Files window to find and open the file.\nFor example, our first assignment is in the 1._Getting_used_to_R folder. We’ll work through the 1_intro_to_R.R script first. Open the file, and a window with a lot of text should appear in your Rstudio.\n\n\nEditing, committing, and pushing changes\nTo understand how git works, change line 2 of the 1_intro_to_R.R file to have your name. Then hit save (disk icon). This saves a copy of the file on your machine. In order for me to see it, we need to push those changes to a github repository.\n\n\nCommitting files to your github repository\nIf you look in the upper right windows, you should see a Git tab. Select it.\n\n\n\nThe git tab allows you to use git commands in Rstudio\n\n\nNotice it has several files. These are the files you have changed or created since you started working. Click the checkbox next to the files, and select Commit. You’ll need to enter a description. Put “My first commit!” and press Commit.\nIf you get a screen that looks like this:\n\n\n\nThis screen means you need to tell your computer who to assign changes to\n\n\nIt just means we need to associate an identity with the commits. To do this, close (x) the git windows. Select the terminal tab:\n\n\n\nThe terminal tab lets you send commands to your computer\n\n\nThen paste this line into the terminal (tab to the right of the console tab), (note you need 2 – should be 2 dashes!)\ngit config –global user.email “you@example.com”\nreplace the email with your email (leave the quotes) and press enter.\nThen paste this line into the terminal,\ngit config –global user.name “Your Name”\nreplace the Your Name with your name (leave the quotes) and press enter.\nNow go back to the git window and try the commit again. It should work. You will only have to do this once (for desktop versions) and only occasionally for cloud-based RStudio instances.\nNow you’ve committed to the file to your local Rstudio instance (on your own machine or server), which is itself a git repository. This is different than a save. A save overwites the current file, while a commit compares changes you have made and tracks them. To see this, you can go the Git tab, select Diff, and then History on the pop-you. From there, you can select the commit, select any file you committed, and actually see the changes. This allows you to go back to (or just see) earlier versions easily, which is often helpful in programming.\n\n\nPushing to github\nNow you need to push these changes to the cloud so I can see them (or, in the future, so you could share with collaborators or save a copy for yourself). From the Git tab, select Push. As of Fall 2021, Github no longer accepts usernames and passwords for authentication. However, Rstudio may ask you for these depending on what version you are using. Don’t be surprised if you enter your password correctly but your attempt to create a repository (or push commits to it) still fails because you need to setup or reset a token.\n\n\n\nIf you see this, it means you need to setup or reauthorize a github token\n\n\nIf you see this message now, go to the Github 2-factor authentication (required as of Fall 2021) section!). If not, you can continue, but note you’ll have to do it later (when you push changes).\n\n\nGithub 2-factor authentication (required as of Fall 2021)\nGithub requires you to use a token to verify you have permission to make changes to repositoties that you store there. To create a token, can use the code below. If this file is open in R, you can select the green triangle button (play icon) to run the current chunk. Otherwise you can copy and paste it into R. Note you may also need to install the usethis library first.\n\nlibrary(usethis)\nusethis::create_github_token()\n\nThis will launch a browser pointed to github. You may need to log in. Then it will have you name a PAT (personal access token). You can, for example, name it Rstudio. Then scroll to the bottom, and select Generate Token. Save the token somewhere (you’ll never see it again once you close the window). Then run the next code chunk. Select 3, then paste in the token you just generated. Again, you may need to install the gitcreds package.\n\nlibrary(gitcreds)\ngitcreds_set()\n\nThis process is letting your computer and github communicate and should only need to be done once for a desktop. For rstudio.cloud, you will need to regularly reenter the token, but you don’t have to recreate it. So save you PAT somewhere just in case. If/when you lose it, however, you can simply make a new one and reconnect the repositories.\nOnce you enter your git credentials, try to push your changes again. It should work this time. A window should appear. When it’s done (white text shows) go to your github repository (on the web). Open the folder for this assignment and click on the .md file. It should preview, and you should see the updated file with your name! Congratulations!\nAs you work, use commits to save snapshots of your work in a version control manner, and pushes to share them. If you get stuck, you can also push your file up so I can see it and help you fix it (much better than “My code isn’t working). Then you can actually see”how” I fixed it. The code will also be useful for assessments."
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html",
    "title": "Estimation and ggplot2",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#overview",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#overview",
    "title": "Estimation and ggplot2",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Estimation lecture and the use of ggplots (lots of ggplot2 example code in the Summarizing data lecture\n\nggplot2 basics\nggplot2 is a great plotting package that allows a lot of control over your output. Let’s do some examples using the sleep dataset that we left off with last week. Load the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nggplot2 works in layers so you can or subtract as needed. Provided code is verbose here so you can see what its doing. First, install and call the package.\n\nlibrary(ggplot2)\n\nTo make a plot, first set a base layer using the ggplot function.\n\ndreaming_sleep_relationship &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming))\n\nHere we are naming a dataframe to use (first argument), then noting which columns to use for the x and y axis (under the aes argument, stands for aesthetics).\nNote when we do this we get a blank graph (if we name the ggplot output, we have to call it to see it!)\n\ndreaming_sleep_relationship\n\n\n\n\nNext we add data layers using geom_ commands. Let’s start with a scatter plot, which we make using the geom_point command.\n\ndreaming_sleep_relationship_scatter &lt;- ggplot(sleep, aes(x=TotalSleep, y = Dreaming)) + \n  geom_point()\n\nAgain, nothing is shown, but not the object is saved! We can call it\n\ndreaming_sleep_relationship_scatter\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nWe can also just call it directly, but when/if we do this the object is not saved in the environment.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point()\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIf nothing extra is given, the geom_commands inherit everything from the ggplot command. So here we get a scatter plot of the relationship between TotalSleep and Dreaming. Note the axis labels are the column titles, which may not be what we want in the end in regards to readability.\nHowever, now you have a basic plot. You can also use other arguments in geom_layer commands to add to it. For example, let’s color these by primate\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Primate))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNow we’ve added information on primates. Since that require us to get more data from the dataset, we had to add another aes argument. Note this is different from (not evaluated in code, as it causes an error!)\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"Primate\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nError in `geom_point()`:\n! Problem while converting geom to grob.\nℹ Error occurred in the 1st layer.\nCaused by error:\n! Unknown colour name: Primate\n\n\nand this\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(colour=\"blue\")\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThe first causes an error as primate isn’t a color. The second makes all points blue! Also note the 2nd method loses the legend as color now conveys no information.\nIn general, you have to put things you want to plot in the aes argument area and anything outside of that changes the entire plot. For example, we can change the size of all points using\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(size = 4)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nThis is also a good time to talk about renaming factor labels. You may want to change Primate levels to Yes and No for your graph. Lots of ways to do this, but the revalue function in the plyr package is nice (and we’ll use this suite of packages often, same person developed ggplot2, plyr, and reshape)\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\n\nNotice what I did above. I made a new column from an existing one using a name I might want on a legend. Now I can use it in a graph.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nI can also just change the legend title directly or change legend text, but often workign with the dataframe is easier for me.\nIf we wanted the levels of Primate in a different order, we can use the relevel function in the plyr package to set one as the “first” level (and then do this sequentially to get them in the right order if needed). You can also change level orders using the factor or ordered functions for multiple levels at once.\n\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\" )\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nFinally, we can use the theme or related functions (like xlab, ylab, ggtitle) to change how the graph looks. Note, all the code here is verbose so you can change as needed, but you rarely need all this.\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nYou can also directly change legend title and colours with the scale_ commands\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nIn general scale_[whatever you had aes commands]_manual lets you set colors or codes. To see color codes go to this chart\nYou can also facet a graph by another column. For example, I can split the graph I already made by Taxa\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\")) +\n  facet_wrap(~Taxa, ncol = 1)\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nNotice doing this and having legend may be redundant, so I can remove the legend\n\nggplot(sleep, aes(x=TotalSleep, y = Dreaming)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent dreaming daily\") +\n  xlab(\"Average hours spent sleeping daily\") +\n  ggtitle(\"Time spent dreaming increases with total sleeping time\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\")) +\n  facet_wrap(~Taxa, ncol = 1) +\n  guides(colour=FALSE)\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\n\n\n\nI also added a theme section to change the facet label. All this shows how you are focused on adding or layering levels in ggplot2.\nYou can save the most recent plot directly to your working directory using\n\nggsave(\"Fig1.jpg\")\n\nSaving 7 x 5 in image\n\n\nWarning: Removed 14 rows containing missing values (`geom_point()`).\n\n\nThis is useful when we need to send just an image to someone (or add it to a document). You can also just save using rstudio functionality.\nggplot2 is a great example of needing to undertand basic functionality without having to remember everything. The intro class lecture and accompanying code should help you get started. A few other points that often come up are noted below.\n\n\nHistograms\nFor histograms, you only need one axis (frequency is calculated automatically)\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNote we can just copy our theme info from above and modify as needed (or ggplot2 will largely skip un-needed info). You can also save and name a theme so you don’t have to do all this everytime.\n\nggplot(sleep, aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 12 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nFinally, remember you can subset the dataframes you feed to the ggplot functions (or any other function for that matter). For example, let’s just do a histogram of just primate sleep.\n\nggplot(sleep[sleep$Taxa == \"Primate\",], aes(x=Dreaming)) +\n  geom_histogram() + \n  #below here is ylabel, xlabel, and main title\n  ylab(\"Frequency\") +\n  xlab(\"Average hours spent dreaming daily\") +\n  ggtitle(\"Distribution of hours spent dreaming\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"),\n        strip.text.x = element_text(size = 18, colour = \"purple\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 2 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\nNot interesting, but you get the idea.\n\n\nBarcharts and confidence intervals\nEstimating is a key part of statistics and should include the value you are estimating and an estimate of uncertainty. Graphs typically show this using confidence intervals, which rely on samples of means following a normal distribution that we can describe. If we assume the estimate (not the data!) is normally distributed, we can assume things about uncertainty. Namely, we can build a 95% confidence interval around our estimate (meaning the true mean is in the range 95 out of 100 times we create a sample).\nNow’s let do these in R. Confidence intervals are often tied to barcharts. Although these are common in practice, they are not easy by default in R as statisticians don’t love them. That’s because they use a lot of wasted color. I’ll show this in a moments. However, since they are common I’ll show you how to build them.\nLet’s go back to the sleep dataset and consider the average total sleep time speed for each exposure level. First, lets change exposure to factors and label them\n\nstr(sleep) #just a reminder\n\n'data.frame':   62 obs. of  13 variables:\n $ Species    : Factor w/ 62 levels \"Africanelephant\",..: 1 2 3 4 5 6 7 8 9 10 ...\n $ BodyWt     : num  6654 1 3.38 0.92 2547 ...\n $ BrainWt    : num  5712 6.6 44.5 5.7 4603 ...\n $ NonDreaming: num  NA 6.3 NA NA 2.1 9.1 15.8 5.2 10.9 8.3 ...\n $ Dreaming   : num  NA 2 NA NA 1.8 0.7 3.9 1 3.6 1.4 ...\n $ TotalSleep : num  3.3 8.3 12.5 16.5 3.9 9.8 19.7 6.2 14.5 9.7 ...\n $ LifeSpan   : num  38.6 4.5 14 NA 69 27 19 30.4 28 50 ...\n $ Gestation  : num  645 42 60 25 624 180 35 392 63 230 ...\n $ Predation  : int  3 3 1 5 3 4 1 4 1 1 ...\n $ Exposure   : int  5 1 1 2 5 4 1 5 2 1 ...\n $ Danger     : int  3 3 1 3 4 4 1 4 1 1 ...\n $ Primate    : Factor w/ 2 levels \"N\",\"Y\": 1 1 1 1 1 1 1 1 1 2 ...\n $ Taxa       : Factor w/ 2 levels \"Primate\",\"Non-primate\": 2 2 2 2 2 2 2 2 2 1 ...\n\nsleep$Exposure &lt;- factor(sleep$Exposure)\n\nCheck levels\n\nlevels(sleep$Exposure)\n\n[1] \"1\" \"2\" \"3\" \"4\" \"5\"\n\n\nand relabel if you want (just for example here)\n\nlevels(sleep$Exposure)&lt;- c(\"Least\",\"Less\", \"Average\", \"More\", \"Most\") \n\nNext, we need to get the average and standard deviation for each group (remember this is tied to the normal distribution!). If we wanted to this by hand, we could do something like thi (let’s just focus on least for an example, and note we have to remove NA data)\n\nmean(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T)\n\n[1] 12.94615\n\n\nThis is our estimate. The standard deviation of this estimate is\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(sleep[sleep$Exposure == \"Least\" & is.na(sleep$TotalSleep) == F, \"TotalSleep\"]))\n\n[1] 0.7833111\n\n\nwhich is equivalent to\n\nsd(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"], na.rm = T) / \n  sqrt(length(na.omit(sleep[sleep$Exposure == \"Least\", \"TotalSleep\"])))\n\n[1] 0.7833111\n\n\nWe also call this the standard error of the mean.\nFortunately, we can also do this using a function from the Rmisc package in R, as ggplot2 doesn’t have it built in (maybe because bar charts are a bad idea?).\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\nsleep_by_exposure &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Exposure\", na.rm = T)\n\nInspect the table\n\nsleep_by_exposure\n\n  Exposure  N TotalSleep       sd        se       ci\n1    Least 26   12.94615 3.994119 0.7833111 1.613259\n2     Less 13   11.11538 3.957029 1.0974823 2.391209\n3  Average  4    8.57500 1.808084 0.9040419 2.877065\n4     More  5   10.72000 1.663430 0.7439086 2.065421\n5     Most 10    4.19000 1.776670 0.5618323 1.270953\n\n\nNow we can use this summarized data to make a graph that shows uncertainty (95% confidence intervals)\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nNow to show why barplots waste ink. Note we can show the same information with\n\nggplot(sleep_by_exposure\n       , aes(x=Exposure, y=TotalSleep)) +\n  geom_point(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep (hours per day\")+ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\n\nAll the exta color is nice, but its not really adding anything!"
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#lets-practice",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#lets-practice",
    "title": "Estimation and ggplot2",
    "section": "Let’s practice!",
    "text": "Let’s practice!\nLet’s return to the mammal sleep dataset that we left off with last week (Make sure you did the first assignment!).\nLoad the dataset\n\nsleep &lt;- read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/sleep.csv\", stringsAsFactors = T)\n#need to use stringsAsFactors to make characters read in as factors\n\nLast time you used the built-in plot functions to do some plots. Let’s replace those with ggplot2 and do some more.\n\n1\n\nFirst plot how TotalSleep is explained by BrainWt (remember the issues with the data). Use ggplot2 to plot the relationship.\n\n\nlibrary(ggplot2)\nggplot(sleep[sleep$BrainWt &lt;1000, ], aes(x=BrainWt, y = TotalSleep)) +\n  geom_point(size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent \\n sleeping daily\") +\n  xlab(\"Brain weight (g)\") +\n  ggtitle(\"Time spent sleeping \\n decreases with brain \\n weight\") +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n2\n\nNext color code each plot point by whether or not its a primate. In order to do this you can use the Primate column or (following class code) make a new column called Taxa to represent the information (hint:search for ” revalue”). Make sure axes are well-labeled.\n\n\nlibrary(plyr)\nsleep$Taxa &lt;- revalue(sleep$Primate, c(Y = \"Primate\", N = \"Non-primate\"))\nsleep$Taxa &lt;- relevel(sleep$Taxa, \"Primate\")\n\nggplot(sleep[sleep$BrainWt &lt;1000, ], aes(x=BrainWt, y = TotalSleep)) +\n  geom_point(aes(colour=Taxa), size = 4) +\n  #below here is ylabel, xlabel, and main title\n  ylab(\"Average hours spent \\n sleeping daily\") +\n  xlab(\"Brain weight (g)\") +\n  ggtitle(\"Time spent sleeping \\n decreases with brain \\n weight\") +\n  #scale commands help with legends\n  scale_colour_manual(name=\"Type of mammal\",values = c(\"#FFA373\",\"#50486D\")) +\n  #theme sets sizes, text, etc\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32),\n        # change plot background, grid lines, etc (just examples so you can see)\n        panel.background = element_rect(fill=\"white\"),\n        panel.grid.minor.y = element_line(size=3),\n        panel.grid.major = element_line(colour = \"black\"),\n        plot.background = element_rect(fill=\"gray\"),\n        legend.background = element_rect(fill=\"gray\"))\n\nWarning: Removed 4 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n3\n\nLet’s work with histograms.\n\n\nWhat type of variation do we see in total time spent sleeping? Create a histogram to explore this issue.\n\n\nggplot(sleep\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\nFacet the graph you created based on whether or not the animal is a primate (Primate column).\n\n\nggplot(sleep\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+ \n  facet_wrap(~Taxa)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 4 rows containing non-finite values (`stat_bin()`).\n\n\n\n\n\n\nNow only graph the data for primates.\n\n\nggplot(sleep[sleep$Taxa == \"Primate\",]\n       , aes(x=TotalSleep)) +\n  geom_histogram() +\n  xlab(\"Total sleep (hours per day\")+ggtitle(\"Variation in sleep levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n4\n\nDevelop a properly-labeled bar graph with error bars to explore how total sleep changes with\n\n\nPrimate (relabeled as yes/no as Primate/Non-Primate; note there are multiple ways to do this!) – use a 95% confidence interval for the bar\n\n\n#use summarySE function from Rmisc package\nsleep$Primate &lt;- revalue(sleep$Primate, c(Y = \"Yes\", N = \"No\"))\nsleep$Primate &lt;- relevel(sleep$Primate, \"No\")\nlibrary(Rmisc)\nsleep_by_primate &lt;- summarySE(sleep, measurevar = \"TotalSleep\", groupvars = \"Primate\", na.rm = T)\n#look at it\nsleep_by_primate\n\n  Primate  N TotalSleep       sd        se       ci\n1      No 51   10.44510 4.810335 0.6735817 1.352929\n2     Yes  7   11.17143 2.870955 1.0851189 2.655190\n\nlibrary(ggplot2)\nggplot(sleep_by_primate\n       , aes(x=Primate, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-ci, ymax=TotalSleep+ci), size=1.5) +\n  ylab(\"Total sleep \\n (hours per day\")+ \n  xlab(\"Primate?\")+ \n  ggtitle(\"Sleep across different taxa\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32)) \n\n\n\n\n\nPredation risk (as a factor!) – use 1 standard error for the bar. Note the difference!\n\n\nsleep$Predation &lt;- as.factor(sleep$Predation)\nsleep_by_predation &lt;- summarySE(sleep, measurevar = \"TotalSleep\", \n                                groupvars = \"Predation\", na.rm = T)\n#look at it\nsleep_by_predation\n\n  Predation  N TotalSleep       sd       se       ci\n1         1 14  12.050000 4.602299 1.230016 2.657288\n2         2 15  12.720000 3.931957 1.015227 2.177445\n3         3 10   9.120000 4.525680 1.431146 3.237476\n4         4  7  10.228571 2.437700 0.921364 2.254496\n5         5 12   7.383333 4.807727 1.387871 3.054684\n\nrequire(ggplot2)\nggplot(sleep_by_predation\n       , aes(x=Predation, y=TotalSleep)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=TotalSleep-se, ymax=TotalSleep+se), size=1.5) +\n  ylab(\"Total sleep \\n (hours per day)\") + \n  ggtitle(\"Sleep across different \\n predation levels\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))"
  },
  {
    "objectID": "content/solutions/2_Estimates_and_ggplot2_solutions.html#estimates-and-certainty-concepts",
    "href": "content/solutions/2_Estimates_and_ggplot2_solutions.html#estimates-and-certainty-concepts",
    "title": "Estimation and ggplot2",
    "section": "Estimates and Certainty Concepts",
    "text": "Estimates and Certainty Concepts\n\n5\n\nWhat does a 95% confidence interval mean?\n\nA 95% confidence interval means the true population parameter value will be in the created interval 95% of the time we create it.\n\n\n6\n\nTo make sure you understand the ideas of sampling, confidence intervals, and the central limit theorem, review the visualizations produced by UBC:\n\n\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/SamplingNormal.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CIMean.htm\nhttps://www.zoology.ubc.ca/~whitlock/Kingfisher/CLT.htm\n\nKey outcomes here are understanding that, regardless of the distribution of the data, the distribution of the means of the data (what we typically consider), will follow a normal distribution if the sample size is large enough.\n\n\n7\n\nFor this question you’ll need the central_limit_theorem.R script from the code_examples folder. Download it to your computer and open it. Alternatively, go ahead and make a copy of the CUNY-Biostats repository. You won’t have write access but can keep one up-to-date on your machine/cloud (pull occassionally!).\n\nOnce you get the script, open it in Rstudio (it will be in another tab!). Make sure you have the VGAM library installed (if you open the script n Rstudio, it will likely prompt you at the top). Then use the Source button (next to the Run command we’ve been using for lines or segments). Source runs the entire code at once (similar to knitting an Rmd file) without showing any console output, but graphs and objects are still produced!\nYou can also do this from the web (included here). When you knit the file, output will appear in your final file. However, its nice to know what Source does in general.\n\nlibrary(VGAM)\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nThis script follows the UBC tutorial to show you how well the CLT (central limit theorem) works (and how it functions). This will be useful in coming to understand when you can trust tests based on the normality of means. The script produces output (graphs) that allow you to examine 6 distributions that differ in shape (skewness and kurtosis) and how those traits interact with sample size to influence the normality of means.\nSource it (or look for the graphs produced in your knitted file) and and then review the plots and consider how sample size interacts with the shape of underlying distributions to influence how quickly sample means approach normality. The noted distributions are:\n\nNormal(Z) (0,1) {no Kurtosis / no skewness / no truncation}\nDouble exponential (0,2) {high Kurtosis / no skewness / no truncation}\nUniform(0,1) {moderate Kurtosis / no skewness / double truncation}\nExponential(1,1) {high asymmetric Kurtosis / high skewness / single truncation}\nChi-square(df=4) {low Kurtosis / moderate skewness / single truncation}\nBinomial distribution (p=.7) {discrete distribution]\n\nThis allows you to visualize what we noted in question 6 and begin to develop a sense for what “large sample size” and “odd distribution” really mean."
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html",
    "title": "4. Continuous tests for 1 population",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#overview",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#overview",
    "title": "4. Continuous tests for 1 population",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Tests for continuous data from one sample lecture. ## Examples\nFrom lecture! Consider if average height of males training at the Australian Institute of Sport is different than average of human population.\nThese are all one sample tests, but they differ in what we know. If we know the variance of our population, we use a z test (function in BSDA package).\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T)\nlibrary(BSDA)\n\nLoading required package: lattice\n\n\n\nAttaching package: 'BSDA'\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nz.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6, sigma.x=7)\n\n\n    One-sample z-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nz = 14.292, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 184.1474 186.8643\nsample estimates:\nmean of x \n 185.5059 \n\n\nIf we don’t, we use a t-test\n\nt.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nt = 12.658, df = 101, p-value &lt; 2.2e-16\nalternative hypothesis: true mean is not equal to 175.6\n95 percent confidence interval:\n 183.9535 187.0583\nsample estimates:\nmean of x \n 185.5059 \n\n\nThese both assume the means of the data are normal! If we want to relax that assumption, we can use the Wilcoxon test (also known as Mann-Whitney test, signed binary transform, or other terms!). This assumes the distribution of means is symmetric.\n\nwilcox.test(sport[sport$Sex == \"male\", \"Ht\"], mu = 175.6)\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\nV = 5052, p-value = 5.714e-16\nalternative hypothesis: true location is not equal to 175.6\n\n\nor the sign-test/media test.\n\nSIGN.test(sport[sport$Sex == \"male\", \"Ht\"], md = 175.6)\n\n\n    One-sample Sign-Test\n\ndata:  sport[sport$Sex == \"male\", \"Ht\"]\ns = 90, p-value = 8.882e-16\nalternative hypothesis: true median is not equal to 175.6\n95 percent confidence interval:\n 183.9000 187.4684\nsample estimates:\nmedian of x \n     185.55 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.9406  183.9 187.3000\nInterpolated CI       0.9500  183.9 187.4684\nUpper Achieved CI     0.9629  183.9 187.7000\n\n\nNote this is just transforming data to 1/0 and doing a binomial test!\n\nabove_175.6 &lt;- nrow(sport[sport$Sex == \"male\" & sport$Ht &gt; 175.6,])\nbinom.test(above_175.6, nrow(sport[sport$Sex == \"male\",]))\n\n\n    Exact binomial test\n\ndata:  above_175.6 and nrow(sport[sport$Sex == \"male\", ])\nnumber of successes = 90, number of trials = 102, p-value = 6.125e-16\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.8035103 0.9377091\nsample estimates:\nprobability of success \n             0.8823529 \n\n\nWe can also bootstrap the data.\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/bootstrapjsg.R\")\nbootstrapjsg(data1=sport[sport$Sex == \"male\", \"Ht\"], null=175.6)\n\n\nAttaching package: 'boot'\n\n\nThe following object is masked from 'package:lattice':\n\n    melanoma\n\n\nWarning: package 'simpleboot' was built under R version 4.2.3\n\n\nSimple Bootstrap Routines (1.1-7)\n\n\nWarning in boot.ci(a, conf): bootstrap variances needed for studentized\nintervals\n\n\n                                                                        \n                 \"0.95\" \"% Confidence Interval\"      \"183.983333333333\" \n                                                                        \n     \"187.046004781861\"               \"p-value\"                     \"0\""
  },
  {
    "objectID": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#lets-practice",
    "href": "content/solutions/4_Continuous_tests_for_1_population_solutions.html#lets-practice",
    "title": "4. Continuous tests for 1 population",
    "section": "Let’s practice!",
    "text": "Let’s practice!\n\nRecognizing and assessing normality\n\n1\nUsing the qqplot_example.R code, examine the following distributions and, for the continuous distributions (marked with a “*”), observe how a normal probability plot (qqplot) can be used to visually test for approximate normality.\n\n*Normal (u= 0; σ2= 1, 10, 100)\n*Student’s t (df = 1, 10, 30, & 100)\n*Chi-square (df= 1, 2, 5, 30, 50)\nBernoulli (P=0.1, 0.5, & 0.9)\nBinomial (P=0.05; N= 2, 5, 25, & 50); (P=0.25; N= 2, 5, 25, & 50); (P=0.50; N= 2, 5, 25, & 50); (P=0.75; N= 2, 5, 25, & 50); (P=0.95; N= 2, 5, 25, & 50)\nPoisson ( u= 2, 5, 10, 30, & 50)\n\nFor this question, its easiest to just source the main file and see what happens. When you source a script, it is run in R without showing any console output (but graphs and objects are still produced!). Try source(“https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R”)\n\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/qqplot_example.R\")\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nNotice the spread of DATA of every distribution tend towards normality as sample size increases\n\n\n2\nReview the central_limit_theorem.R code if you need to convince/remind yourself how common normality of means is for even non-normal data. You can source the code using the same approach noted in Question 1.\nHere we are focused on how the means look as sample size increases\n\n#make sure you have VGAM library installed\nsource(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/code_examples/central_limit_theorem.R\")\n\nPress [enter] to continue\n\n\nLoading required package: VGAM\n\n\nLoading required package: stats4\n\n\nLoading required package: splines\n\n\n\nAttaching package: 'VGAM'\n\n\nThe following objects are masked from 'package:boot':\n\n    logit, simplex\n\n\n\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\nPress [enter] to continue\n\n\n\n\n\n\n\n\nWorking with data (note some sample sizes may be too small for these to all be good ideas!)\nMake sure you are comfortable with null and alternative hypotheses for all examples. You should also feel comfortable graphing the data.\n\n3\nSeven observers were shown, for a brief period, a grill with 161 flies impaled and were asked to estimate the number. The results are given by Cochran (1954). Based on five estimates, they were 183.2, 149.0, 154.0, 167.2, 187.2, 158.0, and 143.0. Test the null hypothesis that the mean of the estimates is 161 flies.\n\nAssuming variance = 275\n\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0)\nlibrary(BSDA)\nz.test(x=flies, mu = 161, sigma.x=sqrt(275))\n\n\n    One-sample z-Test\n\ndata:  flies\nz = 0.33276, p-value = 0.7393\nalternative hypothesis: true mean is not equal to 161\n95 percent confidence interval:\n 150.8010 175.3704\nsample estimates:\nmean of x \n 163.0857 \n\n\nUsing a z-test, I found a test statistics of z~=0.33 .This corresponds to a p-value of 0.73. This p value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nEstimating the variance from the data\n\n\nt.test(x=flies,mu = 161)\n\n\n    One Sample t-test\n\ndata:  flies\nt = 0.32656, df = 6, p-value = 0.7551\nalternative hypothesis: true mean is not equal to 161\n95 percent confidence interval:\n 147.4576 178.7138\nsample estimates:\nmean of x \n 163.0857 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t6=0.32. This corresponds to a p-value of 0.76. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nUsing rank transform analysis\n\n\nwilcox.test(flies, mu=161)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  flies\nV = 15, p-value = 0.9375\nalternative hypothesis: true location is not equal to 161\n\n\nUsing a Wilcoxon signed rank test, which is appropriate when normality assumptions can’t be met and the distribution of the data appears to be symmetric, I found a test statistics of V = 15 .This corresponds to a p-value of 0.94. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean of the estimates is 161 flies.\n\nUsing binary transform analysis\n\n\nSIGN.test(flies, md=161)\n\n\n    One-sample Sign-Test\n\ndata:  flies\ns = 3, p-value = 1\nalternative hypothesis: true median is not equal to 161\n95 percent confidence interval:\n 144.8857 185.9429\nsample estimates:\nmedian of x \n        158 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level   L.E.pt   U.E.pt\nLower Achieved CI     0.8750 149.0000 183.2000\nInterpolated CI       0.9500 144.8857 185.9429\nUpper Achieved CI     0.9844 143.0000 187.2000\n\n\nUsing a sign test, which is appropriate when the data is continuous and other assumptions can’t be met, I found a test statistics of s = 3 .This corresponds to a p-value of 1. This p-value is &gt;.05, so I fail to reject the null hypothesis that the median (Note change here) of the estimates is 161 flies.\nNote there are several ways to load the data! You can make a list (since the list is short):\n\nflies &lt;- c(183.2, 149.0, 154.0, 167.2, 187.2, 158.0, 143.0 )\n\nor make a dataframe in a spreadsheet software (eg, Excel, Google Sheets) and then upload using a read.csv command. We did this in the introduction to R!\n\n\n4\nYields of 10 strawberry plants in a uniformity trial are given by Baker and Baker (1953) as 239, 176, 235, 217, 234, 216, 318, 190, 181, and 225 g. Test the hypothesis that µ = 205 * Assuming variance = 1500\n\nstrawberries &lt;- c(239, 176, 235, 217, 234, 216, 318, 190, 181, 225)\nz.test(x=strawberries,mu = 205, sigma.x=sqrt(1500))\n\n\n    One-sample z-Test\n\ndata:  strawberries\nz = 1.4779, p-value = 0.1394\nalternative hypothesis: true mean is not equal to 205\n95 percent confidence interval:\n 199.0954 247.1046\nsample estimates:\nmean of x \n    223.1 \n\n\nUsing a z-test, I found a test statistics of z=1.48. This corresponds to a p-value of 0.14. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nEstimating the variance from the data\n\n\nt.test(x=strawberries,mu = 205)\n\n\n    One Sample t-test\n\ndata:  strawberries\nt = 1.4164, df = 9, p-value = 0.1903\nalternative hypothesis: true mean is not equal to 205\n95 percent confidence interval:\n 194.1922 252.0078\nsample estimates:\nmean of x \n    223.1 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t9=1.42. This corresponds to a p-value of 0.19. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nUsing rank transform analysis\n\n\nwilcox.test(strawberries, mu=205)\n\nWarning in wilcox.test.default(strawberries, mu = 205): cannot compute exact\np-value with ties\n\n\n\n    Wilcoxon signed rank test with continuity correction\n\ndata:  strawberries\nV = 40.5, p-value = 0.2023\nalternative hypothesis: true location is not equal to 205\n\n\nUsing a Wilcoxon signed rank test, which is appropriate when normality assumptions can’t be met and the distribution of the data appears to be symmetric, I found a test statistics of V=40.5. This corresponds to a p-value of 0.20. This p-value is &gt;.05, so I fail to reject the null hypothesis that the population mean is equal to 205.\n\nUsing binary transform analysis\n\n\nSIGN.test(strawberries, md=205)\n\n\n    One-sample Sign-Test\n\ndata:  strawberries\ns = 7, p-value = 0.3437\nalternative hypothesis: true median is not equal to 205\n95 percent confidence interval:\n 183.9200 237.7022\nsample estimates:\nmedian of x \n        221 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level L.E.pt   U.E.pt\nLower Achieved CI     0.8906 190.00 235.0000\nInterpolated CI       0.9500 183.92 237.7022\nUpper Achieved CI     0.9785 181.00 239.0000\n\n\nUsing a sign test, which is appropriate when the data is continuous and other assumptions can’t be met, I found a test statistics of s= 7. This corresponds to a p-value of 0.34. This p-value is &gt;.05,so I fail to reject the null hypothesis that the population median (Note change here) is equal to 205.\n\n\n5\nEvolutionary geneticists predicts the family sex ratio will be 80% female in broods of eagles that successfully fledge &gt;3 young. Nests that fledge 3 or more chicks are very rare but a sample of 30 chicks are obtained from such nests and they yield 25 females and 5 males. Test the hypotheses that that: * a) the sex ratio is 50% females\n\n#a\nbinom.test(25,30, p=.5)\n\n\n    Exact binomial test\n\ndata:  25 and 30\nnumber of successes = 25, number of trials = 30, p-value = 0.0003249\nalternative hypothesis: true probability of success is not equal to 0.5\n95 percent confidence interval:\n 0.6527883 0.9435783\nsample estimates:\nprobability of success \n             0.8333333 \n\n\nA binomial test was used as we are comparing an observed proportion against a set value. Given a p-value of &lt;.001, I reject the null hypothesis that the proportion of sons is equal to .5.\n\n\nthe sex ratio is 80% females.\n\n\n\nbinom.test(25,30, .8)\n\n\n    Exact binomial test\n\ndata:  25 and 30\nnumber of successes = 25, number of trials = 30, p-value = 0.8205\nalternative hypothesis: true probability of success is not equal to 0.8\n95 percent confidence interval:\n 0.6527883 0.9435783\nsample estimates:\nprobability of success \n             0.8333333 \n\n\nA binomial test was used as we are comparing an observed proportion against a set value. Given a p-value of &lt;.001, I fail to reject the null hypothesis that the proportion of sons is equal to .8.\n\n\n6\nStudies of flying snakes have led researchers to posit the mean undulation rate is 1.4 Hz. You wish to test this hypothesis using the small sample of undulation rates shown below. Create a small dataset of the paradise tree snake undulation rates and choose and justify a test you can use to assess the data.\nUndulation rates (in Hz): 0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6\n\nsnakes &lt;- c(0.9, 1.4, 1.2, 1.2, 1.3, 2.0, 1.4, 1.6)\nt.test(snakes, mu=1.4)\n\n\n    One Sample t-test\n\ndata:  snakes\nt = -0.21822, df = 7, p-value = 0.8335\nalternative hypothesis: true mean is not equal to 1.4\n95 percent confidence interval:\n 1.104098 1.645902\nsample estimates:\nmean of x \n    1.375 \n\n\nUsing a t-test, which is appropriate when the variance must be estimated from the sample and the means of the data may be assumed to follow a normal distribution, I found a test statistics of t7=-.22. This corresponds to a p-value of 0.83. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean undulation rate is 1.4 Hz.\n\n\n7\nUsing data from Australian athletes (http://www.statsci.org/data/oz/ais.html for details), determine if the average male training at the Australian Institute of Sport differs in weight from the average Australian male (85.9 kg) using bootstrapping techniques. Data at\n\nsport &lt;- read.table(\"http://www.statsci.org/data/oz/ais.txt\", header = T, \n                    stringsAsFactors = T)\n\n\nlibrary(MKinfer)\n\nWarning: package 'MKinfer' was built under R version 4.2.3\n\nboot.t.test(sport[sport$Sex == \"male\", \"Wt\"], mu= 85.9)\n\n\n    Bootstrap One Sample t-test\n\ndata:  sport[sport$Sex == \"male\", \"Wt\"]\nbootstrap p-value = 0.01 \nbootstrap mean of x (SE) = 82.51201 (1.218765) \n95 percent bootstrap percentile confidence interval:\n 80.17301 84.92525\n\nResults without bootstrap:\nt = -2.7487, df = 101, p-value = 0.007089\nalternative hypothesis: true mean is not equal to 85.9\n95 percent confidence interval:\n 80.08671 84.96035\nsample estimates:\nmean of x \n 82.52353 \n\n\nUsing a bootstrap test wtih 10,000 samples, we found a p-value of .007; we thus reject the null hypothesis that males training at the AIS have the same weight as the average Australian male. Data indicated they weigh less."
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html",
    "href": "content/solutions/6_Compare_means_solutions.html",
    "title": "Compare means among groups",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#overview",
    "href": "content/solutions/6_Compare_means_solutions.html#overview",
    "title": "Compare means among groups",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Compare means among groups lecture."
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#examples",
    "href": "content/solutions/6_Compare_means_solutions.html#examples",
    "title": "Compare means among groups",
    "section": "Examples",
    "text": "Examples\nWe will run ANOVA’s using the lm function to connect them to other test. First, build the model\n\niris_anova &lt;- lm(Sepal.Length~Species, iris)\n\nThen use the object it created to test assumptions\n\npar(mfrow = c(2,2))\nplot(iris_anova)\n\n\n\n\nIf assumptions are met, check the p-value using the summary or Anova function.\n\nsummary(iris_anova)\n\n\nCall:\nlm(formula = Sepal.Length ~ Species, data = iris)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.6880 -0.3285 -0.0060  0.3120  1.3120 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         5.0060     0.0728  68.762  &lt; 2e-16 ***\nSpeciesversicolor   0.9300     0.1030   9.033 8.77e-16 ***\nSpeciesvirginica    1.5820     0.1030  15.366  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5148 on 147 degrees of freedom\nMultiple R-squared:  0.6187,    Adjusted R-squared:  0.6135 \nF-statistic: 119.3 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_anova, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 1253.00   1 4728.16 &lt; 2.2e-16 ***\nSpecies       63.21   2  119.26 &lt; 2.2e-16 ***\nResiduals     38.96 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nIf the overall test is significant, carry out post hoc tests (Tukey shown here for all pairs, as most common)\n\nlibrary(multcomp)\n\nLoading required package: mvtnorm\n\n\nLoading required package: survival\n\n\nLoading required package: TH.data\n\n\nLoading required package: MASS\n\n\n\nAttaching package: 'TH.data'\n\n\nThe following object is masked from 'package:MASS':\n\n    geyser\n\ncompare_cont_tukey &lt;- glht(iris_anova, linfct = mcp(Species = \"Tukey\"))\nsummary(compare_cont_tukey)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Sepal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0       0.930      0.103   9.033   &lt;1e-08 ***\nvirginica - setosa == 0        1.582      0.103  15.366   &lt;1e-08 ***\nvirginica - versicolor == 0    0.652      0.103   6.333   &lt;1e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nIf assumptions are not met, we can use the Kruskal Wallis non-parametric test and associated post hoc tests.\n\nkruskal.test(Sepal.Length ~ Species, data = iris)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  Sepal.Length by Species\nKruskal-Wallis chi-squared = 96.937, df = 2, p-value &lt; 2.2e-16\n\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n\nor a bootstrap alternative\n\nlibrary(WRS2)\nt1waybt(Sepal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Sepal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 111.9502 \np-value: 0 \nVariance explained: 0.716 \nEffect size: 0.846 \n\nbootstrap_post_hoc &lt;- mcppb20(Sepal.Length~Species, iris)\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\nFor 2 groups, the boot.t.test function in the MKinfer package is also an option."
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#just-for-practice",
    "href": "content/solutions/6_Compare_means_solutions.html#just-for-practice",
    "title": "Compare means among groups",
    "section": "Just for practice",
    "text": "Just for practice\n\n1\nUse the iris dataset in R to determine if petal length differs among species. Do this problems using ANOVA, Kruskal-Wallis, and bootstrapping methods. Make sure you can plot the data and carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n#plot\nlibrary(Rmisc)\n\nLoading required package: lattice\n\n\nLoading required package: plyr\n\nfunction_output &lt;- summarySE(iris, measurevar=\"Petal.Length\", groupvars =\n                               c(\"Species\"))\nlibrary(ggplot2)\nggplot(function_output, aes(x=Species, y=Petal.Length)) +\n  geom_col(aes(fill=Species), size = 3) +\n  geom_errorbar(aes(ymin=Petal.Length-ci, ymax=Petal.Length+ci), size=1.5) +\n  ylab(\"Petal Length (cm)\")+ggtitle(\"Petal Length of \\n various iris species\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\npetal &lt;- lm(Petal.Length ~ Species, iris)\nplot(petal)\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(car)\nAnova(petal, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Petal.Length\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 106.87   1   577.1 &lt; 2.2e-16 ***\nSpecies     437.10   2  1180.2 &lt; 2.2e-16 ***\nResiduals    27.22 147                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n#compare to\nsummary(petal)\n\n\nCall:\nlm(formula = Petal.Length ~ Species, data = iris)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-1.260 -0.258  0.038  0.240  1.348 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        1.46200    0.06086   24.02   &lt;2e-16 ***\nSpeciesversicolor  2.79800    0.08607   32.51   &lt;2e-16 ***\nSpeciesvirginica   4.09000    0.08607   47.52   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4303 on 147 degrees of freedom\nMultiple R-squared:  0.9414,    Adjusted R-squared:  0.9406 \nF-statistic:  1180 on 2 and 147 DF,  p-value: &lt; 2.2e-16\n\nlibrary(multcomp)\ncomp_cholest &lt;- glht(petal, linfct = mcp(Species = \"Tukey\"))\nsummary(comp_cholest)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Petal.Length ~ Species, data = iris)\n\nLinear Hypotheses:\n                            Estimate Std. Error t value Pr(&gt;|t|)    \nversicolor - setosa == 0     2.79800    0.08607   32.51   &lt;2e-16 ***\nvirginica - setosa == 0      4.09000    0.08607   47.52   &lt;2e-16 ***\nvirginica - versicolor == 0  1.29200    0.08607   15.01   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n#kw approach\npetal &lt;- kruskal.test(Petal.Length ~ Species, iris)\npairwise.wilcox.test(iris$Sepal.Length, \n                          iris$Species, \n                          p.adjust.method=\"holm\")\n\n\n    Pairwise comparisons using Wilcoxon rank sum test with continuity correction \n\ndata:  iris$Sepal.Length and iris$Species \n\n           setosa  versicolor\nversicolor 1.7e-13 -         \nvirginica  &lt; 2e-16 5.9e-07   \n\nP value adjustment method: holm \n\n#bootstrap\nlibrary(WRS2)\nt1waybt(Petal.Length~Species, iris)\n\nCall:\nt1waybt(formula = Petal.Length ~ Species, data = iris)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 1510.684 \np-value: 0 \nVariance explained: 0.71 \nEffect size: 0.843 \n\nbootstrap_post_hoc &lt;- mcppb20(Petal.Length~Species, iris)\n#use p.adjust to correct for FWER\np.adjust(as.numeric(bootstrap_post_hoc$comp[,6]), \"holm\")\n\n[1] 0 0 0\n\n\n*Answer: We used an ANOVA (a special case of linear models) to investigate how a numerical response variable differed among 3 groups. This was appropriate as evidenced by the residual plots (there is no pattern in the residuals and they are normally distributed), but other methods are demonstrated as well.\nUsing an ANOVA, we found F2,147= 1180.2, which led to a p-value of &lt;.001. Given this, I reject the null hypothesis there is no difference among mean measurements for each species.\nPost-hoc testing indicated all species significantly differed from all others (all p &lt;.05) using a Tukey approach to control for family-wise error rate. Kruskal-Wallis and bootstrapping approaches led to similar conclusions.*\n\n\n2\nData on plant heights (in cm) for plants grown with a new and old formulation of fertilizer can be found at\nhttps://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv.\nAnalyze this data using the t.test function and the lm function to convince yourself that t-tests are special cases of ANOVAs, which are special cases of linear models!\n\nfertilizer &lt;- read.csv(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vSUVowOKlmTic4ekL7LSbwDcqrsDSXv5K_c4Qyfcvz1lLE1_iINmGzy0zMGxY7z5DImlUErK4S2wY7Y/pub?gid=0&single=true&output=csv\",\n                       stringsAsFactors = T)\n#note use of var.equal!  assumption of ANOVAs\nt.test(height ~ fertilizer, fertilizer, var.equal = T)\n\n\n    Two Sample t-test\n\ndata:  height by fertilizer\nt = 2.9884, df = 16, p-value = 0.008686\nalternative hypothesis: true difference in means between group new and group old is not equal to 0\n95 percent confidence interval:\n 1.34853 7.93147\nsample estimates:\nmean in group new mean in group old \n            56.55             51.91 \n\nfert_lm &lt;- lm(height ~ fertilizer, fertilizer)\nplot(fert_lm)\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(fert_lm)\n\n\nCall:\nlm(formula = height ~ fertilizer, data = fertilizer)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -4.25  -2.61  -0.21   2.38   6.39 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     56.550      1.157  48.865  &lt; 2e-16 ***\nfertilizerold   -4.640      1.553  -2.988  0.00869 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.273 on 16 degrees of freedom\nMultiple R-squared:  0.3582,    Adjusted R-squared:  0.3181 \nF-statistic: 8.931 on 1 and 16 DF,  p-value: 0.008686\n\nrequire(car)\nAnova(fert_lm, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: height\n             Sum Sq Df   F value    Pr(&gt;F)    \n(Intercept) 25583.2  1 2387.7612 &lt; 2.2e-16 ***\nfertilizer     95.7  1    8.9308  0.008686 ** \nResiduals     171.4 16                        \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAnswer: t-tests and ANOVA (lm) approaches yield the same results. Note for the tests to match exactly we have to assume equal variances among groups for the t-tests. In both we reject the null hypothesis of no difference among mean height of plants based on fertilizer. Notice the t statistic (2.9884) is the square root of the F statistic (8.931). The t distribution corresponds to the F with only 1 df in the numerator (so its not listed!)."
  },
  {
    "objectID": "content/solutions/6_Compare_means_solutions.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "href": "content/solutions/6_Compare_means_solutions.html#for-the-following-questions-pick-the-appropriate-method-for-analyzing-the-question.-use-a-plot-of-the-data-andor-model-analysis-to-justify-your-decision.-make-sure-you-can-carry-out-multiple-comparison-methods-as-needed.-also-be-sure-to-understand-the-use-of-coefficients-and-adjusted-r2-values-and-where-to-find-them.",
    "title": "Compare means among groups",
    "section": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.",
    "text": "For the following questions, pick the appropriate method for analyzing the question. Use a plot of the data and/or model analysis to justify your decision. Make sure you can carry out multiple comparison methods as needed. Also be sure to understand the use of coefficients and adjusted R2 values and where to find them.\n\n3\nData on sugar cane yield for multiple fields is available using\nread.table(“https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv”, header = T, stringsAsFactors = T)\nMore info on the data can be found at http://www.statsci.org/data/oz/cane.html. Is there evidence that location (DistrictPosition column) impacts yield (Tonn.Hect column)? If so, which areas are driving this distance?\n\ncane &lt;- read.table(\"https://docs.google.com/spreadsheets/d/e/2PACX-1vRjstKreIM6UknyKFQCtw2_Q6itY9iOAVWO1hUNZkBFL8mwVssvTevqgzV22YDKCUeJq0HBDrsBrf5O/pub?gid=971470377&single=true&output=tsv\", header = T, stringsAsFactors = T)\nsummary(cane)\n\n           District                     DistrictGroup  DistrictPosition\n WrightsCreek  : 389   BahanaSouth             : 498   C: 498          \n Highleigh     : 360   Cairns/Mulgrave(dry)    :1517   E: 482          \n PineCreek     : 317   Cairns/Mulgrave(Med-wet): 842   N: 452          \n LittleMulgrave: 308   MulgravetoBahana        : 466   S: 553          \n Aloomba       : 284   NorthCairns             : 452   W:1790          \n Hambledon     : 267                                                   \n (Other)       :1850                                                   \n     SoilID           SoilName         Area           Variety        Ratoon   \n Min.   :442.0   Liverpool: 737   Min.   : 0.020   138    :629   1R     :767  \n 1st Qu.:712.0   Mission  : 399   1st Qu.: 0.880   120    :598   2R     :760  \n Median :801.0   Innisfail: 330   Median : 1.940   152    :513   3R     :692  \n Mean   :757.5   Virgil   : 272   Mean   : 2.578   124    :466   4R     :493  \n 3rd Qu.:816.0   Thorpe   : 237   3rd Qu.: 3.620   113    :358   PL     :360  \n Max.   :838.0   Edmonton : 220   Max.   :38.270   117    :319   RP     :304  \n                 (Other)  :1580                    (Other):892   (Other):399  \n      Age         HarvestMonth  HarvestDuration     Tonn.Hect      \n Min.   :0.000   Min.   : 6.0   Min.   :  0.000   Min.   :   1.45  \n 1st Qu.:1.000   1st Qu.: 7.0   1st Qu.:  0.000   1st Qu.:  75.54  \n Median :2.000   Median : 9.0   Median :  1.000   Median : 173.46  \n Mean   :2.151   Mean   : 8.6   Mean   :  9.175   Mean   : 240.11  \n 3rd Qu.:3.000   3rd Qu.:10.0   3rd Qu.:  3.000   3rd Qu.: 336.40  \n Max.   :8.000   Max.   :11.0   Max.   :155.000   Max.   :1954.01  \n                                                                   \n     Fibre           Sugar           Jul.96          Aug.96      \n Min.   :14.20   Min.   : 6.08   Min.   :  0.0   Min.   : 2.200  \n 1st Qu.:15.38   1st Qu.:10.93   1st Qu.: 42.2   1st Qu.: 4.500  \n Median :15.80   Median :11.84   Median : 46.0   Median : 7.100  \n Mean   :15.87   Mean   :11.82   Mean   : 50.9   Mean   : 9.274  \n 3rd Qu.:16.25   3rd Qu.:12.73   3rd Qu.: 61.0   3rd Qu.: 9.900  \n Max.   :19.10   Max.   :17.36   Max.   :141.5   Max.   :36.000  \n                                                                 \n     Sep.96           Oct.96          Nov.96           Dec.96     \n Min.   : 0.000   Min.   :137.5   Min.   :  6.00   Min.   :128.5  \n 1st Qu.: 0.000   1st Qu.:181.8   1st Qu.: 17.60   1st Qu.:161.9  \n Median : 5.000   Median :224.8   Median : 31.00   Median :239.5  \n Mean   : 5.932   Mean   :219.8   Mean   : 40.39   Mean   :223.6  \n 3rd Qu.:11.200   3rd Qu.:240.3   3rd Qu.: 39.50   3rd Qu.:241.4  \n Max.   :14.000   Max.   :308.0   Max.   :100.60   Max.   :353.5  \n                                                                  \n     Jan.97          Feb.97          Mar.97          Apr.97     \n Min.   :287.5   Min.   :275.8   Min.   :326.0   Min.   :  0.0  \n 1st Qu.:321.8   1st Qu.:284.0   1st Qu.:326.0   1st Qu.: 49.3  \n Median :443.8   Median :386.6   Median :426.0   Median : 87.8  \n Mean   :455.2   Mean   :419.6   Mean   :415.1   Mean   :105.0  \n 3rd Qu.:508.8   3rd Qu.:495.6   3rd Qu.:480.5   3rd Qu.:176.0  \n Max.   :746.5   Max.   :677.5   Max.   :494.3   Max.   :217.5  \n                                                                \n     May.97           Jun.97           Jul.97           Aug.97      \n Min.   : 30.00   Min.   : 34.20   Min.   :  8.60   Min.   : 18.80  \n 1st Qu.: 44.60   1st Qu.: 40.20   1st Qu.: 16.40   1st Qu.: 39.20  \n Median : 63.50   Median : 41.00   Median : 24.00   Median : 68.00  \n Mean   : 89.99   Mean   : 82.62   Mean   : 31.65   Mean   : 70.47  \n 3rd Qu.: 72.60   3rd Qu.:113.80   3rd Qu.: 28.00   3rd Qu.:112.50  \n Max.   :220.00   Max.   :202.00   Max.   :109.00   Max.   :117.50  \n                                                                    \n     Sep.97           Oct.97           Nov.97          Dec.97     \n Min.   :  4.00   Min.   :  2.00   Min.   : 13.5   Min.   : 75.0  \n 1st Qu.: 42.80   1st Qu.: 22.20   1st Qu.: 62.0   1st Qu.:223.0  \n Median : 73.00   Median : 38.10   Median :123.7   Median :278.3  \n Mean   : 70.46   Mean   : 55.53   Mean   :114.3   Mean   :264.4  \n 3rd Qu.:106.00   3rd Qu.: 53.10   3rd Qu.:167.4   3rd Qu.:315.2  \n Max.   :109.20   Max.   :216.50   Max.   :198.0   Max.   :336.6  \n                                                                  \n\ncane_summary &lt;- summarySE(cane, measurevar=\"Tonn.Hect\", groupvars =\n                               c(\"DistrictPosition\"))\n\nggplot(cane_summary, aes(x=DistrictPosition, y=Tonn.Hect)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=Tonn.Hect-ci, ymax=Tonn.Hect+ci), size=1.5) +\n  ylab(\"Production (tonnes per hectare)\") +\n  xlab(\"District Position\") +\n  ggtitle(\"Production differs \\n among locations\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\nimpact_district &lt;- lm(Tonn.Hect ~ DistrictPosition, cane)\nsummary(impact_district)\n\n\nCall:\nlm(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-274.41 -159.66  -66.07   90.26 1754.55 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)        242.418      9.993  24.259  &lt; 2e-16 ***\nDistrictPositionE   39.360     14.249   2.762  0.00577 ** \nDistrictPositionN   20.252     14.487   1.398  0.16222    \nDistrictPositionS  -42.955     13.777  -3.118  0.00183 ** \nDistrictPositionW   -7.317     11.298  -0.648  0.51727    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 223 on 3770 degrees of freedom\nMultiple R-squared:  0.0107,    Adjusted R-squared:  0.009652 \nF-statistic:  10.2 on 4 and 3770 DF,  p-value: 3.293e-08\n\nplot(impact_district)#not really normal...lets bootstrap\n\n\n\n\n\n\n\n\n\n\n\n\nrequire(WRS2)\nt1waybt(Tonn.Hect ~ DistrictPosition, cane)\n\nCall:\nt1waybt(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nEffective number of bootstrap samples was 599.\n\nTest statistic: 16.5244 \np-value: 0 \nVariance explained: 0.031 \nEffect size: 0.176 \n\nmcppb20(Tonn.Hect ~ DistrictPosition, cane)\n\nCall:\nmcppb20(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\n           psihat  ci.lower  ci.upper p-value\nS vs. N -56.10126 -96.10319 -18.63161 0.00000\nS vs. E -12.51609 -53.42371  21.81795 0.35058\nS vs. W  39.25821   4.77395  72.90082 0.00000\nS vs. C  -0.97532 -29.37455  31.55710 0.89482\nN vs. E  43.58517   5.06669  86.26308 0.00334\nN vs. W  95.35948  61.60008 132.67551 0.00000\nN vs. C  55.12595  24.67933  84.35464 0.00000\nE vs. W  51.77430  23.32072  88.74869 0.00000\nE vs. C  11.54077 -16.61374  47.30163 0.32387\nW vs. C -40.23353 -62.38270 -16.78002 0.00000\n\np &lt;- mcppb20(Tonn.Hect ~ DistrictPosition, cane)\np.adjust(as.numeric(p$comp[,6]), \"holm\")\n\n [1] 0.00000000 0.90150250 0.00000000 0.90150250 0.01335559 0.00000000\n [7] 0.00000000 0.00000000 0.90150250 0.00000000\n\n#compare to lm apporach\nrequire(car)\nAnova(impact_district, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Tonn.Hect\n                    Sum Sq   Df F value    Pr(&gt;F)    \n(Intercept)       29265733    1 588.476 &lt; 2.2e-16 ***\nDistrictPosition   2028140    4  10.195 3.293e-08 ***\nResiduals        187487281 3770                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nrequire(multcomp)\ncomp_district &lt;- glht(impact_district, linfct = mcp(DistrictPosition = \"Tukey\"))\nsummary(comp_district)\n\n\n     Simultaneous Tests for General Linear Hypotheses\n\nMultiple Comparisons of Means: Tukey Contrasts\n\n\nFit: lm(formula = Tonn.Hect ~ DistrictPosition, data = cane)\n\nLinear Hypotheses:\n           Estimate Std. Error t value Pr(&gt;|t|)    \nE - C == 0   39.360     14.249   2.762  0.04402 *  \nN - C == 0   20.252     14.487   1.398  0.62081    \nS - C == 0  -42.955     13.777  -3.118  0.01515 *  \nW - C == 0   -7.317     11.298  -0.648  0.96582    \nN - E == 0  -19.108     14.601  -1.309  0.67821    \nS - E == 0  -82.315     13.896  -5.924  &lt; 0.001 ***\nW - E == 0  -46.677     11.444  -4.079  &lt; 0.001 ***\nS - N == 0  -63.207     14.141  -4.470  &lt; 0.001 ***\nW - N == 0  -27.569     11.739  -2.348  0.12598    \nW - S == 0   35.638     10.850   3.285  0.00883 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n(Adjusted p values reported -- single-step method)\n\n\nAnswer: For this analysis I used a bootstrap approach as the residual plots suggested a non-normal distribution. Analysis revealed a test statistics of 16.52 and p-value of 0, so I reject the null hypothesis of no difference among Districts. since I rejected the null hypothesis, I have to use post-hoc tsts to determine which groups are different than the others.\nPost-hoc tests reveal all district areas differ from each other except for south and east, south and central, and east and central (using sequential FDR to control for family-wise error rate.)\nNote that a linear model does lead to slightly different findings regarding which districts differ from which others.\n\n\n4\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on gender? If so, which gender has the higher FEV score? How much variance does gender explain?\n\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T,\n                  stringsAsFactors = T)\nfev_summary &lt;- summarySE(fev, measurevar=\"FEV\", groupvars =\n                               c(\"Sex\"))\n\nggplot(fev_summary, aes(x=Sex, y=FEV)) +\n  geom_col(size = 3) +\n  geom_errorbar(aes(ymin=FEV-ci, ymax=FEV+ci), size=1.5) +\n  ylab(\"FEV (liters)\") +\n  xlab(\"Sex\") +\n  ggtitle(\"FEV differs \\n among males and females\") +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n\n\nfev_gender &lt;- lm(FEV ~ Sex, fev)\nplot(fev_gender) #anova is fine\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_gender, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n             Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 1910.62   1 2652.756 &lt; 2.2e-16 ***\nSex           21.32   1   29.607 7.496e-08 ***\nResiduals    469.60 652                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_gender)\n\n\nCall:\nlm(formula = FEV ~ Sex, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.01645 -0.69420 -0.06367  0.58233  2.98055 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  2.45117    0.04759  51.505  &lt; 2e-16 ***\nSexMale      0.36128    0.06640   5.441  7.5e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8487 on 652 degrees of freedom\nMultiple R-squared:  0.04344,   Adjusted R-squared:  0.04197 \nF-statistic: 29.61 on 1 and 652 DF,  p-value: 7.496e-08\n\n\nI used an ANOVA (or linear model, or t-test, here, all the same since 2 groups!) to consider the impact of sex on FEV. This was appropriate as evidenced by the residual plots (there is no pattern in the residuals and they are normally distributed). Results indicate there is a difference among sexes (F1,652 = 29.607, p&lt;.001). There is no need for post-hoc tests here since there are only 2 groups being considered.\nCoefficients related to the groups (note female is replaced by intercept here, and the SexMale coefficient is relative to that) indicates that males have a higher FEV on average. Graphs also show this relationship.\n\n\n5\nThe following data are human blood clotting times (in minutes) of individuals given one of two different drugs.\n\n\n\nDrug B\nDrug G\n\n\n\n\n8.8\n9.9\n\n\n8.4\n9.0\n\n\n7.9\n11.1\n\n\n8.7\n9.6\n\n\n9.1\n8.7\n\n\n9.6\n10.4\n\n\n\n9.5\n\n\n\nTest the hypothesis that the mean clotting times are equal for the two groups\n\nEstimating the variance from the data\n\n\ndrug_b &lt;- c( 8.8, 8.4, 7.9, 8.7, 9.1, 9.6)\ndrug_g &lt;- c(9.9, 9.0, 11.1, 9.6, 8.7, 10.4, 9.5)\nt.test(drug_b, drug_g)\n\n\n    Welch Two Sample t-test\n\ndata:  drug_b and drug_g\nt = -2.5454, df = 10.701, p-value = 0.02774\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.8543048 -0.1314095\nsample estimates:\nmean of x mean of y \n 8.750000  9.742857 \n\n\nUsing a un-paired t-test, since the experimental units were not matched and I assumed the means of each group would follow a normal distribution of unknown variance, I found a test statistics of t10.701=-2.544. This corresponds to a p-value of 0.02. This p-value is &lt;.05, so I reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing rank transform analysis\n\n\nwilcox.test(drug_b, drug_g)\n\nWarning in wilcox.test.default(drug_b, drug_g): cannot compute exact p-value\nwith ties\n\n\n\n    Wilcoxon rank sum test with continuity correction\n\ndata:  drug_b and drug_g\nW = 7, p-value = 0.05313\nalternative hypothesis: true location shift is not equal to 0\n\n\nUsing a un-paired rank-based test, which is appropriate when normality assumptions can’t be met and I assumed the means of each group would follow a similar distribution, I found a test statistics of W=7. This corresponds to a p-value of 0.05. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing a permutation test\n\n\nrequire(coin) #requires data_frame\n\nLoading required package: coin\n\nclotting &lt;- data.frame(drug = c(rep(\"drug_b\", length(drug_b)), rep(\"drug_g\", \n                                                                   length(drug_g))),\n                       clotting = c(drug_b, drug_g))\nclotting$drug &lt;- factor(clotting$drug)\nindependence_test(clotting ~ drug, clotting)\n\n\n    Asymptotic General Independence Test\n\ndata:  clotting by drug (drug_b, drug_g)\nZ = -2.0726, p-value = 0.03821\nalternative hypothesis: two.sided\n\n\nUsing a permutation test, which is not fully appropriate here due to small sample sizes (and that also assumes similar distributions for each group), I found a test statistics of Z=-2.0726.. This corresponds to a p-value of 0.038. This p-value is &gt;.05, so I fail to reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\nUsing a bootstrap test\n\n\nlibrary(MKinfer)\n\nWarning: package 'MKinfer' was built under R version 4.2.3\n\nboot.t.test(drug_b, drug_g)\n\n\n    Bootstrap Welch Two Sample t-test\n\ndata:  drug_b and drug_g\nbootstrap p-value = 0.0206 \nbootstrap difference of means (SE) = -0.9972483 (0.3528393) \n95 percent bootstrap percentile confidence interval:\n -1.7285714 -0.2928571\n\nResults without bootstrap:\nt = -2.5454, df = 10.701, p-value = 0.02774\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -1.8543048 -0.1314095\nsample estimates:\nmean of x mean of y \n 8.750000  9.742857 \n\n\nUsing a bootstrap test with 10000 samples, which is not fully appropriate here due to small sample sizes, I found a p value of 0.0047. This p-value is &lt;.05, so I reject the null hypothesis that the mean clotting times are the same for the two drugs.\n\n\n6\n(Example from Handbook on Biological Statistics) Odd (stunted, short, new) feathers were compared in color to typical feathers in Northern Flickers (Colaptes auratus) (Wiebe and Bortolotti 2002) . Data is at\nhttps://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\nTest the hypothesis that odd and typical feathers did not differ using\n\na Student’s t test and/or lm\na rank test\nbootstrapping\n\nNote we will return to this question next week!\n\na Student’s t test\n\n\nfeather &lt;-  read.csv(\"https://raw.githubusercontent.com/jsgosnell/CUNY-BioStats/master/datasets/wiebe_2002_example.csv\", stringsAsFactors = T)\nt.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Paired t-test\n\ndata:  Color_index by Feather\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean difference \n      -0.137125 \n\n\n*I used a paired t-test because feathers were measured on the same bird.\nI also assumed the difference in means was normally distributed given the trait and sample size. The test resulted in a statistic of t15 = -4.06. This corresponds to a p-value of .001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers. Note this equivalent too:\n\nlibrary(car)\nAnova(lm(Color_index ~ Feather+Bird, data=feather))\n\nAnova Table (Type II tests)\n\nResponse: Color_index\n           Sum Sq Df F value   Pr(&gt;F)   \nFeather   0.15043  1 16.5214 0.001017 **\nBird      0.21950 15  1.6072 0.184180   \nResiduals 0.13657 15                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\na rank test\n\n\nwilcox.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Wilcoxon signed rank exact test\n\ndata:  Color_index by Feather\nV = 10, p-value = 0.001312\nalternative hypothesis: true location shift is not equal to 0\n\n\nI used a paired rank-based test because feathers were measured on the same bird. I did not assume the difference in means was normally distributed but did assume it followed a symmetric distribution. The test resulted in a statistic of V = 10. This corresponds to a p-value of .001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers.\n\na binary test\n\n\nlibrary(BSDA)\n\n\nAttaching package: 'BSDA'\n\n\nThe following objects are masked from 'package:carData':\n\n    Vocab, Wool\n\n\nThe following object is masked from 'package:datasets':\n\n    Orange\n\nSIGN.test(feather[feather$Feather == \"Odd\", \"Color_index\"], \n          feather[feather$Feather == \"Typical\", \"Color_index\"])\n\n\n    Dependent-samples Sign-Test\n\ndata:  feather[feather$Feather == \"Odd\", \"Color_index\"] and feather[feather$Feather == \"Typical\", \"Color_index\"]\nS = 3, p-value = 0.02127\nalternative hypothesis: true median difference is not equal to 0\n95 percent confidence interval:\n -0.24048275 -0.02331055\nsample estimates:\nmedian of x-y \n       -0.114 \n\nAchieved and Interpolated Confidence Intervals: \n\n                  Conf.Level  L.E.pt  U.E.pt\nLower Achieved CI     0.9232 -0.2400 -0.0320\nInterpolated CI       0.9500 -0.2405 -0.0233\nUpper Achieved CI     0.9787 -0.2410 -0.0140\n\n\nI used a sign test (always paired!) because feathers were measured on the same bird. I did not assume the difference in means was normally distributed or that the differences followed a symmetric distribution. The test resulted in a statistic of s = 3. This corresponds to a p-value of .02. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers.\n\nbootstrapping\n\n\nlibrary(MKinfer)\nboot.t.test(Color_index ~ Feather, data=feather, paired=TRUE)\n\n\n    Bootstrap Paired t-test\n\ndata:  Color_index by Feather\nbootstrap p-value = 4e-04 \nbootstrap mean of the differences (SE) = -0.1375141 (0.03231539) \n95 percent bootstrap percentile confidence interval:\n -0.203750 -0.074625\n\nResults without bootstrap:\nt = -4.0647, df = 15, p-value = 0.001017\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.20903152 -0.06521848\nsample estimates:\nmean of the differences \n              -0.137125 \n\n\nSince feathers were measured on the same bird. I used a bootstrap (10,000 samples) focused on the difference in color. This resulted in a p-value of &lt;.001. Since the p-value is &lt;.05, I reject the null hypothesis that feather color is the same between odd and typical feathers."
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html",
    "title": "Relationships among numerical variables",
    "section": "",
    "text": "Remember you should"
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#overview",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#overview",
    "title": "Relationships among numerical variables",
    "section": "Overview",
    "text": "Overview\nThis practice reviews the Relationships among numerical variabless lecuture."
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#example",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#example",
    "title": "Relationships among numerical variables",
    "section": "Example",
    "text": "Example\nFollowing the iris dataset from class\n\nlibrary(ggplot2)\nggplot(iris, aes(x=Petal.Length, y=Sepal.Length)) +\n  geom_point(size = 3) +\n  ylab(\"Sepal Length\")+ggtitle(\"Sepal length increases with petal length\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))+\n  xlab(\"Petal length (cm)\") +\n  ylab(\"Sepal length (cm)\")\n\n\n\niris_regression &lt;- lm(Sepal.Length ~ Petal.Length, iris)\npar(mfrow = c(2,2))\nplot(iris_regression)\n\n\n\nlibrary(car)\n\nLoading required package: carData\n\nAnova(iris_regression, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Sepal.Length\n             Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)  500.16   1 3018.28 &lt; 2.2e-16 ***\nPetal.Length  77.64   1  468.55 &lt; 2.2e-16 ***\nResiduals     24.53 148                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(iris_regression)\n\n\nCall:\nlm(formula = Sepal.Length ~ Petal.Length, data = iris)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.24675 -0.29657 -0.01515  0.27676  1.00269 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4.30660    0.07839   54.94   &lt;2e-16 ***\nPetal.Length  0.40892    0.01889   21.65   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4071 on 148 degrees of freedom\nMultiple R-squared:   0.76, Adjusted R-squared:  0.7583 \nF-statistic: 468.6 on 1 and 148 DF,  p-value: &lt; 2.2e-16\n\n\n\ncor.test(~ Sepal.Length + Petal.Length, data = iris)\n\n\n    Pearson's product-moment correlation\n\ndata:  Sepal.Length and Petal.Length\nt = 21.646, df = 148, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8270363 0.9055080\nsample estimates:\n      cor \n0.8717538 \n\ncor.test(~ Sepal.Length + Petal.Length, data = iris,\n         method=\"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  Sepal.Length and Petal.Length\nS = 66429, p-value &lt; 2.2e-16\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.8818981 \n\n\n\nbootstrap_iris &lt;- Boot(iris_regression)\n\nLoading required namespace: boot\n\nConfint(bootstrap_iris)\n\nBootstrap bca confidence intervals\n\n              Estimate     2.5 %    97.5 %\n(Intercept)  4.3066034 4.1653483 4.4669840\nPetal.Length 0.4089223 0.3679834 0.4468094"
  },
  {
    "objectID": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#practice",
    "href": "content/solutions/8_Relationships_among_numerical_variables_solutions.html#practice",
    "title": "Relationships among numerical variables",
    "section": "Practice",
    "text": "Practice\n\n1\n\nA professor carried out a long-term study to see how various factors impacted pulse rate before and after exercise. Data can be found at\n\nhttp://www.statsci.org/data/oz/ms212.txt\nWith more info at\nhttp://www.statsci.org/data/oz/ms212.html.\nIs there evidence that age, height, or weight impact change in pulse rate for students who ran (Ran column = 1)? For each of these, how much variation in pulse rate do they explain?\n\npulse &lt;- read.table(\"http://www.statsci.org/data/oz/ms212.txt\", header = T, stringsAsFactors = T)\npulse$change &lt;- pulse$Pulse2 - pulse$Pulse1\n#need to make columns entered as numeral change to factor, although it doesn't \n#really matter when only 2 groups (why?)\npulse$Exercise &lt;-as.factor(pulse$Exercise)\npulse$Gender &lt;- as.factor(pulse$Gender)\n\n#age\nexercise &lt;- lm(change ~ Age, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\nrequire(car)\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)  3882.7  1  8.6317 0.005242 **\nAge           222.7  1  0.4950 0.485395   \nResiduals   19792.3 44                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Age, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-41.512 -12.183   2.591  12.893  44.868 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  67.3759    22.9328   2.938  0.00524 **\nAge          -0.7932     1.1274  -0.704  0.48539   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.21 on 44 degrees of freedom\nMultiple R-squared:  0.01113,   Adjusted R-squared:  -0.01135 \nF-statistic: 0.495 on 1 and 44 DF,  p-value: 0.4854\n\n\nFirst we need to make a column that shows change in pulse rate. We also should change Exercise and gender to factors.\nFor age we note the model meets assumptions (no patterns in residuals and residuals follow a normal distribution). We also find no evidence that age impacts change (F1,44 = .4950, p = 0.49). We fail to reject our null hypothesis that there is no relationship between age and change in pulse rate. We also note that age only explains 1.1% of the variation in change in pulse rate (likely due to chance!).\n\n#weight\nexercise &lt;- lm(change ~ Weight, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)  3588.9  1  7.9618 0.007143 **\nWeight        181.5  1  0.4027 0.528990   \nResiduals   19833.4 44                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Weight, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-43.173 -17.343   1.967  13.503  42.760 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  42.1276    14.9300   2.822  0.00714 **\nWeight        0.1381     0.2176   0.635  0.52899   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 21.23 on 44 degrees of freedom\nMultiple R-squared:  0.009069,  Adjusted R-squared:  -0.01345 \nF-statistic: 0.4027 on 1 and 44 DF,  p-value: 0.529\n\n\nFor weight we note the model meets assumptions. We also find no evidence that weight impacts change (F1,44 = .4027, p = 0.53). We fail to reject our null hypothesis that there is no relationship between weight and change in pulse rate. We also note that weight only explains 1% of the variation in change in pulse rate (likely due to chance!).\n\n#height\nexercise &lt;- lm(change ~ Height, pulse[pulse$Ran == 1, ])\npar(mfrow =c (2,2))\nplot(exercise)\n\n\n\nAnova(exercise, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: change\n             Sum Sq Df F value Pr(&gt;F)\n(Intercept)   243.9  1  0.5503 0.4621\nHeight        511.4  1  1.1536 0.2886\nResiduals   19503.6 44               \n\nsummary(exercise)\n\n\nCall:\nlm(formula = change ~ Height, data = pulse[pulse$Ran == 1, ])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-42.798 -17.012   1.848  12.177  43.861 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  21.0688    28.4017   0.742    0.462\nHeight        0.1773     0.1650   1.074    0.289\n\nResidual standard error: 21.05 on 44 degrees of freedom\nMultiple R-squared:  0.02555,   Adjusted R-squared:  0.003402 \nF-statistic: 1.154 on 1 and 44 DF,  p-value: 0.2886\n\n\nFor height we note the model meets assumptions. We also find no evidence that weight impacts change (F1,44 = 1.15, p = 0.29). We fail to reject our null hypothesis that there is no relationship between height and change in pulse rate. We also note that age only explains 2.5% of the variation in change in pulse rate (likely due to chance!).\n\n\n2\n\n(from OZDASL repository, http://www.statsci.org/data/general/stature.html; reference for more information)\n\nWhen anthropologists analyze human skeletal remains, an important piece of information is living stature. Since skeletons are commonly based on statistical methods that utilize measurements on small bones. The following data was presented in a paper in the American Journal of Physical Anthropology to validate one such method. Data is available @\nhttp://www.statsci.org/data/general/stature.txt\nas a tab-delimted file (need to use read.table!) Is there evidence that metacarpal bone length is a good predictor of stature? If so, how much variation does it account for in the response variable?\n\nheight &lt;- read.table(\"http://www.statsci.org/data/general/stature.txt\", \n                     header = T, stringsAsFactors = T)\nhead(height)\n\n  MetaCarp Stature\n1       45     171\n2       51     178\n3       39     157\n4       41     163\n5       48     172\n6       49     183\n\nmetacarp_relationship &lt;- lm(Stature ~ MetaCarp, height)\nplot(metacarp_relationship)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(metacarp_relationship, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Stature\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept) 515.73  1  28.491 0.001078 **\nMetaCarp    347.29  1  19.186 0.003234 **\nResiduals   126.71  7                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(metacarp_relationship)\n\n\nCall:\nlm(formula = Stature ~ MetaCarp, data = height)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0102 -3.1091 -1.1128  0.3891  7.4880 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   94.428     17.691   5.338  0.00108 **\nMetaCarp       1.700      0.388   4.380  0.00323 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.255 on 7 degrees of freedom\nMultiple R-squared:  0.7327,    Adjusted R-squared:  0.6945 \nF-statistic: 19.19 on 1 and 7 DF,  p-value: 0.003234\n\n\nTo consider the relationship among these continuous variables, we used linear regression. Analysis of model assumptions suggest assumptions are met, although the dataset is small. Analysis suggests there is a significant positive relationship between metacarpal length and stature (F1,7 = 19.19, p = 0.003). The R2 value indicates that metacarpal length explains 73% of the variation in stature. Coefficients indicate that stature increases with increasing metacarpal length.\n\n\n3\n\nData on medals won by various countries in the 1992 and 1994 Olympics is available in a tab-delimited file at\n\nhttp://www.statsci.org/data/oz/medals.txt\nMore information on the data can be found at:\nhttp://www.statsci.org/data/oz/medals.html\nIs there any relationship between a country’s population and the total number of medals they win?\n\nmedals &lt;- read.table(header = T, \"http://www.statsci.org/data/oz/medals.txt\", \n                     stringsAsFactors = T)\nhead(medals)\n\n       Country Summer Winter Population Latitude\n1  UnifiedTeam    112     34      231.5       61\n2 UnitesStates    108     13      260.7       38\n3      Germany     82     24       81.1       51\n4        China     54      3     1190.4       36\n5         Cuba     31      0       11.1       22\n6      Hungary     30      0       10.3       46\n\nmedals$total &lt;- medals$Summer + medals$Winter\npopulation_medals &lt;- lm(total ~ Population, medals)\nplot(population_medals)\n\n\n\n\n\n\n\n\n\n\n\n\nsummary(population_medals)\n\n\nCall:\nlm(formula = total ~ Population, data = medals)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-36.470 -12.303  -9.525   4.379 118.141 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept) 12.01849    3.51123   3.423  0.00112 **\nPopulation   0.06842    0.02117   3.233  0.00199 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 25.8 on 60 degrees of freedom\nMultiple R-squared:  0.1483,    Adjusted R-squared:  0.1341 \nF-statistic: 10.45 on 1 and 60 DF,  p-value: 0.001994\n\nAnova(population_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: total\n            Sum Sq Df F value   Pr(&gt;F)   \n(Intercept)   7799  1  11.716 0.001122 **\nPopulation    6957  1  10.450 0.001994 **\nResiduals    39942 60                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\ncor.test(~total + Population, medals, method = \"spearman\")\n\nWarning in cor.test.default(x = mf[[1L]], y = mf[[2L]], ...): Cannot compute\nexact p-value with ties\n\n\n\n    Spearman's rank correlation rho\n\ndata:  total and Population\nS = 29456, p-value = 0.04271\nalternative hypothesis: true rho is not equal to 0\nsample estimates:\n      rho \n0.2582412 \n\n\nThere is a high leverage point in the dataset (row 4), but residuals appear to be fairly normally distributed and little structure exists in the graph of Residuals vs. Fitted Values. Analysis using linear regression suggests a significant ( F1,60 = 10.45, p = 0.002) positive relationship between population size and medal count that explains ~15% of the variation in the response variable. Rank- correlation analysis also indicated this relationship exists.\n\n\n4\n\nContinuing with the Olympic data, is there a relationship between the latitude of a country and the number of medals won in summer or winter Olympics?\n\n\n#still using medals\nsummer_medals &lt;- lm(Summer ~ Latitude, medals)\nplot(summer_medals)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(summer_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Summer\n             Sum Sq Df F value  Pr(&gt;F)  \n(Intercept)     3.6  1  0.0075 0.93143  \nLatitude     2440.3  1  5.0389 0.02848 *\nResiduals   29057.2 60                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(summer_medals)\n\n\nCall:\nlm(formula = Summer ~ Latitude, data = medals)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.707 -10.856  -4.922   0.352  93.827 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)   0.5403     6.2531   0.086   0.9314  \nLatitude      0.3588     0.1598   2.245   0.0285 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 22.01 on 60 degrees of freedom\nMultiple R-squared:  0.07747,   Adjusted R-squared:  0.0621 \nF-statistic: 5.039 on 1 and 60 DF,  p-value: 0.02848\n\nwinter_medals &lt;- lm(Winter ~ Latitude, medals)\nplot(winter_medals)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(winter_medals, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: Winter\n             Sum Sq Df F value    Pr(&gt;F)    \n(Intercept)   90.07  1  2.2353 0.1401300    \nLatitude     502.29  1 12.4652 0.0008035 ***\nResiduals   2417.71 60                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(winter_medals)\n\n\nCall:\nlm(formula = Winter ~ Latitude, data = medals)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-6.906 -3.773 -1.383  1.395 26.768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  -2.6967     1.8037  -1.495 0.140130    \nLatitude      0.1628     0.0461   3.531 0.000803 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.348 on 60 degrees of freedom\nMultiple R-squared:  0.172, Adjusted R-squared:  0.1582 \nF-statistic: 12.47 on 1 and 60 DF,  p-value: 0.0008035\n\n\nVisual analysis of residuals from both models show some structure in the residual and deviations from normality, but we continue on with linear regression given the small sample size. Both summer and winter medal counts are positively (surpisingly) and significantly (both p &lt;.05) related to latitude, with latitude explaining ~17% of the variation in winter medal count and ~8% of the data in summer medal count.\n\n\n5\n\nData on FEV (forced expiratory volume), a measure of lung function, can be found at\n\nhttp://www.statsci.org/data/general/fev.txt\nMore information on the dataset is available at\nhttp://www.statsci.org/data/general/fev.html.\nIs there evidence that FEV depends on age or height? If so, how do these factors impact FEV, and how much variance does each explain?\n\nfev &lt;- read.table(\"http://www.statsci.org/data/general/fev.txt\", header = T, \n                  stringsAsFactors = T)\nhead(fev)\n\n    ID Age   FEV Height    Sex Smoker\n1  301   9 1.708   57.0 Female    Non\n2  451   8 1.724   67.5 Female    Non\n3  501   7 1.720   54.5 Female    Non\n4  642   9 1.558   53.0   Male    Non\n5  901   9 1.895   57.0   Male    Non\n6 1701   8 2.336   61.0 Female    Non\n\nfev_height &lt;- lm(FEV ~ Height, fev)\nplot(fev_height)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_height, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept) 166.25   1  896.33 &lt; 2.2e-16 ***\nHeight      369.99   1 1994.73 &lt; 2.2e-16 ***\nResiduals   120.93 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_height)\n\n\nCall:\nlm(formula = FEV ~ Height, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.75167 -0.26619 -0.00401  0.24474  2.11936 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -5.432679   0.181460  -29.94   &lt;2e-16 ***\nHeight       0.131976   0.002955   44.66   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4307 on 652 degrees of freedom\nMultiple R-squared:  0.7537,    Adjusted R-squared:  0.7533 \nF-statistic:  1995 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n\nModel assumptions appear to be met. Height appears to have a positive relationship with FEV (F1,652 = 1995, p&lt;.001).\n\nfev_age &lt;- lm(FEV ~ Age, fev)\nplot(fev_age)\n\n\n\n\n\n\n\n\n\n\n\n\nAnova(fev_age, type = \"III\")\n\nAnova Table (Type III tests)\n\nResponse: FEV\n            Sum Sq  Df F value    Pr(&gt;F)    \n(Intercept)   9.89   1  30.707 4.359e-08 ***\nAge         280.92   1 872.184 &lt; 2.2e-16 ***\nResiduals   210.00 652                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nsummary(fev_age)\n\n\nCall:\nlm(formula = FEV ~ Age, data = fev)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.57539 -0.34567 -0.04989  0.32124  2.12786 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.431648   0.077895   5.541 4.36e-08 ***\nAge         0.222041   0.007518  29.533  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5675 on 652 degrees of freedom\nMultiple R-squared:  0.5722,    Adjusted R-squared:  0.5716 \nF-statistic: 872.2 on 1 and 652 DF,  p-value: &lt; 2.2e-16\n\n\nModel assumptions appear to be met. Age appears to have a positive relationship with FEV (F1,652 = 872.2, p&lt;.001).\n\n\n6\n\nContinuing with the FEV data, produce plots that illustrate how height, age, and gender each impact FEV.\n\n\nlibrary(ggplot2)\n#age plot####\nggplot(fev, aes(x=Age, y=FEV)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  ylab(\"FEV (L)\")+ggtitle(\"FEV increases with age\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n#height plot####\nggplot(fev, aes(x=Height, y=FEV)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  ylab(\"FEV (L)\")+ggtitle(\"FEV increases with height\")+\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n#gender plot ####\n\n#bar chart with error bars ####\nlibrary(Rmisc)\n\nLoading required package: lattice\nLoading required package: plyr\n\nfunction_output &lt;- summarySE(fev, measurevar=\"FEV\", groupvars =\n                               c(\"Sex\"))\n\nggplot(function_output, aes(x=Sex, y=FEV)) +\n  geom_col(size = 3) +\n  ylab(\"FEV (L)\") +\n  ggtitle(\"FEV is higher in males \")+\n  geom_errorbar(aes(ymin=FEV-ci, ymax=FEV+ci), size=1.5) +\n  theme(axis.title.x = element_text(face=\"bold\", size=28), \n        axis.title.y = element_text(face=\"bold\", size=28), \n        axis.text.y  = element_text(size=20),\n        axis.text.x  = element_text(size=20), \n        legend.text =element_text(size=20),\n        legend.title = element_text(size=20, face=\"bold\"),\n        plot.title = element_text(hjust = 0.5, face=\"bold\", size=32))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead."
  }
]