[
  {
    "objectID": "content/additional_resources.html",
    "href": "content/additional_resources.html",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!"
  },
  {
    "objectID": "content/additional_resources.html#class-related-materials",
    "href": "content/additional_resources.html#class-related-materials",
    "title": "Additional resources",
    "section": "",
    "text": "The class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!"
  },
  {
    "objectID": "content/additional_resources.html#other-resources",
    "href": "content/additional_resources.html#other-resources",
    "title": "Additional resources",
    "section": "Other resources",
    "text": "Other resources\nAs noted in the introduction, there are many, many resources that may assist you in your quest to learn statistics and R. Relevant ones are noted throughout the book and listed here.\n“Introduction to Data Science” (n.d.)\n“Welcome | r for Data Science” (n.d.)"
  },
  {
    "objectID": "content/Acquiring_data.html",
    "href": "content/Acquiring_data.html",
    "title": "Acquiring data",
    "section": "",
    "text": "Let’s start our statistics journey by thinking about the simplest scenario: We want to know something about a group. An example might be the average (or mean, we will define later if needed!) value for some trait, the minimum value, or the maximum value. We could also wish to know about the distribution of values for that trait in the group. These traits of the group are called statistics:\n\nthe numerical facts or data themselves - Dictionary.com\n\nThis means we have a target trait we are focused on, and we have defined a group of interest. We can call this group of interest a population. Note that while the term population may have specific meanings in some fields (such as ecology), here population is just the group of interest. It could be a population of Goliath grouper in Florida, a population of flowers in Virginia, or people from a certain country or demographic group. We could want to know something about all of these groups!\nAs we’ve already noted, in a perfect world we know everything (or at least our trait value) for every member of the focal population. However, we often don’t or can’t measure every member of a population. It may be too difficult or expensive to measure every member of the population. In fact, we may not even know how large the population is!\nIn the cases where we can’t measure every member of the population, we collect data on the focal trait(s) from a sample. A sample is the subset of the population of interest. Data can be collected from samples used in experimental studies, where researchers manipulate something to see how it impacts the focal trait. Researchers may expose organisms to different stimuli in a controlled lab, field, or mesocosm study to see what happens. For example, researchers interested in impacts of an invasive crayfish (Pacifastacus leniusculus) on Mazama newts (Taricha granulosa mazamae) collected newts and crayfish.; they then placed either just newts or newts and crayfish in in large tanks to observe interactions Girdner et al. (2018).\n\n\n\nFigure 1: Experimental mesocosms used to evaluate Mazama newt and signal crayfish behavior on Wizard Island, Crater Lake, Oregon. A team of NPS scientists observed the interaction between newts and crayfish in tanks designed to mimic natural habitat.\n\n\nData can also be collected from observational studies, where researchers simply measure outcomes and other traits without manipulating anything. For example, scientists interested in impacts of climate change on species ranges surveyed sites for species presence and abundance and compared it to historical data (Sagarin et al. (1999)).\nDifferent types of studies change what we can use the data for. In general, experimental studies are more commonly used to ascertain causation (something makes something happen), whereas observational studies are used to assess correlation (something happens when something else happens). However, these can be hard to disentangle, especially since studies can only be observational since experiments would be unethical or impossible to carry out. As XKCD puts it\n\n\n\nFigure 2: XKCD: Correlation. Title text (text that pops up when you hover over the comic): Correlation doesn't imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’.\n\n\n\nCorrelation doesn’t imply causation, but it does waggle its eyebrows suggestively and gesture furtively while mouthing ‘look over there’ - XKCD #552\n\nOnce we have the sample, we can measure the trait of interest in it, and use that to estimate the statistic of interest for the actual population. This is the science of statistics, which can actually be defined as\n\nthe practice or science of collecting and analyzing numerical data in large quantities, especially for the purpose of inferring proportions in a whole from those in a representative sample. - Oxford English Dictionary\n\nIf the whole idea of statistics is to infer something about the population from our sample, we need to make sure the sample is representative of the population. That means it should not be biased. Bias occurs if the trait values we measure in our sample differ from the population in a consistent way. This can happen with samples of convenience, or when researchers select samples that are easy to measure but may not be representative of the population. Classic examples include estimating the amount of time students spend studying by surveying students at a campus library.\nBias may also be related to issues of independence. In a good sampling design, every member of the population has the same chance of being included in a sample. Samples of convenience violate this premise, and often the underlying issue is that the samples are not independent. A perfect solution is to randomly choose members of the population to be in the sample, but that is often not possible. Again, it requires knowing every member of the population! Indepence also means each data point is not related to any others!\n\n\n\nFigure 3: XKCD: Slope Hypothesis Testing. Don’t worry, we’ll come back to significance - but what is the independence issue?\n\n\nIn some cases linkages among samples are impossible to avoid. We will cover ways to address that using blocking factors or random effects later.\nNotice in discussing bias we are not directly focusing on the quality of the measurements! For that, we could discuss accuracy (how well we measure the underlying trait in regards to its true value, which we typically don’t know) and precision (how repeatable our measurement technique is). Obviously we need good data to make good estimates, but these ideas are different from our current focus on picking a good sample.\nEven if we have a proper way to measure a trait (accurate and precise) in a good sample (not biased), we will still be producing an estimate of the population statistic! This is due to *sampling error*. Sampling error refers to the fact that every sample will produce a slightly different estimate of the statistic. Imagine this - there a 1000 fish in a lake. We sample 50 of them, measure their length, and use it calculate the average fish length. If we took a different sample, do you think it would have exactly the same average?\nWe can demonstrate this in R - you won’t understand the code below yet, so just trust me for now, but this will let you start seeing code and thinking about how to use it.\nLet’s generate a population of fish. We’ll store their lengths in a vector called *lengths* .\n\nlengths &lt;- rnorm(n=1000, mean = 10, sd=1)\n\nThe average length of fish in this population is 10.01 cm. We can then simulate a sample from this population. In fact, let’s simulate 2 and compare the means of each.\n\nsample_1 &lt;- sample(lengths,50)\nsample_2 &lt;-sample(lengths, 50)\n\nThe mean length for fish in sample 1 is 9.77 cm, while that in sample 2 is 10 cm (Note: if you view this on the webpage you will see a number, but in the actual qmd file you see R code here - this is an example of merging code and text!). These are both close to the true value, but they are also both slightly different - this is sampling error!\nSampling error always exists, and a major part of statistics is to quantify it. One thing that reduces sampling error is to have large samples! Remember, if we measure every member of the population we don’t even need statistics, so the closer we get to that (implying larger samples) the better!\nNow that we have data, we’ll discuss summarizing it in the next section (and actually define mean and some of the other terms we’ve started to use!).\n\n\n\n\nReferences\n\nGirdner, Scott F., Andrew M. Ray, Mark W. Buktenica, David K. Hering, Jeremy A. Mack, and John W. Umek. 2018. “Replacement of a Unique Population of Newts (Taricha Granulosa Mazamae) by Introduced Signal Crayfish (Pacifastacus Leniusculus) in Crater Lake, Oregon.” Biological Invasions 20 (3): 721–40. https://doi.org/10.1007/s10530-017-1570-6.\n\n\nSagarin, Raphael D., James P. Barry, Sarah E. Gilman, and Charles H. Baxter. 1999. “Climate-Related Change in an Intertidal Community over Short and Long Time Scales.” Ecological Monographs 69 (4): 465–90. https://doi.org/10.2307/2657226."
  },
  {
    "objectID": "content/1b_intro_to_Rmd.html",
    "href": "content/1b_intro_to_Rmd.html",
    "title": "1b. Intro to Rmd files and literate programming",
    "section": "",
    "text": "Rmd files differ from R files in that they combine regular text with code chunks. This is a code chunk\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nCode chunks combine code with output. When combined with regular text/prose, this makes it easier to produce a range of documents. You set the output in the YAML header (the stuff between the 3 dashes you see at top of this document).\nAfter you write the file, you Knit it to turn the Rmd file into the selected output. Try it now. Note the first time you do this in a project you may be prompted to install a number of packages! If you are using a webservice you may also need to allow pop-ups in your browser. Don’t be surprised if a new window pops up (it should).\n\n\n\nThe knit button turns your .rmd file into other products\n\n\nThe Knit button saves the .Rmd file and renders a new version whose output depends on what you selected in the header. Here we have html_document, so if everything works a preview of a webpage like document should appear. The file also produces a github friendly .md file. This means you should only edit the Rmd file (leave the md and output files alone! They are automatically produced any changes you make there will be overwritten by your next knit).\nWhen you Knit a file, it runs in a totally new R instance. this means anything you only added in your instance (like working in the console) won’t be available. In other words, its the best way to see what a “new” user gets when they use your code.\nhowever, you don’t have to knit the file every time. if you just want to see output, note you can press the green button next to an R chunk.\n\n\n\nThe green arrows just runs the chunk in the console and shows the output\n\n\n\nprint(\"this is a chunk\")\n\n[1] \"this is a chunk\"\n\n\nNow we’ll start changing the file to show you how rmarkdown works. First, amend the file by replacing the NAME and DATE spots in the header (top of the file between the — markers) with your name and the real date. Then Knit the file again. You should see your name in the new preview.\nRstudio has a Markdown Quick Reference guide (look under the help tab), but some general notes.\n\nPound/Hashtag signs denote headers\nyou can surround something double asterisks for bold or single asterisks for italics\nlists are denoted by numbers or asterisks at beginning of line (followed by space!)\n\nand can be indented for sublevels\n\nR code can be done inline, but is generally placed in stand-alone chunks\n\nthese will, by default, show the code and output\n\nlots of other options exist!\n\nThe main idea is Rmd files allow you to combine code, text, graphs, etc into multiple outputs that you can share (including with coding illiterate colleagues who just want output)."
  },
  {
    "objectID": "content/getting_started.html",
    "href": "content/getting_started.html",
    "title": "Before the first class",
    "section": "",
    "text": "Over the course of the semester/reading this book, our (ambitious) goals are to\nTo prepare for our first few lessons"
  },
  {
    "objectID": "content/getting_started.html#concept-stuff",
    "href": "content/getting_started.html#concept-stuff",
    "title": "Before the first class",
    "section": "Concept stuff",
    "text": "Concept stuff\n\nCheck out the class website\nWatch this video"
  },
  {
    "objectID": "content/getting_started.html#tech-stuff",
    "href": "content/getting_started.html#tech-stuff",
    "title": "Before the first class",
    "section": "Tech stuff",
    "text": "Tech stuff\n\nGet access to R!. You can make an account at Rstudio cloud (https://rstudio.cloud/). You can also install R (https://cran.r-project.org/) and Rstudio (https://www.rstudio.com/) on your machine, but I strongly recommend starting with Rstudio cloud.\nRstudio cloud is free for up to 25 hours/month, you don’t have to maintain it, and it gives gives a standard install (same on all machines, so your intro/ our training may be smoother). You can also do both. If you need help, videos are at :\n\nDownloading R\nDownloading Rstudio\nMaking a Rstudio cloud account\n\nJoin the github classroom we’ll be using for our sessions\n\nlook for email from Blackboard! \nWhen you visit the page it will ask you to connect or create a github repository. You can use any name (be anonymous or not) that you want. This is a free process.\n\n\n\nOptional (get a head start if you want)\nIt may be easier to open these intructions in a browser so you can follow along there while working in Rstudio!\nAfter you join the github classroom, you’ll make a clone of the repository onto your machine. First, find your copy of the repository. You can follow the github classroom link again, or log into github and then visit https://github.com/settings/repositories. Find the repository called data_science_intro_YOURGITHUBUSERNAME, and click on it. Then follow along below - find instructions for Rstudio cloud or Rstudio desktop depending on your setup.\n\nIf you are using Rstudio cloud…\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio cloud\nLog into your Rstudio cloud account. You’ll see something like this:\n\n\n\nRstudio cloud home screen\n\n\nTo copy a repository, select New Project, New Project from Github repo. Next you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!)\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the field asking for the URL of your github repository.\nNote you may need to enter your github username and password to create the repository.\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!\n\n\nIf you are using RStudio on your desktop (or via a server…anywhere that\nlooks like an RStudio screen)\nVideo at Accepting your first github repository (from github classroom) and cloning to Rstudio desktop\nTo start working on an assignment, open RStudio.\n\n\n\nSelect File &gt; New Project in Rstudio\n\n\nSelect file, new project, Version control. On the next screen select git. If this isn’t available, you may need to install git (free) on your system. You can download it at https://git-scm.com/download/.\nNext you’ll need to enter the url for your repository. To find this, click on the Code button from the github page for your repository (instructions above!).\n\n\n\nClick on Code to get repository url\n\n\nCopy the web url (or click the copy icon). Input that into the Rstudio Repository URL space. You can select/edit what you want the repository to be called and where its stored (its just a folder on your computer). For example, I have a Repositories folder in my main hard drive where I save all of these. Then select Create project. Whatever you choose, the project will be saved in new folder in that location using the name you chose. Note you may need to enter your github username and password to create the repository.\nYou also may get an error/warning about personal access token! this happens at different points on different machines (thus why Rstudio cloud is nice). If you see this now, don’t worry. We’ll cover it (a known issue) in class.\nThe next screen will bring you to a “normal” RStudio screen. We’ll come back to this in the first class or two!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "This site is a work in progress! Original .R and .rmd files from are being migrated into a new book using quarto."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Welcome",
    "section": "Welcome",
    "text": "Welcome\nThis book is meant to accompany BIO/ENV 2100:Biostatistics at Baruch College, but it should offer another perspective to anyone trying to learn statistics, R, or some combination. The class now includes\n\na website housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!\n\nAll of these resources may prove useful in learning the material.\nI say another perspective because an immediate question should be why the world needs another self-published statistics book, especially one focused on introducing R. There are already many, many good ones (some of which are shared at the end of each of relevant chapter and in the list of additional resources).To this I offer a few responses\n\nAs already noted, this book was designed to accompany courses I teach. Having the material presented in the same order, but with additional context, should help students learn the material.\nThe courses I teach focus on introducing statistics from a biological perspective, so examples, papers, and problems focus on natural systems when possible. Having examples, including from published papers, that introduce the need and use of various tests should aid in helping students learn to understand why various tests exist and when they should be used."
  },
  {
    "objectID": "index.html#here-there-be-monsters-but-also-opportunities",
    "href": "index.html#here-there-be-monsters-but-also-opportunities",
    "title": "Welcome",
    "section": "Here there be monsters, but also opportunities!",
    "text": "Here there be monsters, but also opportunities!\nStatistics is a complex field that is unfortunately often stuffed into the curriculum of other majors (see above). However, my goal is to teach the concepts while also giving students the tools to actually address questions. Given these goals,\n\nwe’ll learn how to use tools and applications including R (through Rstudio), git, and markdown. If this is your first time using any (or all) of these tools, don’t worry. We will start at the very beginning.\n\nThere are many, many ways to do any task in R. I will show you one (sometimes two) for a given concept, but note you may find other approaches online or in other material\nI typically use verbose coding (more words and lines, but easier to read and understand). I know much of what we do could be done in fewer steps, but speed is commonly less of an issue than readability (which is connected to repoducibility) for our fields\n\nGiven our focus on concepts, we will not dwell on the proofs or other mathematical components of statistics. I’m happy to point you towards texts to help with those, or discuss them.\nWe will use easy examples to illustrate concepts and applications (toy datasets), which make it easier for you to update in the future (real data are often messy!) while also connecting our class to real-life papers and ideas as much as possible\n\n\n\n\nFigure 1: Old maps rarely stated “Here there be monsters”, but mythical animals did appear on maps!\n\n\nBe warned: You may encounter some questions as we introduce new material. For example, we’ll talk about normality before fully explaining it. We’ll also use code (to make figures, for example) before you understand it. Feel free to ask questions, but you can also be sure we’ll cycle back (and expand) on many topics. I’ll also add asides/tangents throughout the book to help answer some common questions that pop up.\nHopefully this will open the door to careers in data science (a related term) and statistics to some students who haven’t considered that path before. Jobs in these fields are some of the fastest growing in the country, and the skills you learn in this class, including\n\nCritical thinking\nCoding\n\nR\nmarkdown\ngit\n\nData wrangling\nVisualization and stats\nWriting and communication\n\nwill be some of the most transferable you acquire as an undergraduate.\n\n\n\nFigure 2: Chart from Occupational Outlook Handbook showing fastest growing occupations and median pay. Data from 9.8.22. Screenshot taken 7.26.23\n\n\nI hope you find the book useful and learn to see statistics as more than something you do to finish a project or a course that you are required to take. The book is written in quarto, a derivative/extension of rmarkdown, which allows R code and prose to be easily created and published together. You can see the code for all the material on github, and you will learn early on how to make a copy of the material that you can work on yourself."
  },
  {
    "objectID": "content/acknowledgements.html",
    "href": "content/acknowledgements.html",
    "title": "Acknowledgments",
    "section": "",
    "text": "Many thanks to Bill Rice and Steve Gaines at UCSB for encouraging me to continue my interests in statistics.\nMy department at Baruch also supported me when I proposed the Biostatistics (ENV/BIO 2100) course in 2017 and taught for the first time in 2018.\nBaruch College’s Center for Teaching and Learning, as a channel for a statewide funding effort focuse on developed OER (open-educational resources) at CUNY and SUNY campuses, have supported the continued development of the class.\nThe class now includes\n\nwebsite (https://sites.google.com/view/biostats/home) housing slides and associated material\ntutorials for many lessons using Swirl\n\ndeveloped with support of a QUBES working group\n\nthis book!\n\nThis repo and GitHub Action was based on the tutorial by Openscapes quarto-website-tutorial by Julia Lowndes and Stefanie Butland."
  },
  {
    "objectID": "content/Introduction.html",
    "href": "content/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "“Why is statistics a required course for someone who wants to be a dentist/doctor/ nurse?”\nThis is a common question (or at least thought) for many students. I hope to convince you this semester you at least need to understand statistics as part of the scientific method (and you should realize the scientific process informs all those jobs - in fact it can inform any job or task where you are searching for an answer or better method).\nFor example, doctors prescribe medicine to patients, but how do they know these medicines work? Some doctors carry out research, but many rely on published guidelines, which themselves rely on research. So a new drug or treatment is proposed- but who decides it’s worth using? Researchers carry out trials to determine the efficacy of the treatment. In doing this they have to consider how to design an experiment (what do they collect? from whom?) and analyze the resulting data so they can trust the results.\n\n\n\nFigure 1: XKCD: Control Group\n\n\nOther students in our class may be interested in a more environment- or resource management- focused career (e.g., wildlife rehabilitation, carbon mitigation expert, researcher). Regardless of your goal, any question should be informed by this approach. For example,\n\nDoes an environmental factor cause cancer?\nDo potential toxins really harm the enviroment?\nIs organic food really healthier?\nDoes exposing organisms reared in captivity to predator cues lead to more successful releases?\n\nZhu et al. (2023)\n\n\n\nAt its heart, statistics is about turning data into information that we can use to make decisions or better understand the world around us. Data can come from experiments we are running. This offers a clear connection to field and lab science, and its what we will focus on for most of this class. Data and theories can also be used to develop models that produce output ; this isn’t real-world data, but it offers very useful insight on what we think will happen if something occurs (and something we can test with other field data!). For example, restoration projects may focus on small-scale plots that undergo different restoration protocols. Data produced from monitoring these plots may be used to develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions.\nAbove I used words like know (how do they know these medicines work? )and predict (develop models to predict large-scale impacts (and maybe benefits and costs) of different restoration scenarios for larger regions). While we may use words like these that are related our findings interchangeably at times, its important to note the different. Statistics (and related models) generally give us estimates about how the real world works. Put another way, if we knew everything about the world, we wouldn’t need to use statistics because we wouldn’t need estimates.\nThe reasons we don’t usually know everything include\n\nthe world is complicated (some questions can’t be directly tested)\nit’s not possible to measure everything\n\nBecause of this, statistics is also focused on trying to describe populations of interest or find signals (impacts of treatments, medicines, or restoration practices, for example) amidst the noise (variation in outcomes that are always common!). When considering relationships among variables, noise may occur because there are lots of things impacting the outcome of interest. For example, restoration protocol may impact the trajectory of an oyster reef, but so too may local factors like temperature an and salinity. Noise can also occur because of sampling error - since we don’t measure everything, our estimate of relationship or population traits may be imperfect.\nIn the next session we’ll start to discuss how we can use data to make estimates about a population (and answer questions like what is a population and what are we trying to estimate). However, a final aside to finish this section - we often think about statistics happening after an experiment, survey, or other thing we get data from is finished. However, part of statistics is experimental design! Statistics should inform how you setup an experiment. In fact, the best idea (which seldom happens!) is that you simulate the type of data you expect to get from your experiment and then analyze that before you actually run the experiment. This ensures you are measuring what you need to measure and setting things up correctly! As the famous quote (to statisticians) states,\n\nTo consult the statistician after an experiment is finished is often merely to ask him to conduct a post mortem examination. He can perhaps say what the experiment died of. -Ronald Fisher\n\n\n\n\n\nReferences\n\nZhu, Jennifer, J. Stephen Gosnell, Laila Akallal, and Micah Goltsman. 2023. “Fear Changes Traits and Increases Survival: A Meta-Analysis Evaluating the Efficacy of Antipredator Training in Captive-Rearing Programs.” Restoration Ecology 31 (3): e13674. https://doi.org/10.1111/rec.13674."
  },
  {
    "objectID": "content/summarizing_data.html",
    "href": "content/summarizing_data.html",
    "title": "Summarizing data",
    "section": "",
    "text": "Figure 1: XKCD: Data Trap. It’s important to make sure your analysis destroys as much information as it produces.\nOnce we have some data, the next step is often to summarize it. In fact, we’ve already done that in some ways. Some statistics like the mean may be considered a summary of the data. This may be useful because we prefer large datasets (remember good sampling!), but making sense of a list of numbers can be really hard! Summaries help us describe, and eventually compare, datasets, which we are using to infer something about a population.\nThink about it this way. We want to know if several species of iris (Iris versicolor, setosa and virginica) have similarly-shaped flowers. Since we can’t measure every flower on every plant from these species, we sample several sites and come up with the following data (using R’s built-in iris dataset, a dataset we will often use).\niris\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species\n1            5.1         3.5          1.4         0.2     setosa\n2            4.9         3.0          1.4         0.2     setosa\n3            4.7         3.2          1.3         0.2     setosa\n4            4.6         3.1          1.5         0.2     setosa\n5            5.0         3.6          1.4         0.2     setosa\n6            5.4         3.9          1.7         0.4     setosa\n7            4.6         3.4          1.4         0.3     setosa\n8            5.0         3.4          1.5         0.2     setosa\n9            4.4         2.9          1.4         0.2     setosa\n10           4.9         3.1          1.5         0.1     setosa\n11           5.4         3.7          1.5         0.2     setosa\n12           4.8         3.4          1.6         0.2     setosa\n13           4.8         3.0          1.4         0.1     setosa\n14           4.3         3.0          1.1         0.1     setosa\n15           5.8         4.0          1.2         0.2     setosa\n16           5.7         4.4          1.5         0.4     setosa\n17           5.4         3.9          1.3         0.4     setosa\n18           5.1         3.5          1.4         0.3     setosa\n19           5.7         3.8          1.7         0.3     setosa\n20           5.1         3.8          1.5         0.3     setosa\n21           5.4         3.4          1.7         0.2     setosa\n22           5.1         3.7          1.5         0.4     setosa\n23           4.6         3.6          1.0         0.2     setosa\n24           5.1         3.3          1.7         0.5     setosa\n25           4.8         3.4          1.9         0.2     setosa\n26           5.0         3.0          1.6         0.2     setosa\n27           5.0         3.4          1.6         0.4     setosa\n28           5.2         3.5          1.5         0.2     setosa\n29           5.2         3.4          1.4         0.2     setosa\n30           4.7         3.2          1.6         0.2     setosa\n31           4.8         3.1          1.6         0.2     setosa\n32           5.4         3.4          1.5         0.4     setosa\n33           5.2         4.1          1.5         0.1     setosa\n34           5.5         4.2          1.4         0.2     setosa\n35           4.9         3.1          1.5         0.2     setosa\n36           5.0         3.2          1.2         0.2     setosa\n37           5.5         3.5          1.3         0.2     setosa\n38           4.9         3.6          1.4         0.1     setosa\n39           4.4         3.0          1.3         0.2     setosa\n40           5.1         3.4          1.5         0.2     setosa\n41           5.0         3.5          1.3         0.3     setosa\n42           4.5         2.3          1.3         0.3     setosa\n43           4.4         3.2          1.3         0.2     setosa\n44           5.0         3.5          1.6         0.6     setosa\n45           5.1         3.8          1.9         0.4     setosa\n46           4.8         3.0          1.4         0.3     setosa\n47           5.1         3.8          1.6         0.2     setosa\n48           4.6         3.2          1.4         0.2     setosa\n49           5.3         3.7          1.5         0.2     setosa\n50           5.0         3.3          1.4         0.2     setosa\n51           7.0         3.2          4.7         1.4 versicolor\n52           6.4         3.2          4.5         1.5 versicolor\n53           6.9         3.1          4.9         1.5 versicolor\n54           5.5         2.3          4.0         1.3 versicolor\n55           6.5         2.8          4.6         1.5 versicolor\n56           5.7         2.8          4.5         1.3 versicolor\n57           6.3         3.3          4.7         1.6 versicolor\n58           4.9         2.4          3.3         1.0 versicolor\n59           6.6         2.9          4.6         1.3 versicolor\n60           5.2         2.7          3.9         1.4 versicolor\n61           5.0         2.0          3.5         1.0 versicolor\n62           5.9         3.0          4.2         1.5 versicolor\n63           6.0         2.2          4.0         1.0 versicolor\n64           6.1         2.9          4.7         1.4 versicolor\n65           5.6         2.9          3.6         1.3 versicolor\n66           6.7         3.1          4.4         1.4 versicolor\n67           5.6         3.0          4.5         1.5 versicolor\n68           5.8         2.7          4.1         1.0 versicolor\n69           6.2         2.2          4.5         1.5 versicolor\n70           5.6         2.5          3.9         1.1 versicolor\n71           5.9         3.2          4.8         1.8 versicolor\n72           6.1         2.8          4.0         1.3 versicolor\n73           6.3         2.5          4.9         1.5 versicolor\n74           6.1         2.8          4.7         1.2 versicolor\n75           6.4         2.9          4.3         1.3 versicolor\n76           6.6         3.0          4.4         1.4 versicolor\n77           6.8         2.8          4.8         1.4 versicolor\n78           6.7         3.0          5.0         1.7 versicolor\n79           6.0         2.9          4.5         1.5 versicolor\n80           5.7         2.6          3.5         1.0 versicolor\n81           5.5         2.4          3.8         1.1 versicolor\n82           5.5         2.4          3.7         1.0 versicolor\n83           5.8         2.7          3.9         1.2 versicolor\n84           6.0         2.7          5.1         1.6 versicolor\n85           5.4         3.0          4.5         1.5 versicolor\n86           6.0         3.4          4.5         1.6 versicolor\n87           6.7         3.1          4.7         1.5 versicolor\n88           6.3         2.3          4.4         1.3 versicolor\n89           5.6         3.0          4.1         1.3 versicolor\n90           5.5         2.5          4.0         1.3 versicolor\n91           5.5         2.6          4.4         1.2 versicolor\n92           6.1         3.0          4.6         1.4 versicolor\n93           5.8         2.6          4.0         1.2 versicolor\n94           5.0         2.3          3.3         1.0 versicolor\n95           5.6         2.7          4.2         1.3 versicolor\n96           5.7         3.0          4.2         1.2 versicolor\n97           5.7         2.9          4.2         1.3 versicolor\n98           6.2         2.9          4.3         1.3 versicolor\n99           5.1         2.5          3.0         1.1 versicolor\n100          5.7         2.8          4.1         1.3 versicolor\n101          6.3         3.3          6.0         2.5  virginica\n102          5.8         2.7          5.1         1.9  virginica\n103          7.1         3.0          5.9         2.1  virginica\n104          6.3         2.9          5.6         1.8  virginica\n105          6.5         3.0          5.8         2.2  virginica\n106          7.6         3.0          6.6         2.1  virginica\n107          4.9         2.5          4.5         1.7  virginica\n108          7.3         2.9          6.3         1.8  virginica\n109          6.7         2.5          5.8         1.8  virginica\n110          7.2         3.6          6.1         2.5  virginica\n111          6.5         3.2          5.1         2.0  virginica\n112          6.4         2.7          5.3         1.9  virginica\n113          6.8         3.0          5.5         2.1  virginica\n114          5.7         2.5          5.0         2.0  virginica\n115          5.8         2.8          5.1         2.4  virginica\n116          6.4         3.2          5.3         2.3  virginica\n117          6.5         3.0          5.5         1.8  virginica\n118          7.7         3.8          6.7         2.2  virginica\n119          7.7         2.6          6.9         2.3  virginica\n120          6.0         2.2          5.0         1.5  virginica\n121          6.9         3.2          5.7         2.3  virginica\n122          5.6         2.8          4.9         2.0  virginica\n123          7.7         2.8          6.7         2.0  virginica\n124          6.3         2.7          4.9         1.8  virginica\n125          6.7         3.3          5.7         2.1  virginica\n126          7.2         3.2          6.0         1.8  virginica\n127          6.2         2.8          4.8         1.8  virginica\n128          6.1         3.0          4.9         1.8  virginica\n129          6.4         2.8          5.6         2.1  virginica\n130          7.2         3.0          5.8         1.6  virginica\n131          7.4         2.8          6.1         1.9  virginica\n132          7.9         3.8          6.4         2.0  virginica\n133          6.4         2.8          5.6         2.2  virginica\n134          6.3         2.8          5.1         1.5  virginica\n135          6.1         2.6          5.6         1.4  virginica\n136          7.7         3.0          6.1         2.3  virginica\n137          6.3         3.4          5.6         2.4  virginica\n138          6.4         3.1          5.5         1.8  virginica\n139          6.0         3.0          4.8         1.8  virginica\n140          6.9         3.1          5.4         2.1  virginica\n141          6.7         3.1          5.6         2.4  virginica\n142          6.9         3.1          5.1         2.3  virginica\n143          5.8         2.7          5.1         1.9  virginica\n144          6.8         3.2          5.9         2.3  virginica\n145          6.7         3.3          5.7         2.5  virginica\n146          6.7         3.0          5.2         2.3  virginica\n147          6.3         2.5          5.0         1.9  virginica\n148          6.5         3.0          5.2         2.0  virginica\n149          6.2         3.4          5.4         2.3  virginica\n150          5.9         3.0          5.1         1.8  virginica\nOverwhelming, isn’t it? And this isn’t a huge dataset! There are only 150 rows, yet some datasets have tens of thousands!\nLet’s just look at the first few rows of the data\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\nIt’s really hard (or impossible) to just look at these numbers and infer anything about the population. Summary statistics help us get a better mental image of the distribution of the sample data.\nIt’s really hard (or impossible) to just look at these numbers and infer anything about the population. Summary statistics help us get a better mental image of the distribution of the sample data."
  },
  {
    "objectID": "content/summarizing_data.html#types-of-data",
    "href": "content/summarizing_data.html#types-of-data",
    "title": "Summarizing data",
    "section": "Types of data",
    "text": "Types of data\nWe can summarize data using visual (i.e., graphs) or numerical (e.g., summary statistics like the mean) approaches. The specific way we summarize the data also depends on the type of data. Note, the trait we are collecting data on may also be called a variable (since it varies across the population and thus sample).\n\nCategorical variables\nVariables can be categorical (e.g., eye color). If categorical variables have no clear hierarchical relationship (again, like eye color - one isn’t better than the other), then they are nominal variables. If the categories imply a rank or order (e.g., freshmen, sophomore, junior, senior; egg, larvae, pupae, adult) then they are ordinal variables).\n\n\nNumeric variables\nIf data values are based on numbers instead of categories, they are numeric variables. These can be divided into those are count-based (no fractions) - we call these discrete data- and those that can take on values between whole numbers - like height. We call these continuous variables."
  },
  {
    "objectID": "content/summarizing_data.html#graphical-summaries",
    "href": "content/summarizing_data.html#graphical-summaries",
    "title": "Summarizing data",
    "section": "Graphical summaries",
    "text": "Graphical summaries\nVisual interpretations or displays of your data are an excellent way to let patterns, trends, and distributions easier to see. In this section we’ll go over a number of graphs. Consider this is a resource. I don’t expect you to know how to make each of these on your own immediately. We will actually introduce the software we are using to make these in later sections. Instead, you can return here later when you are actually making a graph for ideas (and code!). For your first read, focus on the images (not the code!)\nWhile the type of graph you should use will depend on the data (and you may have several options!) all graphs should have\n\nDescriptive title\n\nMove beyond Y vs. X. State any patterns you see in the title to help the viewer know what they are looking for! Honest interpretation of data is always paramount, but in producing a graph you will already be making visualization decisions.\n\nLabeled axes (measure and unit)\n\nWhat did you measure, and using what (e.g. Sepal length (cm)\n\nData points\n\nOther parts should only be included when needed.\n\nLegends\n\nOnly needed for graphs with multiple datasets where color, shape, or some other visual cue indicates something to the viewer.\n\nTrendlines\n\nCan be used to show the general/overall relationship between variables. If you use these, make sure to use the right ones! Don’t fit a straight line to a curved relationship!\n\n\n\nSingle variable\n\nNumerical data\n\nHistograms\nOccasionally you only want to show the distribution for a single numerical variable (or how the data themselves are distributed). For example, we could want to display sepal lengths for all the Iris virginica we sampled. We could do this using a histogram.\n\nlabel_size &lt;- 2\ntitle_size &lt;-2.5\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"], \n     main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))), \n     xlab = \"Sepal Length (cm)\", \n     cex.lab=label_size, cex.axis=label_size, cex.main=title_size, \n     cex.sub=label_size, col = \"blue\")\n\n\n\n\nFigure 4: Example of approximately normal data\n\n\n\n\nThe above plot is produced using functions available in all R installs. Many plots now use ggplot2, a package you have to install (don’t worry we’ll get there!). However, since you may come back to this later, I’ll also show how to make each of these graphs using ggplot2.\n\nlibrary(ggplot2)\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 5: Example of approximately normal data\n\n\n\n\nHistograms put the data in bins (usually automatically set by software, but you can update!) and then show the number of samples that fell into each bin. This allows a quick estimate (look at the y, or vertical, axis) of how many samples were taken. The above images also allows us to begin to consider the bounds/range of the data (~4.5-8 cm), which gives information on the minimum and maximum values. We can also see lengths around 6-7 cm are most common.\n\n\nWhy do these graphs look slightly different? (Click the grey triangle to see the answer\n\nMost programs, including R, have autobreak functions to separate the data into bins. Notice ggplot2 uses a different algorithm to bin the data. That also impacts what you see! Users, however, can override these, so it’s worth noting that differences in bin size can influence what distributions look like.\n\nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],       main = expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),       xlab = \"Sepal Length (cm)\",       cex.lab=label_size, cex.axis=label_size, cex.main=title_size,       cex.sub=label_size, col = \"blue\") \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=3, main = \"Sepal length histogram, 3 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")  \nhist(iris[iris$Species == \"virginica\", \"Sepal.Length\"],        breaks=10, main = \"Sepal length histogram, 10 breaks\", xlab = \"Sepal Length (cm)\", cex.lab=label_size, cex.axis=label_size, cex.main=title_size, cex.sub=label_size, col = \"blue\")\n\n\n\n\nFigure 6: ?(caption)\n\n\n\n\n\n\n\nFigure 7: ?(caption)\n\n\n\n\n\n\n\nFigure 8: ?(caption)\n\n\n\n\nA similar issue exists for qualitative data in regards to the categories that are combined/used.\n\nThis distribution of this data is approximately normal. We will define normality more later (equations!), but for now note the distribution is roughly symmetric, with tails on either side. Values near the middle of the range are more common, with the chance of getting smaller or larger values declining at an increasing rate…\nComparing the above graph to other distributions may be an easier approach. Consider these graphs.\n\ncardinals &lt;- round(rbeta(10000,70,5),3)\nhist(cardinals, main=\"Weight of Westchester cardinals\", xlab = \"\\n Weight (g)\", ylab = \"Frequency (#)\\n\", col = \"red\", cex.lab=label_size, cex.axis=1.25, cex.main=title_size, cex.sub=label_size)\n\n\n\n\nFigure 9: Example of left-skewed data (plot)\n\n\n\n\n\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram( fill=\"red\", color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 10: Example of left-skewed data (ggplot2)\n\n\n\n\n\nparrots&lt;- round(c(rnorm(1000,.9,4)),3)\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram( fill=\"green\", color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 11: Example of normal data\n\n\n\n\n\nblue_jays &lt;- round(rbeta(10000,2,10),3)\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram( fill=\"blue\", color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 12: Example of right-skewed data\n\n\n\n\nThe cardinal Figure 10 data has a longer left tail and is not symmetric. We call this left- or negatively-skewed data (since it’s going lower on the x-axis). Compare that to the blue jay Figure 12 data; it has a longer right-tail and is positively- or right-skewed. Again, note this is all relative to symmetric data like you see with the parrots Figure 11, which is normally-distributed data.\nAll symmetric data is not normal, however. Look at the data on robin and woodpecker weights.\n\nrochester &lt;- round(c(runif(1000,.1,8)),3)\nggplot(data.frame(rochester), \n       aes(x=rochester)) +\n  geom_histogram( fill=\"pink\", color=\"black\") +\n  labs(title=\"Weight of Rochester robins\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 13: Example of uniform data\n\n\n\n\n\nwoodpeckers &lt;- round(c(rnorm(100,20,4),rnorm(100,40,4)),3)\nggplot(data.frame(woodpeckers), \n       aes(x=woodpeckers)) +\n  geom_histogram( fill=\"orange\", color=\"black\") +\n  labs(title=\"Weight of  Westchester woodpeckers\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 14: Example of bimodal data\n\n\n\n\nBoth these are roughly symmetric but clearly different from normally-distributed data. The robin data is what we call uniformly distributed. There are really no tails, as it appears you are just as likely to see any number within the bounds as any other. Kurtosis is the statistical term for what proportion of the data points are in the tails. High kurtosis distributions have heavy tails with multiple outliers. The uniform distibution is an example of a low kurtosis distribution (it has no tails!).\nThis figure may also help.\n\n\n\nFigure 15: English: Plot of several symmetric unimodal probability densities with unit variance. From highest to lowest peak: red, kurtosis 3, Laplace (D)ouble exponential distribution; orange, kurtosis 2, hyperbolic (S)ecant distribution; green, kurtosis 1.2, (L)ogistic distribution; black, kurtosis 0, (N)ormal distribution; cyan, kurtosis −0.593762…, raised (C)osine distribution; blue, kurtosis −1, (W)igner semicircle distribution; magenta, kurtosis −1.2, (U)niform distribution.\n\n\nIf we consider the normal distribution (shown in black) to have 0 kurtosis, the uniform (pink) has less, and the double-exponential (red) has more.\nFigure 15\nFinally, the woodpecker data is what we call bimodal. It is symmetric in this case (not always true!), but it has a two clear peaks instead of a single central or skewed high point in the distribution.\nThese distributions helps us think about what we would expect to find in future samples (remember, we assume we have good samples!). To think about future sampling, we can change our y-axis from what we saw (frequency) to a probability density.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_histogram(aes(y = ..density..),fill=\"blue\", color=\"black\") +\n  geom_density()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Density\")\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 16: Probability density distribution\n\n\n\n\nThese probability density distributions can be calculated from data (as seen above), but they can also be developed from equations. The benefits of using a distribution derived from an equation is that it is consistent and easy to describe (standardized). This is why many common tests we will learn rely upon the data (or some derivative of it) following a known distribution. For example, many parametric tests will rely upon the data (or means of the data, or errors…we’ll get there) following a normal distribution. We can see our parrot data (which came from a normal distribution!) is very close to a “perfect” normal distribution as define by an equation.\n\nparrots_df &lt;- data.frame(parrots)\ncolors &lt;- c(\"PDF from data\" = \"black\", \"normal curve\" = \"red\", \"Petal Width\" = \"orange\")\nggplot(parrots_df, \n       aes(x=parrots)) +\n  geom_histogram(aes(y = ..density..),fill=\"green\", color=\"black\") +\n  geom_density(aes(color=\"PDF from data\"))+\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Density\",\n       color=\"Legend\")+\nstat_function(fun = dnorm, args = list(mean = mean(parrots_df$parrots), sd = sd(parrots_df$parrots)), aes(color=\"normal curve\"))+\n      scale_color_manual(values = colors)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 17: Comparing the distribution of the data to a perfect normal distribution\n\n\n\n\n\n\nBonus question: Why isn’t it perfect? (Click the grey triangle to see the answer!)\n\nThis is an easy example of sampling error!\n\n\n\nBox plots (aka, box and whisker plots)\nAnother way to visualize the distribution of numerical data for a single group is using box-and-whisker plots.\n\nggplot(iris[iris$Species == \"virginica\",],\n            aes(x=Species,y=Sepal.Length)) + geom_boxplot(size = 3) +\n    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"\",\n       y= \"Sepal Length (cm)\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\nFigure 18: Example of approximately normal data\n\n\n\n\nThese plots show the values of the quartiles of the data. In this way they start combining numerical summaries (more to come!) and visual summaries. More to come, but for now imagine you had a 99 data points. If you arrange the data points from smallest to largest, the median of the data would be the middle (50th data point). If you took the bottom half of the data (first data to median), the first quartile would be the middle point (or, in this case, the average of the 25th and 26th data points). Similarly, the third quartile is the middle of the top half of the data set (or, if not one number, average of 75th and 76th data point). Note the median is also the 2nd quartile of the data!\nThe box in the box-and-whisker plot shows the first, second, and third quartiles, also known as the inter-quartile range (IQR). The whiskers extend to the minimum and maximum values of the dataset or, up to values within a set range. In ggplot, whiskers by default can only be as long as 150% of the IQR. This means extreme outliers are shown as individual dots. Typically, the most extreme values (minimum and maximum) plus the first, second, and third quartiles are together called the five number summary.\n\n“Easy” examples of five number summaries\n\nAssume we have data that goes from 1 to 99. The five number summary should be\n\nx &lt;- seq(1:1:99) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0    25.5    50.0    50.0    74.5    99.0 \n\n\nNote the 1st and 3rd quartiles are averaged!\nSimilarly, consider the numbers 1-5\n\nx &lt;- seq(1:1:5) \nsummary(x)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      1       2       3       3       4       5 \n\n\n\n\n\n\nCategorical data\nFor categorical data, a bar chart fills a very similar role. Note, however, we don’t bin the data., and there is inherent order for some examples (nominal data). For example, we could examine the colors of our I. virginica. To do this, we’ll need to add some data to our iris data (notice this produces no output…)…\n\nset.seed(19)\ncolors &lt;- c(\"blue\", \"orange\", \"purple\")\niris$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\n\nand then summarize it…\n\nlibrary(Rmisc)\n\nLoading required package: lattice\n\n\nLoading required package: plyr\n\nI_viriginica_colors &lt;- summarySE(iris[iris$Species == \"virginica\",], measurevar = \"Sepal.Length\",\n                                 groupvars = \"Color\", na.rm = T)\n\nbefore we graph it.\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")))\n\n\n\n\nFigure 19: Distribution of flower colors\n\n\n\n\nOr better\n\nbarplot(I_viriginica_colors$N, \n        names.arg = I_viriginica_colors$Color, \n        cex.lab=label_size, cex.axis=label_size, \n        cex.main=title_size, cex.sub=label_size, \n        main = expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n        xlab=\"Colors\",\n        ylab=\"Frequency\",\n        col = colors)\n\n\n\n\nFigure 20: Distribution of flower colors (plot)\n\n\n\n\nUsing ggplot2\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 21: Distribution of flower colors (ggplot2)\n\n\n\n\nNote the legend may be superflous here (but consider accessiblity - should we add another distinguishing feature?):\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Color,fill=Color)) +\n  geom_bar()+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Colors\",\n       y= \"Frequency\")+\n  guides(fill = \"none\")\n\n\n\n\nFigure 22: Let colors match traits if possible, but note everyone can’t see colors and sometimes they are not printed.\n\n\n\n\n\n\n**Barchart issues**\n\nNote all of the bar graphs above share a similar problem. People tend to like bars, but they are actually just using a lot of ink! We could get the same information about sepal lengths focusing on just the “top” of the bar:\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length)) +\n  geom_freqpoly(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 23: Note you only really know the tops of the bar!\n\n\n\n\nWe can also just display the data!\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Species, y=Sepal.Length)) +\n  geom_point(color=\"blue\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Frequency\")+\n  theme(axis.text.x = element_text(size=0))\n\n\n\n\nFigure 24: Displaying the data may be the easiest option for small-ish datasets.\n\n\n\n\n\n\n\n\nMultiple variables\nOften we collect multiple pieces of information instead of just one. This can occur for multiple reasons. We may want to consider differences in some variable/trait among groups. This means we have either numerical or categorical data from various groups, but note that groups themselves are now a piece of data! We can think of these analyses as impact of group (a category) on traits (numerical or categorical). We will eventually call these a t-test or ANOVA (when the trait we measure is categorical) ota \\(\\chi^2\\) test (when the trait is categorical). Either way, this is a case where we are collecting a single piece of data from multiple groups. Alternatively, we may collect data on multiple traits from a single group to see how they impact each other. We will eventually analyze this type of data using regression or correlation. Regardless of type, we can also graph this data.\n\nNumerical variables from multiple groups\nWhen we gather numerical data from various groups and wish to compare, we can extend our use bar charts and box-whisker plots by using shapes, colors, or other features to symbolize the groups. For example, we can illustrate the mean (coming up in numerical summaries) or other summary statistics using bar plots..\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_bar(stat = \"summary\", fun = \"mean\") +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n{#fig-bar_charts_all species width=672}\n\n\nor the distribution using stacked histograms…\n\nggplot(iris, aes(x=Sepal.Length)) +     geom_histogram(aes(fill=Species))+    labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\",        x= \"Species\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n{#fig-stacked_histograms_all species width=672}\n\n\nor box-and-whisker plots.\n\nggplot(iris, aes(y=Sepal.Length, x=Species, fill=Species)) +\n  geom_boxplot(aes(colour=Species))+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),        y= \"Sepal length (cm)\", x= \"Species\")\n\n{#fig-box_whisker_all species width=672}\n\n\nWe can also still just display the data for each group…\n\nggplot(iris, aes(y=Sepal.Length, x=Species, color=Species)) +\n  geom_jitter() +\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")\n\n{#fig-point_all species width=672}\n\n\nWe also need to ensure the different groups are visible when distributions overlap. Sometimes stacked histograms (and similar graphs) make it hard to actually visualize each individual group. One option is to instead facet these graphs. Faceting means we produce different graphs for each group, treatment, etc, but they (typically) share axes. This makes it easier to compare the groups.\n\n ggplot(iris, aes(x=Sepal.Length)) + \n   geom_histogram(aes(fill=Species))+ \n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       y= \"Sepal length (cm)\",\n       x= \"Species\")+\n   facet_wrap(~Species, ncol = 1)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n{#fig-faceted_histograms_all species width=672}\n\n\nAnother option is to show the cumulative frequency distribution for each group.\n\nggplot(iris, aes(Sepal.Length, colour = Species)) + stat_ecdf()+\n  labs(title=expression(paste(\"Sepal lengths of \",italic(\"I. species\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Cumulative frequency\")\n\n\n\n\nFigure 25: Cumulative frequency distributions can be useful in noting exactly where distributions diverge\n\n\n\n\n\n\nCategorical data from multiple groups\nFor our example, let’s return to our focus on the color of flowers for various species of iris. One option for this is to consider bar plots. These can be stacked…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 26: Bar plots are stacked by default and count the number of rows found in each category\n\n\n\n\nor not…\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = position_dodge(width=0.5))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 27: Bar plots can also be grouped by adding the position_dodge argument\n\n\n\n\nOther options include divergent plots, but those are best for 2 groups of data. They also require the data to be summarized and somewhat transformed. For example, we could have blue or not blue flowers.\n\nlibrary(plyr)\niris$blue &lt;- revalue(iris$Color, c(\"blue\"=\"blue\", \"purple\"=\"not blue\", \"orange\"=\"not blue\"))\n\nThen we have to summarize the data.\n\niris_summary &lt;- data.frame(table(iris$blue, iris$Species))\nnames(iris_summary) &lt;- c(\"Blue\", \"Species\", \"Frequency\")\n\nand make not blue negative\n\niris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] &lt;- iris_summary[iris_summary$Blue == \"not blue\", \"Frequency\"] * -1\n\nthen plot it.\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 28: Divergent plots show how 2 categories differ among groups\n\n\n\n\nwhich we could flip by reversing all x/y arguments..\n\nggplot(iris_summary,aes(y=Species, x=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       y= \"Species\",\n       x= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\"))\n\n\n\n\nFigure 29: Reorienting graphs may help viewers better visualize differnces\n\n\n\n\nor using an additional argument (remember, a lot of this is for later reference!)\n\nggplot(iris_summary,aes(x=Species, y=Frequency)) +\n  geom_bar(aes(fill=Blue), stat=\"identity\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"not blue\" = \"orange\", \"purple\" = \"purple\")) +\n  coord_flip()\n\n\n\n\nFigure 30: Note we get the same results by simply adding the argument coord_flip\n\n\n\n\n\n\ngeom_bar vs geom_col\n\ngeom_bar and geom_col are very similar commands, but geom_bar assumes its needs to do something to the data (like count it) by default, whereas geom_col assumes the data are summarized/ready to plot as is. The extra argument stat=identity above can usually make geom_bar behave like geom_col.\n\nIn the above cases, each group was measured the same number of times. However, if this isn’t true, visualizations may confound sampling size with summaries. In those cases, focusing on proportion of outcomes may be more useful (and will give you the exact same visualization if all groups were measured the same number of times!). This is sometimes called a mosaic plot; another way to make them (not shown here) is using the package ggmosaic.\n\nggplot(iris,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position = \"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Proportion\")+\n  scale_fill_manual(\"legend\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\"))+\n  guides(fill = \"none\")\n\n\n\n\nFigure 31: For proportion-based visualizations, stacked bar plots may be easier to read than grouped. We just add the position=fill argument to make these.\n\n\n\n\nNote we could also facet this data if we had other variables. For example, assume sampled another set of populations to the west..\n\niris_new &lt;- iris\ncolors &lt;- c(\"pink\", \"orange\", \"yellow\")\niris_new$Color &lt;- factor(sample(colors, size = nrow(iris),replace = T))\niris_both &lt;- rbind(iris,iris_new)\niris_both$Population &lt;- factor(c(rep(\"East\",nrow(iris)), rep(\"West\", nrow(iris_new))))\n\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color))+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\nFigure 32: Faceting can make patterns easier to compare.\n\n\n\n\nNote we can combined these ideas!\n\nggplot(iris_both,aes(x=Species)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Color of \",italic(\"I. virginica \"), \"flowers\")),\n       x= \"Species\",\n       y= \"Frequency\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_wrap(~Population, nrow=1)\n\n\n\n\nFigure 33: We can add facets and proportions.\n\n\n\n\nFinally, we can end this section noting a pie chart is just a transformed bar chart.\n\niris_both$Share &lt;- \"\"\nggplot(iris_both,aes(x=Share)) +\n  geom_bar(aes(fill=Color), position=\"fill\")+\n  labs(title=expression(paste(\"Distribution of flower colors differ among populations of \",italic(\"I. species \"))),\n       y=\"\", \n       x=\"\")+\n  scale_fill_manual(\"Flower color\", values = c(\"blue\" = \"blue\", \"orange\" = \"orange\", \"purple\" = \"purple\", \"pink\"=\"pink\", \"yellow\"=\"yellow\"))+\n  facet_grid(Population~Species) +\n coord_polar(theta=\"y\") \n\n\n\n\nFigure 34: We can add facets and proportions.\n\n\n\n\n\n\nRelationships among data from a single group\nInstead of collecting data on a single trait from multiple groups, we may collect data on multiple traits from a single group. For example, we could want to see if petal length is related to sepal width in I.virginica. This relationship could be visually summarized using a scatter plot.\n\nggplot(iris[iris$Species == \"virginica\",],\n              aes(x=Sepal.Length, y=Petal.Length)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\nFigure 35: Scatter plots show relationships among numerical variables.\n\n\n\n\nObviously we can (and will) combine many of the above approaches. For example, we may want to see if relationships among two numerical variables differ among groups (an ANCOVA!).\n\nggplot(iris,\n              aes(x=Sepal.Length, y=Petal.Length, color=Species)) +\n  geom_point() +\n  labs(title=expression(paste(\"Larger sepals means larger petals in \",italic(\"I. virginica\"))),\n       x= \"Sepal length (cm)\",\n       y= \"Petal Length (cm)\")\n\n\n\n\nFigure 36: We can add facets and proportions\n\n\n\n\nWe’ll get to these later in class, but I just want to note their existence here. Finally, if you are reading this for the first time, don’t worry about the tests (just like the code!). We will explain how all these tests are related when we get there!\nFinally, note data of this type may include time or dates. We’ll use a different dataset to illustrate this.\n\nairquality$Date &lt;-as.Date(paste(airquality$Month, airquality$Day,\"1973\", sep=\"/\"), format =\"%m/%d/%Y\")\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y=\"Temperature (C)\")\n\n\n\n\nFigure 37: Scatter plots can also include temporal data\n\n\n\n\nWe can also add lines…\n\nggplot(airquality, aes(x=Date,y =Temp)) + \n  geom_point(col = \"orange\") + \n  geom_line()+\n  labs(title=\"Temperature over time\", \n       x= \"Date\",\n       y=\"Temperature (C)\")\n\n\n\n\nFigure 38: Scatter plots can also include lines\n\n\n\n\nWe can even include multiple data sets!\n\nggplot(airquality, aes(x =Date,y =Temp)) + geom_point(aes(col =\"Temp\")) + geom_line(col=\"orange\") + geom_point(aes(y=Wind+50, col = \"Wind speed\")) + scale_y_continuous(sec.axis = sec_axis(~.-50, name = \"Wind (mph)\")) + geom_line(aes(y=Wind+50))+\n     labs(title=\"Environmental measurements over time\", \n       x= \"Date\",\n       y=\"Temperature (C)\")\n\n\n\n\nFigure 39: Scatter plots can also include multiple lines\n\n\n\n\n\n\nThere’s more to do and think about!\nThis just scratches the surface of potential ways to visualize data. For example, heatmaps can be used to show location specific data and we can build interactive or animated visualizations. However, the basic principles we’ve examined here should get you started.\nThe different approaches covered here also indicate there a lots way to display data! Whichever approach you use, you should ensure that you represent the data honestly and clearly. Sometimes that means you just display data (points)! You should also always consider possible ways the data/visualization could be misinterpreted and avoid them. Common mistakes include the decision about which baseline should be included. For example, should charts always include 0 on the y-axis? Not including 0 can may small differences appear large. However, including it can make important changes seem insignificant! Consider\n\nsmall_difference &lt;- data.frame(Treatment = c(\"a\",\"b\"), mean=c(37,40))\nlibrary(ggpubr)\n\n\nAttaching package: 'ggpubr'\n\n\nThe following object is masked from 'package:plyr':\n\n    mutate\n\nbp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, fill=Treatment))+\n  geom_bar(stat=\"identity\")\nsp &lt;- ggplot(small_difference, aes(x=Treatment, y=mean, color=Treatment))+\n  geom_point()\ncompare &lt;- ggarrange(bp, sp, labels = c(\"A\", \"B\"),\n          ncol = 2, nrow = 1,common.legend = TRUE, legend=\"bottom\")\nannotate_figure(compare,\n                top = text_grob(\"Including a zero point can make a big difference!\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\nFigure 40: The decision of where to start the y-axis can have major impacts on interpretation\n\n\n\n\nIf this is changes in temperature, option B may be more useful (this could be a normal temperature (37 C) compared to a fever of 104 (40 C). However, if its a difference in a metabolic rate, it may have minor impacts (and thus we choose option A)!\nSimilarly, imagine we collected this data\n\ngood_fit_x &lt;- runif(100, 1, 50) \ngood_fit_y &lt;- rnorm(100,25,2) \ngood_data &lt;- data.frame(source = \"good\", x=good_fit_x, y=good_fit_y) \nbad_fit_x &lt;- runif(10, 20, 30) \nbad_fit_y &lt;- rnorm(10,95,1) \nbad_data &lt;- data.frame(source = \"outlier\", x=bad_fit_x, y=bad_fit_y) \nall_data &lt;- rbind (good_data, bad_data)\n\npoints &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  labs(title=\"Raw data\")\n\npoints_plus_curve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_point(aes(color=source)) + \n  geom_smooth(se = F) + \n    labs(title=\"Curve fit to data but points shown\")\n\ncurve &lt;- ggplot(all_data, aes(x =x,y =y)) + geom_smooth(se = F) +\n    labs(title=\"Only curve\")\ncompare &lt;- ggarrange(points, points_plus_curve, curve, labels = c(\"A\", \"B\", \"C\"),\n          ncol = 2, nrow = 2, common.legend = TRUE, legend=\"bottom\")\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\nannotate_figure(compare,\n                top = text_grob(\"Same data, three visualizations\", color = \"red\", face = \"bold\", size = 14))\n\n\n\n\nFigure 41: This would likely indicate\n\n\n\n\nWhereas the raw data (panel A) may suggest some outliers that are concerning, by panel C we have “smoothed” the data and made an interesting pattern. In general, thought must be applied to individual situations regarding visualization style and nuance. Adding information on spread in the data will also help (coming up!)."
  },
  {
    "objectID": "content/summarizing_data.html#numerical-summaries",
    "href": "content/summarizing_data.html#numerical-summaries",
    "title": "Summarizing data",
    "section": "Numerical Summaries",
    "text": "Numerical Summaries\nWhile visual summaries give us a clearer picture of the data, numerical summaries can help distill a large dataset into several components that can then be analyzed or compared. A key point is we are rarely trying to say if 2 groups are exactly the same or if a trait value is exactly equal to something. Given sampling error, we know its unlikely we would get exactly the same values, and, more importantly, its really rare for 2 groups to be exactly the same. Instead, we are often comparing characteristics of the population data among group or to set values.\nOne common characteristic of a population is central tendency. Central tendency considers what are common values in a dataset by focusing on the center of the distribution. Mean, or the average or \\(\\mu\\) , is one measure of central tendency. Due to sampling error, we don’t know \\(\\mu\\), but we can estimate it. In general, we use Greek letters to denote the population values and standard(Latin) letters typically denote our estimate (sometimes with added symbols). For example, if we have n data points, our estimate of the mean \\(\\mu\\) is known as \\(\\overline{Y}\\) (read as “y-bar”) is\n\\[\n\\overline{Y} = \\frac{\\sum_{i=1}^{n} n_{i}}{n} \\sim \\mu\n\\]\nwhere \\(\\sim\\) means “approximately”. Other measures of central tendency include the mode (most common data point) or median (middle data point if all data were placed in ascending order (remember box plots!)).\nWhy do we need more than one measure of central tendency? Consider our cardinal data:\n\n# function to calculate mode\nfun.mode&lt;-function(x){as.numeric(names(sort(-table(x)))[1])}\n\nggplot(data.frame(cardinals), \n       aes(x=cardinals)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester cardinals\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(cardinals), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(cardinals), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(cardinals), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 42: Skew impacts value of and relationships among various measures of central tendency\n\n\n\n\nNote the data is left-skewed. so the mean is pulled towards these outliers. The median may offer a better summary of the actual center. We see similar outcomes with right-skewed data.\n\nggplot(data.frame(blue_jays), \n       aes(x=blue_jays)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester blue jays\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(blue_jays), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(blue_jays), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(blue_jays), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 43: Skew impacts value of and relationships among various measures of central tendency\n\n\n\n\nBut with symmetric data, we see the measures of central tendency align more\n\nggplot(data.frame(parrots), \n       aes(x=parrots)) +\n  geom_histogram(color=\"black\") +\n  labs(title=\"Weight of Westchester parrots\",\n       x= \"Weight (g)\",\n       y= \"Frequency\")+\n  geom_vline(aes(xintercept=mean(parrots), color=\"mean\"))+\n  geom_vline(aes(xintercept=median(parrots), color= \"median\"))+\n  geom_vline(aes(xintercept=fun.mode(parrots), color = \"mode\")) +\n  theme_bw()+theme(legend.position=\"bottom\")+\n    guides(color = guide_legend(title = \"Measure\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nFigure 44: For symmetric data, measures of central tendency are more aligned.\n\n\n\n\n\n\nWhy is the mode not always on the highest bar?\n\nNote the mode is heavily/totally impacted by data precision and thus can lead to unusual matches with histograms. In our above example, cardinals were measured to 10-3 grams. However, the data was binned to levels of 10-2 grams. Due to this mismatch, the most common measurement of the raw data was 0.954, which occurred 165 times. However, more data points still fell in another bin!\n\n#bimodal data with measures of central tendency##### par(mar = c(rep(2,4))) putnam &lt;- c(rnorm(100,20,4),rnorm(100,40,4)) hist(putnam, main=“Weight of Westchester woodpeckers”, xlab = “Weight (g)”, ylab = “Frequency (#)”, col = “orange”, cex.lab=label_size, cex.axis=1.25, cex.main=title_size, cex.sub=label_size, probability = T) lines(density(putnam), col = “black”, lwd = 4) # add a density estimate with defaults abline(v=mean(putnam), col=“red”, lwd = 4) abline(v=median(putnam), col=“green”, lwd = 4) abline(v=(getmode(putnam)), col=“blue”, lwd = 4) legend(“bottomright”, legend = c(“mean”, “median”, “mode”), fill=c(“red”,“green”,“blue”), cex = 1.5, bty=“n”, x.intersp = .1, y.intersp = .5)\n#illustrate variance#### #add sample # iris$sample &lt;- 1:nrow(iris)\n#just scatter plot\nggplot(iris[iris$Species == “setosa”,], aes(sample,Sepal.Length)) + geom_point(size = 3) + ylab(“Sepal Length (cm)”)+ggtitle(expression(paste(“Sepal Length in”, italic(“Iris setosa”))))+ theme(axis.title.x = element_text(face=“bold”, size=28), axis.title.y = element_text(face=“bold”, size=28), axis.text.y = element_text(size=20), axis.text.x = element_text(size=20), legend.text =element_text(size=20), legend.title = element_text(size=20, face=“bold”), plot.title = element_text(hjust = 0.5, face=“bold”, size=32))\n#add mean ggplot(iris[iris\\(Species == \"setosa\",], aes(sample,Sepal.Length)) + geom_point(size = 3) + ylab(\"Sepal Length (cm)\")+ggtitle(expression(paste(\"Sepal Length in \", italic(\"Iris setosa\"))))+ geom_hline(yintercept = mean(iris[iris\\)Species == “setosa”, “Sepal.Length”]), color = “blue”, size = 2) + annotate(“text”, label = “mean”, x = 20, y = 4.9 , size = 8, color = “blue”) + theme(axis.title.x = element_text(face=“bold”, size=28), axis.title.y = element_text(face=“bold”, size=28), axis.text.y = element_text(size=20), axis.text.x = element_text(size=20), legend.text =element_text(size=20), legend.title = element_text(size=20, face=“bold”), plot.title = element_text(hjust = 0.5, face=“bold”, size=32))"
  }
]